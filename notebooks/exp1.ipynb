{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jaea6ppoSYFx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.load_data import *\n",
    "from utils.train_predict import train_validate_loop, predict\n",
    "from utils.early_stopping import EarlyStopping\n",
    "from utils.metrics import *\n",
    "\n",
    "from models.lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTUNA_STORAGE = \"sqlite:///db.sqlite3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PlHQsGhFSYF1"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/users/bbas/TrabajoFinal/databases\"\n",
    "GROUP = \"Grupo1\"\n",
    "SIMULATION = \"Simulacion_1.dta\"\n",
    "FILEPATH = os.path.join(DATA_DIR, GROUP, SIMULATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5v_3f_FDqHc"
   },
   "source": [
    "**Terminología**:\n",
    "* Tipo 1: individuos tratados.\n",
    "* Tipo 2: individuos de control (i.e. podrían haber sido tratados pero por alguna razón no lo fueron)\n",
    "* Tipo 3: ni tratados ni de control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "sjGpNBoTSYF2",
    "outputId": "a11baa73-7e16-4a5f-a30f-bb37905a19a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 100 indivuduos de tipo 1.\n",
      "Tenemos 100 indivuduos de tipo 2.\n",
      "Tenemos 800 indivuduos de tipo 3.\n"
     ]
    }
   ],
   "source": [
    "type1_df, type2_df, type3_df = get_dfs(FILEPATH)\n",
    "\n",
    "print(f\"Tenemos {len(type1_df)} indivuduos de tipo 1.\")\n",
    "print(f\"Tenemos {len(type2_df)} indivuduos de tipo 2.\")\n",
    "print(f\"Tenemos {len(type3_df)} indivuduos de tipo 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3yE4IV7ClWO"
   },
   "source": [
    "# **Conjunto de entrenamiento**\n",
    "En el conjunto de entrenamiento, metemos:\n",
    "* Todos los de tipo 1 (con target 1)\n",
    "* Algunos de tipo 3 (con target 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TEcrukq_cEbE"
   },
   "outputs": [],
   "source": [
    "# De los individuos de tipo 3, vamos a meter 600 en el conjunto de entrenamiento\n",
    "# de forma tal de tener en total 700 (600 + 100, 70%) individuos en en este conjunto.\n",
    "type3_train = 600\n",
    "# A los que sobran los metemos en el de test\n",
    "type3_test  = len(type3_df) - type3_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNUhyIbmzaqn",
    "outputId": "cc78775e-d17d-4cb1-b4f8-645b939bf59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 700\n",
      "(700, 8) (700,)\n"
     ]
    }
   ],
   "source": [
    "X_train_df = pd.concat([type1_df, type3_df[:type3_train]], ignore_index=True)\n",
    "y_train_df = X_train_df['tratado']\n",
    "\n",
    "print(len(X_train_df), len(y_train_df))\n",
    "print(X_train_df.shape, y_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQiAwy1DC8QN",
    "outputId": "d7e2afd7-620c-4432-97a7-dcbf9b908a23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tratado\n",
       "0    600\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXv_RmiXWu8V"
   },
   "source": [
    "Vemos que el conjunto de entrenamiento está desbalanceado: tiene 100 datos con label 1 y 600 con label 0. Vamos a dejar el dataset así y corregirlo asignando pesos a la función de pérdida durante el entrenamiento. Calculo los pesos acá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svQDm13AW8nO",
    "outputId": "25914f68-2bfd-459e-9557-b9397422a79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso para la clase 0 (mayoritaria): 0.5833333333333334\n",
      "Peso para la clase 1 (minoritaria): 3.5\n"
     ]
    }
   ],
   "source": [
    "# Weights inversely proportional to frequency\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_df), y=y_train_df)\n",
    "\n",
    "print(f\"Peso para la clase 0 (mayoritaria): {weights[0]}\")\n",
    "print(f\"Peso para la clase 1 (minoritaria): {weights[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxNlt5C6Crq7"
   },
   "source": [
    "# **Conjunto de test**\n",
    "En el conjunto de test, metemos:\n",
    "* Todos los de tipo 2 (con target 1)\n",
    "* Los que sobraron de tipo 3 (con target 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8bKGzUq0HMC",
    "outputId": "99219ded-292e-4297-c11f-19bcc34aa747"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n",
      "(300, 8) (300,)\n"
     ]
    }
   ],
   "source": [
    "X_test_df = pd.concat([type2_df, type3_df[type3_train:]], ignore_index=True)\n",
    "y_test_df = X_test_df['control']\n",
    "\n",
    "print(len(X_test_df), len(y_test_df))\n",
    "print(X_test_df.shape, y_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_periods = 4\n",
    "value_columns = ['inicio_prog'] + [f'y(t-{i})' for i in range(required_periods, 0, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  StandardScaler().fit(X_train_df[value_columns])\n",
    "\n",
    "X_train_df[value_columns] = scaler.transform(X_train_df[value_columns])\n",
    "X_test_df [value_columns] = scaler.transform(X_test_df [value_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkTV_FJRYJB4"
   },
   "source": [
    "# **LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basados en el documento `docs/lstm.md`, transformemos los datos que tenemos a la forma que necesitan las LSTM:\n",
    "`(batch_size, sequence_length, num_features)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0EVPE5UaP9d"
   },
   "source": [
    "Cada fila es un individuo y en cada fila ya tenemos todo lo que necesitamos, los 4 datos temporales (`y(t-4)`, `y(t-3)`, `y(t-2)`, `y(t-1)`) y además el dato estático (`inicio_prog`) que lo vamos a tener que repetir cuatro veces para tener la dimensión que deseamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WRK3llPh5a2D"
   },
   "outputs": [],
   "source": [
    "time_steps = 4\n",
    "num_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = get_lstm_input(X_train_df, time_steps, num_features)\n",
    "X_test_tensor  = get_lstm_input(X_test_df , time_steps, num_features)\n",
    "\n",
    "# When using BCEWithLogitsLoss as loss function, the targets should be casted to float\n",
    "y_train_tensor = torch.tensor(y_train_df, dtype=torch.float)\n",
    "y_test_tensor  = torch.tensor(y_test_df , dtype=torch.float)\n",
    "\n",
    "train_set = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_set  = TensorDataset(X_test_tensor , y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kptxCJGX-Swv"
   },
   "source": [
    "## **Búsqueda de hiperparámetros con Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "# study = optuna.create_study(\n",
    "#     direction=\"minimize\",\n",
    "#     storage=OPTUNA_STORAGE,\n",
    "#     study_name=f\"study_{timestamp}\"\n",
    "# )\n",
    "# study.optimize(\n",
    "#     lambda trial: objective(trial, train_set, test_set, weights),\n",
    "#     n_trials=100,\n",
    "#     timeout=600,\n",
    "#     n_jobs=-1,\n",
    "#     show_progress_bar=True\n",
    "# )\n",
    "\n",
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print(\"  Value: \", trial.value)\n",
    "\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Studies de Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study name</th>\n",
       "      <th>Start date</th>\n",
       "      <th>Best trial id</th>\n",
       "      <th>Best objective value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>study_20241126-163837</td>\n",
       "      <td>2024-11-26 16:38:37</td>\n",
       "      <td>22</td>\n",
       "      <td>0.050632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Study name           Start date  Best trial id  \\\n",
       "0  study_20241126-163837  2024-11-26 16:38:37             22   \n",
       "\n",
       "   Best objective value  \n",
       "0              0.050632  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all study summaries\n",
    "study_summaries = optuna.get_all_study_summaries(storage=OPTUNA_STORAGE)\n",
    "\n",
    "data = []\n",
    "for summary in study_summaries:\n",
    "    study_name = summary.study_name\n",
    "    start_date = summary.datetime_start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    best_trial_id = summary.best_trial.number if summary.best_trial else None\n",
    "    best_value = summary.best_trial.value if summary.best_trial else None\n",
    "    data.append([study_name, start_date, best_trial_id, best_value])\n",
    "\n",
    "# Create a DataFrame\n",
    "optuna_studies_df = pd.DataFrame(data, columns=[\"Study name\", \"Start date\", \"Best trial id\", \"Best objective value\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "optuna_studies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Eliminar un study de Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = []\n",
    "for study_name in to_delete:\n",
    "    optuna.delete_study(study_name=study_name, storage=OPTUNA_STORAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entrenamiento del modelo con mejores hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c5368172b546d98bf83ee0c3573baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train loss: 0.6871 | Train accuracy: 0.7914\n",
      "Test loss : 1.0929 | Test accuracy : 0.7367\n",
      "----------------------------------------------------------------\n",
      "Epoch 2\n",
      "Train loss: 0.7394 | Train accuracy: 0.8743\n",
      "Test loss : 1.1232 | Test accuracy : 0.7800\n",
      "----------------------------------------------------------------\n",
      "Epoch 3\n",
      "Train loss: 0.7328 | Train accuracy: 0.7986\n",
      "Test loss : 1.0512 | Test accuracy : 0.7333\n",
      "----------------------------------------------------------------\n",
      "Epoch 4\n",
      "Train loss: 0.6941 | Train accuracy: 0.8443\n",
      "Test loss : 1.0824 | Test accuracy : 0.7567\n",
      "----------------------------------------------------------------\n",
      "Epoch 5\n",
      "Train loss: 0.6749 | Train accuracy: 0.8814\n",
      "Test loss : 1.1659 | Test accuracy : 0.7733\n",
      "----------------------------------------------------------------\n",
      "Epoch 6\n",
      "Train loss: 0.6839 | Train accuracy: 0.8829\n",
      "Test loss : 1.2269 | Test accuracy : 0.7833\n",
      "----------------------------------------------------------------\n",
      "Epoch 7\n",
      "Train loss: 0.6690 | Train accuracy: 0.8786\n",
      "Test loss : 1.0894 | Test accuracy : 0.7667\n",
      "----------------------------------------------------------------\n",
      "Epoch 8\n",
      "Train loss: 0.6688 | Train accuracy: 0.8829\n",
      "Test loss : 1.2051 | Test accuracy : 0.7733\n",
      "----------------------------------------------------------------\n",
      "Epoch 9\n",
      "Train loss: 0.6708 | Train accuracy: 0.8843\n",
      "Test loss : 1.1166 | Test accuracy : 0.7867\n",
      "----------------------------------------------------------------\n",
      "Epoch 10\n",
      "Train loss: 0.6611 | Train accuracy: 0.8814\n",
      "Test loss : 1.1480 | Test accuracy : 0.7733\n",
      "----------------------------------------------------------------\n",
      "Epoch 11\n",
      "Train loss: 0.6686 | Train accuracy: 0.8829\n",
      "Test loss : 1.2261 | Test accuracy : 0.7667\n",
      "----------------------------------------------------------------\n",
      "Epoch 12\n",
      "Train loss: 0.6668 | Train accuracy: 0.8743\n",
      "Test loss : 1.0192 | Test accuracy : 0.7833\n",
      "----------------------------------------------------------------\n",
      "Epoch 13\n",
      "Train loss: 0.6823 | Train accuracy: 0.8629\n",
      "Test loss : 0.9880 | Test accuracy : 0.7767\n",
      "----------------------------------------------------------------\n",
      "Epoch 14\n",
      "Train loss: 0.6405 | Train accuracy: 0.8800\n",
      "Test loss : 1.1081 | Test accuracy : 0.7767\n",
      "----------------------------------------------------------------\n",
      "Epoch 15\n",
      "Train loss: 0.6370 | Train accuracy: 0.8700\n",
      "Test loss : 1.0568 | Test accuracy : 0.7733\n",
      "----------------------------------------------------------------\n",
      "Epoch 16\n",
      "Train loss: 0.6389 | Train accuracy: 0.8729\n",
      "Test loss : 1.0922 | Test accuracy : 0.7767\n",
      "----------------------------------------------------------------\n",
      "Epoch 17\n",
      "Train loss: 0.6555 | Train accuracy: 0.8843\n",
      "Test loss : 0.9989 | Test accuracy : 0.7867\n",
      "----------------------------------------------------------------\n",
      "Epoch 18\n",
      "Train loss: 0.6547 | Train accuracy: 0.8443\n",
      "Test loss : 1.0338 | Test accuracy : 0.7667\n",
      "----------------------------------------------------------------\n",
      "Epoch 19\n",
      "Train loss: 0.6224 | Train accuracy: 0.8786\n",
      "Test loss : 1.0399 | Test accuracy : 0.7833\n",
      "----------------------------------------------------------------\n",
      "Epoch 20\n",
      "Train loss: 0.6314 | Train accuracy: 0.8643\n",
      "Test loss : 0.9600 | Test accuracy : 0.7933\n",
      "----------------------------------------------------------------\n",
      "Epoch 21\n",
      "Train loss: 0.6156 | Train accuracy: 0.8857\n",
      "Test loss : 1.0601 | Test accuracy : 0.7933\n",
      "----------------------------------------------------------------\n",
      "Epoch 22\n",
      "Train loss: 0.6549 | Train accuracy: 0.8271\n",
      "Test loss : 1.0520 | Test accuracy : 0.7567\n",
      "----------------------------------------------------------------\n",
      "Epoch 23\n",
      "Train loss: 0.6297 | Train accuracy: 0.8757\n",
      "Test loss : 1.0588 | Test accuracy : 0.7933\n",
      "----------------------------------------------------------------\n",
      "Epoch 24\n",
      "Train loss: 0.6351 | Train accuracy: 0.8929\n",
      "Test loss : 1.1589 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 25\n",
      "Train loss: 0.6168 | Train accuracy: 0.8714\n",
      "Test loss : 1.0421 | Test accuracy : 0.7867\n",
      "----------------------------------------------------------------\n",
      "Epoch 26\n",
      "Train loss: 0.6464 | Train accuracy: 0.8229\n",
      "Test loss : 0.9650 | Test accuracy : 0.7800\n",
      "----------------------------------------------------------------\n",
      "Epoch 27\n",
      "Train loss: 0.6222 | Train accuracy: 0.8571\n",
      "Test loss : 1.0221 | Test accuracy : 0.7900\n",
      "----------------------------------------------------------------\n",
      "Epoch 28\n",
      "Train loss: 0.6550 | Train accuracy: 0.8257\n",
      "Test loss : 0.9985 | Test accuracy : 0.7700\n",
      "----------------------------------------------------------------\n",
      "Epoch 29\n",
      "Train loss: 0.6165 | Train accuracy: 0.8671\n",
      "Test loss : 0.9658 | Test accuracy : 0.7900\n",
      "----------------------------------------------------------------\n",
      "Epoch 30\n",
      "Train loss: 0.6187 | Train accuracy: 0.8814\n",
      "Test loss : 1.1377 | Test accuracy : 0.8000\n",
      "----------------------------------------------------------------\n",
      "Epoch 31\n",
      "Train loss: 0.5927 | Train accuracy: 0.8614\n",
      "Test loss : 0.9792 | Test accuracy : 0.7867\n",
      "----------------------------------------------------------------\n",
      "Epoch 32\n",
      "Train loss: 0.6421 | Train accuracy: 0.8743\n",
      "Test loss : 1.1842 | Test accuracy : 0.7700\n",
      "----------------------------------------------------------------\n",
      "Epoch 33\n",
      "Train loss: 0.5920 | Train accuracy: 0.8857\n",
      "Test loss : 1.0918 | Test accuracy : 0.7833\n",
      "----------------------------------------------------------------\n",
      "Epoch 34\n",
      "Train loss: 0.5772 | Train accuracy: 0.8671\n",
      "Test loss : 0.9133 | Test accuracy : 0.7833\n",
      "----------------------------------------------------------------\n",
      "Epoch 35\n",
      "Train loss: 0.5556 | Train accuracy: 0.8871\n",
      "Test loss : 0.9256 | Test accuracy : 0.7933\n",
      "----------------------------------------------------------------\n",
      "Epoch 36\n",
      "Train loss: 0.6598 | Train accuracy: 0.8929\n",
      "Test loss : 1.2471 | Test accuracy : 0.7867\n",
      "----------------------------------------------------------------\n",
      "Epoch 37\n",
      "Train loss: 0.5686 | Train accuracy: 0.8714\n",
      "Test loss : 0.9245 | Test accuracy : 0.7833\n",
      "----------------------------------------------------------------\n",
      "Epoch 38\n",
      "Train loss: 0.6061 | Train accuracy: 0.8386\n",
      "Test loss : 0.8969 | Test accuracy : 0.7700\n",
      "----------------------------------------------------------------\n",
      "Epoch 39\n",
      "Train loss: 0.5673 | Train accuracy: 0.8714\n",
      "Test loss : 0.9748 | Test accuracy : 0.7867\n",
      "----------------------------------------------------------------\n",
      "Epoch 40\n",
      "Train loss: 0.5685 | Train accuracy: 0.8629\n",
      "Test loss : 0.9196 | Test accuracy : 0.7900\n",
      "----------------------------------------------------------------\n",
      "Epoch 41\n",
      "Train loss: 0.5683 | Train accuracy: 0.8671\n",
      "Test loss : 0.9268 | Test accuracy : 0.7900\n",
      "----------------------------------------------------------------\n",
      "Epoch 42\n",
      "Train loss: 0.5476 | Train accuracy: 0.8629\n",
      "Test loss : 0.9528 | Test accuracy : 0.7900\n",
      "----------------------------------------------------------------\n",
      "Epoch 43\n",
      "Train loss: 0.5497 | Train accuracy: 0.8771\n",
      "Test loss : 0.9567 | Test accuracy : 0.7967\n",
      "----------------------------------------------------------------\n",
      "Epoch 44\n",
      "Train loss: 0.5609 | Train accuracy: 0.8729\n",
      "Test loss : 0.9759 | Test accuracy : 0.8000\n",
      "----------------------------------------------------------------\n",
      "Epoch 45\n",
      "Train loss: 0.5244 | Train accuracy: 0.8657\n",
      "Test loss : 0.8762 | Test accuracy : 0.8033\n",
      "----------------------------------------------------------------\n",
      "Epoch 46\n",
      "Train loss: 0.6122 | Train accuracy: 0.8814\n",
      "Test loss : 1.0955 | Test accuracy : 0.7800\n",
      "----------------------------------------------------------------\n",
      "Epoch 47\n",
      "Train loss: 0.5311 | Train accuracy: 0.8771\n",
      "Test loss : 0.9929 | Test accuracy : 0.7967\n",
      "----------------------------------------------------------------\n",
      "Epoch 48\n",
      "Train loss: 0.5652 | Train accuracy: 0.8829\n",
      "Test loss : 1.0251 | Test accuracy : 0.7933\n",
      "----------------------------------------------------------------\n",
      "Epoch 49\n",
      "Train loss: 0.6229 | Train accuracy: 0.8157\n",
      "Test loss : 0.9421 | Test accuracy : 0.7767\n",
      "----------------------------------------------------------------\n",
      "Epoch 50\n",
      "Train loss: 0.5210 | Train accuracy: 0.8857\n",
      "Test loss : 0.9200 | Test accuracy : 0.8100\n",
      "----------------------------------------------------------------\n",
      "Epoch 51\n",
      "Train loss: 0.5200 | Train accuracy: 0.8771\n",
      "Test loss : 0.9173 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 52\n",
      "Train loss: 0.5121 | Train accuracy: 0.8857\n",
      "Test loss : 0.9077 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 53\n",
      "Train loss: 0.5249 | Train accuracy: 0.8700\n",
      "Test loss : 0.9055 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 54\n",
      "Train loss: 0.4851 | Train accuracy: 0.9014\n",
      "Test loss : 0.8867 | Test accuracy : 0.8300\n",
      "----------------------------------------------------------------\n",
      "Epoch 55\n",
      "Train loss: 0.5327 | Train accuracy: 0.8657\n",
      "Test loss : 0.8890 | Test accuracy : 0.8000\n",
      "----------------------------------------------------------------\n",
      "Epoch 56\n",
      "Train loss: 0.5099 | Train accuracy: 0.8757\n",
      "Test loss : 0.8585 | Test accuracy : 0.8167\n",
      "----------------------------------------------------------------\n",
      "Epoch 57\n",
      "Train loss: 0.5068 | Train accuracy: 0.8914\n",
      "Test loss : 0.8402 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 58\n",
      "Train loss: 0.5432 | Train accuracy: 0.8800\n",
      "Test loss : 0.8934 | Test accuracy : 0.8200\n",
      "----------------------------------------------------------------\n",
      "Epoch 59\n",
      "Train loss: 0.5149 | Train accuracy: 0.8871\n",
      "Test loss : 0.8755 | Test accuracy : 0.8333\n",
      "----------------------------------------------------------------\n",
      "Epoch 60\n",
      "Train loss: 0.5226 | Train accuracy: 0.8643\n",
      "Test loss : 0.8663 | Test accuracy : 0.7900\n",
      "----------------------------------------------------------------\n",
      "Epoch 61\n",
      "Train loss: 0.5237 | Train accuracy: 0.8600\n",
      "Test loss : 0.8527 | Test accuracy : 0.7900\n",
      "----------------------------------------------------------------\n",
      "Epoch 62\n",
      "Train loss: 0.4828 | Train accuracy: 0.8814\n",
      "Test loss : 0.7918 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 63\n",
      "Train loss: 0.4724 | Train accuracy: 0.8971\n",
      "Test loss : 0.8708 | Test accuracy : 0.8133\n",
      "----------------------------------------------------------------\n",
      "Epoch 64\n",
      "Train loss: 0.4880 | Train accuracy: 0.8914\n",
      "Test loss : 0.8729 | Test accuracy : 0.8200\n",
      "----------------------------------------------------------------\n",
      "Epoch 65\n",
      "Train loss: 0.4567 | Train accuracy: 0.8886\n",
      "Test loss : 0.8093 | Test accuracy : 0.8100\n",
      "----------------------------------------------------------------\n",
      "Epoch 66\n",
      "Train loss: 0.5516 | Train accuracy: 0.9043\n",
      "Test loss : 1.1043 | Test accuracy : 0.8167\n",
      "----------------------------------------------------------------\n",
      "Epoch 67\n",
      "Train loss: 0.4795 | Train accuracy: 0.8971\n",
      "Test loss : 0.8650 | Test accuracy : 0.8200\n",
      "----------------------------------------------------------------\n",
      "Epoch 68\n",
      "Train loss: 0.4724 | Train accuracy: 0.8800\n",
      "Test loss : 0.8168 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 69\n",
      "Train loss: 0.4288 | Train accuracy: 0.8957\n",
      "Test loss : 0.7934 | Test accuracy : 0.8133\n",
      "----------------------------------------------------------------\n",
      "Epoch 70\n",
      "Train loss: 0.4506 | Train accuracy: 0.9014\n",
      "Test loss : 0.8215 | Test accuracy : 0.8200\n",
      "----------------------------------------------------------------\n",
      "Epoch 71\n",
      "Train loss: 0.4963 | Train accuracy: 0.8671\n",
      "Test loss : 0.8741 | Test accuracy : 0.8133\n",
      "----------------------------------------------------------------\n",
      "Epoch 72\n",
      "Train loss: 0.4656 | Train accuracy: 0.8957\n",
      "Test loss : 0.8626 | Test accuracy : 0.8100\n",
      "----------------------------------------------------------------\n",
      "Epoch 73\n",
      "Train loss: 0.4873 | Train accuracy: 0.9014\n",
      "Test loss : 0.8942 | Test accuracy : 0.8200\n",
      "----------------------------------------------------------------\n",
      "Epoch 74\n",
      "Train loss: 0.4797 | Train accuracy: 0.8714\n",
      "Test loss : 0.8095 | Test accuracy : 0.8167\n",
      "----------------------------------------------------------------\n",
      "Epoch 75\n",
      "Train loss: 0.5303 | Train accuracy: 0.8829\n",
      "Test loss : 0.9646 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 76\n",
      "Train loss: 0.4840 | Train accuracy: 0.8500\n",
      "Test loss : 0.7439 | Test accuracy : 0.8167\n",
      "----------------------------------------------------------------\n",
      "Epoch 77\n",
      "Train loss: 0.4220 | Train accuracy: 0.8786\n",
      "Test loss : 0.7055 | Test accuracy : 0.8167\n",
      "----------------------------------------------------------------\n",
      "Epoch 78\n",
      "Train loss: 0.4247 | Train accuracy: 0.8786\n",
      "Test loss : 0.7150 | Test accuracy : 0.8367\n",
      "----------------------------------------------------------------\n",
      "Epoch 79\n",
      "Train loss: 0.4612 | Train accuracy: 0.8500\n",
      "Test loss : 0.7134 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 80\n",
      "Train loss: 0.4245 | Train accuracy: 0.8914\n",
      "Test loss : 0.6973 | Test accuracy : 0.8367\n",
      "----------------------------------------------------------------\n",
      "Epoch 81\n",
      "Train loss: 0.4253 | Train accuracy: 0.9043\n",
      "Test loss : 0.7623 | Test accuracy : 0.8433\n",
      "----------------------------------------------------------------\n",
      "Epoch 82\n",
      "Train loss: 0.3897 | Train accuracy: 0.9100\n",
      "Test loss : 0.7294 | Test accuracy : 0.8433\n",
      "----------------------------------------------------------------\n",
      "Epoch 83\n",
      "Train loss: 0.3765 | Train accuracy: 0.9200\n",
      "Test loss : 0.7006 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 84\n",
      "Train loss: 0.3841 | Train accuracy: 0.9043\n",
      "Test loss : 0.6989 | Test accuracy : 0.8400\n",
      "----------------------------------------------------------------\n",
      "Epoch 85\n",
      "Train loss: 0.4077 | Train accuracy: 0.8800\n",
      "Test loss : 0.6967 | Test accuracy : 0.8333\n",
      "----------------------------------------------------------------\n",
      "Epoch 86\n",
      "Train loss: 0.4096 | Train accuracy: 0.8986\n",
      "Test loss : 0.7203 | Test accuracy : 0.8333\n",
      "----------------------------------------------------------------\n",
      "Epoch 87\n",
      "Train loss: 0.3978 | Train accuracy: 0.8957\n",
      "Test loss : 0.6980 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 88\n",
      "Train loss: 0.7818 | Train accuracy: 0.8371\n",
      "Test loss : 1.3605 | Test accuracy : 0.8000\n",
      "----------------------------------------------------------------\n",
      "Epoch 89\n",
      "Train loss: 0.5646 | Train accuracy: 0.8857\n",
      "Test loss : 0.9746 | Test accuracy : 0.8200\n",
      "----------------------------------------------------------------\n",
      "Epoch 90\n",
      "Train loss: 0.5597 | Train accuracy: 0.8514\n",
      "Test loss : 0.8556 | Test accuracy : 0.7900\n",
      "----------------------------------------------------------------\n",
      "Epoch 91\n",
      "Train loss: 0.5219 | Train accuracy: 0.8743\n",
      "Test loss : 0.8426 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 92\n",
      "Train loss: 0.5078 | Train accuracy: 0.8886\n",
      "Test loss : 0.8744 | Test accuracy : 0.8167\n",
      "----------------------------------------------------------------\n",
      "Epoch 93\n",
      "Train loss: 0.5089 | Train accuracy: 0.8600\n",
      "Test loss : 0.7650 | Test accuracy : 0.8167\n",
      "----------------------------------------------------------------\n",
      "Epoch 94\n",
      "Train loss: 0.4908 | Train accuracy: 0.8914\n",
      "Test loss : 0.8460 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 95\n",
      "Train loss: 0.4863 | Train accuracy: 0.8829\n",
      "Test loss : 0.7755 | Test accuracy : 0.8300\n",
      "----------------------------------------------------------------\n",
      "Epoch 96\n",
      "Train loss: 0.5826 | Train accuracy: 0.7857\n",
      "Test loss : 0.7998 | Test accuracy : 0.7833\n",
      "----------------------------------------------------------------\n",
      "Epoch 97\n",
      "Train loss: 0.5131 | Train accuracy: 0.8457\n",
      "Test loss : 0.7915 | Test accuracy : 0.7933\n",
      "----------------------------------------------------------------\n",
      "Epoch 98\n",
      "Train loss: 0.4903 | Train accuracy: 0.8871\n",
      "Test loss : 0.8334 | Test accuracy : 0.8033\n",
      "----------------------------------------------------------------\n",
      "Epoch 99\n",
      "Train loss: 0.4461 | Train accuracy: 0.8914\n",
      "Test loss : 0.8176 | Test accuracy : 0.7967\n",
      "----------------------------------------------------------------\n",
      "Epoch 100\n",
      "Train loss: 0.4206 | Train accuracy: 0.9014\n",
      "Test loss : 0.7433 | Test accuracy : 0.8133\n",
      "----------------------------------------------------------------\n",
      "Epoch 101\n",
      "Train loss: 0.4038 | Train accuracy: 0.9029\n",
      "Test loss : 0.7184 | Test accuracy : 0.8133\n",
      "----------------------------------------------------------------\n",
      "Epoch 102\n",
      "Train loss: 0.4489 | Train accuracy: 0.8729\n",
      "Test loss : 0.7804 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 103\n",
      "Train loss: 0.4004 | Train accuracy: 0.8714\n",
      "Test loss : 0.6458 | Test accuracy : 0.8000\n",
      "----------------------------------------------------------------\n",
      "Epoch 104\n",
      "Train loss: 0.3934 | Train accuracy: 0.9100\n",
      "Test loss : 0.7203 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 105\n",
      "Train loss: 0.5054 | Train accuracy: 0.8757\n",
      "Test loss : 0.8733 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 106\n",
      "Train loss: 0.4908 | Train accuracy: 0.8700\n",
      "Test loss : 0.7980 | Test accuracy : 0.8333\n",
      "----------------------------------------------------------------\n",
      "Epoch 107\n",
      "Train loss: 0.5076 | Train accuracy: 0.8700\n",
      "Test loss : 0.9078 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 108\n",
      "Train loss: 0.4379 | Train accuracy: 0.8800\n",
      "Test loss : 0.7612 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 109\n",
      "Train loss: 0.3972 | Train accuracy: 0.9043\n",
      "Test loss : 0.7240 | Test accuracy : 0.8267\n",
      "----------------------------------------------------------------\n",
      "Epoch 110\n",
      "Train loss: 0.3890 | Train accuracy: 0.9000\n",
      "Test loss : 0.7074 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 111\n",
      "Train loss: 0.4103 | Train accuracy: 0.8971\n",
      "Test loss : 0.7358 | Test accuracy : 0.8033\n",
      "----------------------------------------------------------------\n",
      "Epoch 112\n",
      "Train loss: 0.4115 | Train accuracy: 0.8871\n",
      "Test loss : 0.7272 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 113\n",
      "Train loss: 0.3678 | Train accuracy: 0.9129\n",
      "Test loss : 0.6630 | Test accuracy : 0.8500\n",
      "----------------------------------------------------------------\n",
      "Epoch 114\n",
      "Train loss: 0.3392 | Train accuracy: 0.9229\n",
      "Test loss : 0.6492 | Test accuracy : 0.8400\n",
      "----------------------------------------------------------------\n",
      "Epoch 115\n",
      "Train loss: 0.3405 | Train accuracy: 0.9200\n",
      "Test loss : 0.6300 | Test accuracy : 0.8400\n",
      "----------------------------------------------------------------\n",
      "Epoch 116\n",
      "Train loss: 0.4432 | Train accuracy: 0.8886\n",
      "Test loss : 0.8312 | Test accuracy : 0.8133\n",
      "----------------------------------------------------------------\n",
      "Epoch 117\n",
      "Train loss: 0.3680 | Train accuracy: 0.9171\n",
      "Test loss : 0.6785 | Test accuracy : 0.8500\n",
      "----------------------------------------------------------------\n",
      "Epoch 118\n",
      "Train loss: 0.4037 | Train accuracy: 0.8786\n",
      "Test loss : 0.6917 | Test accuracy : 0.8367\n",
      "----------------------------------------------------------------\n",
      "Epoch 119\n",
      "Train loss: 0.4152 | Train accuracy: 0.9029\n",
      "Test loss : 0.7782 | Test accuracy : 0.8200\n",
      "----------------------------------------------------------------\n",
      "Epoch 120\n",
      "Train loss: 0.3476 | Train accuracy: 0.9029\n",
      "Test loss : 0.6046 | Test accuracy : 0.8433\n",
      "----------------------------------------------------------------\n",
      "Epoch 121\n",
      "Train loss: 0.4134 | Train accuracy: 0.8843\n",
      "Test loss : 0.6642 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 122\n",
      "Train loss: 0.4061 | Train accuracy: 0.8814\n",
      "Test loss : 0.7126 | Test accuracy : 0.8167\n",
      "----------------------------------------------------------------\n",
      "Epoch 123\n",
      "Train loss: 0.3476 | Train accuracy: 0.9057\n",
      "Test loss : 0.6627 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 124\n",
      "Train loss: 0.3117 | Train accuracy: 0.9157\n",
      "Test loss : 0.5870 | Test accuracy : 0.8600\n",
      "----------------------------------------------------------------\n",
      "Epoch 125\n",
      "Train loss: 0.2944 | Train accuracy: 0.9257\n",
      "Test loss : 0.5929 | Test accuracy : 0.8667\n",
      "----------------------------------------------------------------\n",
      "Epoch 126\n",
      "Train loss: 0.3026 | Train accuracy: 0.9286\n",
      "Test loss : 0.6051 | Test accuracy : 0.8500\n",
      "----------------------------------------------------------------\n",
      "Epoch 127\n",
      "Train loss: 0.2924 | Train accuracy: 0.9186\n",
      "Test loss : 0.5970 | Test accuracy : 0.8500\n",
      "----------------------------------------------------------------\n",
      "Epoch 128\n",
      "Train loss: 0.3611 | Train accuracy: 0.8971\n",
      "Test loss : 0.6794 | Test accuracy : 0.8433\n",
      "----------------------------------------------------------------\n",
      "Epoch 129\n",
      "Train loss: 0.3549 | Train accuracy: 0.9129\n",
      "Test loss : 0.6514 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 130\n",
      "Train loss: 0.3290 | Train accuracy: 0.9129\n",
      "Test loss : 0.5799 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 131\n",
      "Train loss: 0.3002 | Train accuracy: 0.9157\n",
      "Test loss : 0.6099 | Test accuracy : 0.8533\n",
      "----------------------------------------------------------------\n",
      "Epoch 132\n",
      "Train loss: 0.3154 | Train accuracy: 0.9014\n",
      "Test loss : 0.6023 | Test accuracy : 0.8533\n",
      "----------------------------------------------------------------\n",
      "Epoch 133\n",
      "Train loss: 0.3174 | Train accuracy: 0.9057\n",
      "Test loss : 0.6165 | Test accuracy : 0.8300\n",
      "----------------------------------------------------------------\n",
      "Epoch 134\n",
      "Train loss: 0.3529 | Train accuracy: 0.8943\n",
      "Test loss : 0.6433 | Test accuracy : 0.8333\n",
      "----------------------------------------------------------------\n",
      "Epoch 135\n",
      "Train loss: 0.2975 | Train accuracy: 0.9286\n",
      "Test loss : 0.6389 | Test accuracy : 0.8667\n",
      "----------------------------------------------------------------\n",
      "Epoch 136\n",
      "Train loss: 0.3678 | Train accuracy: 0.9000\n",
      "Test loss : 0.6327 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 137\n",
      "Train loss: 0.3295 | Train accuracy: 0.9000\n",
      "Test loss : 0.5938 | Test accuracy : 0.8433\n",
      "----------------------------------------------------------------\n",
      "Epoch 138\n",
      "Train loss: 0.3913 | Train accuracy: 0.8757\n",
      "Test loss : 0.7023 | Test accuracy : 0.8333\n",
      "----------------------------------------------------------------\n",
      "Epoch 139\n",
      "Train loss: 0.3406 | Train accuracy: 0.9071\n",
      "Test loss : 0.6536 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 140\n",
      "Train loss: 0.3275 | Train accuracy: 0.9186\n",
      "Test loss : 0.6885 | Test accuracy : 0.8433\n",
      "----------------------------------------------------------------\n",
      "Epoch 141\n",
      "Train loss: 0.3647 | Train accuracy: 0.9114\n",
      "Test loss : 0.7189 | Test accuracy : 0.8533\n",
      "----------------------------------------------------------------\n",
      "Epoch 142\n",
      "Train loss: 0.3289 | Train accuracy: 0.8971\n",
      "Test loss : 0.6212 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 143\n",
      "Train loss: 0.3473 | Train accuracy: 0.9286\n",
      "Test loss : 0.7313 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 144\n",
      "Train loss: 0.3278 | Train accuracy: 0.9071\n",
      "Test loss : 0.6164 | Test accuracy : 0.8600\n",
      "----------------------------------------------------------------\n",
      "Epoch 145\n",
      "Train loss: 0.3496 | Train accuracy: 0.8814\n",
      "Test loss : 0.6000 | Test accuracy : 0.8267\n",
      "----------------------------------------------------------------\n",
      "Epoch 146\n",
      "Train loss: 0.3518 | Train accuracy: 0.9314\n",
      "Test loss : 0.7490 | Test accuracy : 0.8600\n",
      "----------------------------------------------------------------\n",
      "Epoch 147\n",
      "Train loss: 0.3128 | Train accuracy: 0.9186\n",
      "Test loss : 0.6493 | Test accuracy : 0.8500\n",
      "----------------------------------------------------------------\n",
      "Epoch 148\n",
      "Train loss: 0.2890 | Train accuracy: 0.9200\n",
      "Test loss : 0.5585 | Test accuracy : 0.8667\n",
      "----------------------------------------------------------------\n",
      "Epoch 149\n",
      "Train loss: 0.2598 | Train accuracy: 0.9443\n",
      "Test loss : 0.5627 | Test accuracy : 0.8800\n",
      "----------------------------------------------------------------\n",
      "Epoch 150\n",
      "Train loss: 0.2869 | Train accuracy: 0.9157\n",
      "Test loss : 0.5617 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 151\n",
      "Train loss: 0.2836 | Train accuracy: 0.9057\n",
      "Test loss : 0.5268 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 152\n",
      "Train loss: 0.2487 | Train accuracy: 0.9457\n",
      "Test loss : 0.5211 | Test accuracy : 0.8900\n",
      "----------------------------------------------------------------\n",
      "Epoch 153\n",
      "Train loss: 0.4940 | Train accuracy: 0.9057\n",
      "Test loss : 1.0309 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 154\n",
      "Train loss: 0.3951 | Train accuracy: 0.8857\n",
      "Test loss : 0.7043 | Test accuracy : 0.8067\n",
      "----------------------------------------------------------------\n",
      "Epoch 155\n",
      "Train loss: 0.3430 | Train accuracy: 0.8957\n",
      "Test loss : 0.5814 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 156\n",
      "Train loss: 0.3566 | Train accuracy: 0.8829\n",
      "Test loss : 0.5870 | Test accuracy : 0.8367\n",
      "----------------------------------------------------------------\n",
      "Epoch 157\n",
      "Train loss: 0.3187 | Train accuracy: 0.9129\n",
      "Test loss : 0.5775 | Test accuracy : 0.8433\n",
      "----------------------------------------------------------------\n",
      "Epoch 158\n",
      "Train loss: 0.3205 | Train accuracy: 0.9086\n",
      "Test loss : 0.5869 | Test accuracy : 0.8533\n",
      "----------------------------------------------------------------\n",
      "Epoch 159\n",
      "Train loss: 0.2971 | Train accuracy: 0.9186\n",
      "Test loss : 0.5689 | Test accuracy : 0.8700\n",
      "----------------------------------------------------------------\n",
      "Epoch 160\n",
      "Train loss: 0.2919 | Train accuracy: 0.9129\n",
      "Test loss : 0.5716 | Test accuracy : 0.8400\n",
      "----------------------------------------------------------------\n",
      "Epoch 161\n",
      "Train loss: 0.3202 | Train accuracy: 0.9157\n",
      "Test loss : 0.6368 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 162\n",
      "Train loss: 0.2764 | Train accuracy: 0.9200\n",
      "Test loss : 0.5513 | Test accuracy : 0.8667\n",
      "----------------------------------------------------------------\n",
      "Epoch 163\n",
      "Train loss: 0.2514 | Train accuracy: 0.9300\n",
      "Test loss : 0.5085 | Test accuracy : 0.8900\n",
      "----------------------------------------------------------------\n",
      "Epoch 164\n",
      "Train loss: 0.2296 | Train accuracy: 0.9371\n",
      "Test loss : 0.4840 | Test accuracy : 0.8867\n",
      "----------------------------------------------------------------\n",
      "Epoch 165\n",
      "Train loss: 0.2352 | Train accuracy: 0.9457\n",
      "Test loss : 0.4839 | Test accuracy : 0.8933\n",
      "----------------------------------------------------------------\n",
      "Epoch 166\n",
      "Train loss: 0.2588 | Train accuracy: 0.9371\n",
      "Test loss : 0.5366 | Test accuracy : 0.8867\n",
      "----------------------------------------------------------------\n",
      "Epoch 167\n",
      "Train loss: 0.3251 | Train accuracy: 0.8771\n",
      "Test loss : 0.6198 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 168\n",
      "Train loss: 0.2997 | Train accuracy: 0.9257\n",
      "Test loss : 0.6243 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 169\n",
      "Train loss: 0.2549 | Train accuracy: 0.9243\n",
      "Test loss : 0.5335 | Test accuracy : 0.8667\n",
      "----------------------------------------------------------------\n",
      "Epoch 170\n",
      "Train loss: 0.2704 | Train accuracy: 0.9386\n",
      "Test loss : 0.6038 | Test accuracy : 0.8833\n",
      "----------------------------------------------------------------\n",
      "Epoch 171\n",
      "Train loss: 0.2259 | Train accuracy: 0.9486\n",
      "Test loss : 0.4942 | Test accuracy : 0.8767\n",
      "----------------------------------------------------------------\n",
      "Epoch 172\n",
      "Train loss: 0.2400 | Train accuracy: 0.9343\n",
      "Test loss : 0.5460 | Test accuracy : 0.8733\n",
      "----------------------------------------------------------------\n",
      "Epoch 173\n",
      "Train loss: 0.2078 | Train accuracy: 0.9443\n",
      "Test loss : 0.4831 | Test accuracy : 0.8800\n",
      "----------------------------------------------------------------\n",
      "Epoch 174\n",
      "Train loss: 0.2337 | Train accuracy: 0.9386\n",
      "Test loss : 0.5122 | Test accuracy : 0.8800\n",
      "----------------------------------------------------------------\n",
      "Epoch 175\n",
      "Train loss: 0.2695 | Train accuracy: 0.9357\n",
      "Test loss : 0.6329 | Test accuracy : 0.8600\n",
      "----------------------------------------------------------------\n",
      "Epoch 176\n",
      "Train loss: 0.2258 | Train accuracy: 0.9414\n",
      "Test loss : 0.5306 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 177\n",
      "Train loss: 0.2287 | Train accuracy: 0.9357\n",
      "Test loss : 0.4965 | Test accuracy : 0.8700\n",
      "----------------------------------------------------------------\n",
      "Epoch 178\n",
      "Train loss: 0.2202 | Train accuracy: 0.9429\n",
      "Test loss : 0.5380 | Test accuracy : 0.8767\n",
      "----------------------------------------------------------------\n",
      "Epoch 179\n",
      "Train loss: 0.2250 | Train accuracy: 0.9414\n",
      "Test loss : 0.5064 | Test accuracy : 0.8767\n",
      "----------------------------------------------------------------\n",
      "Epoch 180\n",
      "Train loss: 0.3459 | Train accuracy: 0.9486\n",
      "Test loss : 0.8066 | Test accuracy : 0.8800\n",
      "----------------------------------------------------------------\n",
      "Epoch 181\n",
      "Train loss: 0.2738 | Train accuracy: 0.9014\n",
      "Test loss : 0.5568 | Test accuracy : 0.8300\n",
      "----------------------------------------------------------------\n",
      "Epoch 182\n",
      "Train loss: 0.4741 | Train accuracy: 0.8457\n",
      "Test loss : 0.7595 | Test accuracy : 0.8100\n",
      "----------------------------------------------------------------\n",
      "Epoch 183\n",
      "Train loss: 0.3999 | Train accuracy: 0.8986\n",
      "Test loss : 0.7992 | Test accuracy : 0.8233\n",
      "----------------------------------------------------------------\n",
      "Epoch 184\n",
      "Train loss: 0.3720 | Train accuracy: 0.9014\n",
      "Test loss : 0.7757 | Test accuracy : 0.8367\n",
      "----------------------------------------------------------------\n",
      "Epoch 185\n",
      "Train loss: 0.4182 | Train accuracy: 0.9000\n",
      "Test loss : 0.8158 | Test accuracy : 0.8333\n",
      "----------------------------------------------------------------\n",
      "Epoch 186\n",
      "Train loss: 0.3575 | Train accuracy: 0.9129\n",
      "Test loss : 0.6849 | Test accuracy : 0.8500\n",
      "----------------------------------------------------------------\n",
      "Epoch 187\n",
      "Train loss: 0.3372 | Train accuracy: 0.9214\n",
      "Test loss : 0.6860 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 188\n",
      "Train loss: 0.2998 | Train accuracy: 0.9329\n",
      "Test loss : 0.5818 | Test accuracy : 0.8667\n",
      "----------------------------------------------------------------\n",
      "Epoch 189\n",
      "Train loss: 0.2718 | Train accuracy: 0.9271\n",
      "Test loss : 0.5564 | Test accuracy : 0.8733\n",
      "----------------------------------------------------------------\n",
      "Epoch 190\n",
      "Train loss: 0.3640 | Train accuracy: 0.9071\n",
      "Test loss : 0.6679 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 191\n",
      "Train loss: 0.3172 | Train accuracy: 0.9329\n",
      "Test loss : 0.6390 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 192\n",
      "Train loss: 0.2826 | Train accuracy: 0.9486\n",
      "Test loss : 0.5880 | Test accuracy : 0.8733\n",
      "----------------------------------------------------------------\n",
      "Epoch 193\n",
      "Train loss: 0.2663 | Train accuracy: 0.9500\n",
      "Test loss : 0.5882 | Test accuracy : 0.8767\n",
      "----------------------------------------------------------------\n",
      "Epoch 194\n",
      "Train loss: 0.2765 | Train accuracy: 0.9429\n",
      "Test loss : 0.5888 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 195\n",
      "Train loss: 0.2537 | Train accuracy: 0.9457\n",
      "Test loss : 0.5699 | Test accuracy : 0.8767\n",
      "----------------------------------------------------------------\n",
      "Epoch 196\n",
      "Train loss: 0.3622 | Train accuracy: 0.9071\n",
      "Test loss : 0.6691 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 197\n",
      "Train loss: 0.3760 | Train accuracy: 0.9071\n",
      "Test loss : 0.7124 | Test accuracy : 0.8533\n",
      "----------------------------------------------------------------\n",
      "Epoch 198\n",
      "Train loss: 0.3891 | Train accuracy: 0.9029\n",
      "Test loss : 0.6911 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 199\n",
      "Train loss: 0.3469 | Train accuracy: 0.9000\n",
      "Test loss : 0.5826 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 200\n",
      "Train loss: 0.3437 | Train accuracy: 0.9157\n",
      "Test loss : 0.6286 | Test accuracy : 0.8733\n",
      "----------------------------------------------------------------\n",
      "Epoch 201\n",
      "Train loss: 0.3116 | Train accuracy: 0.9114\n",
      "Test loss : 0.5343 | Test accuracy : 0.8667\n",
      "----------------------------------------------------------------\n",
      "Epoch 202\n",
      "Train loss: 0.3048 | Train accuracy: 0.9171\n",
      "Test loss : 0.6195 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 203\n",
      "Train loss: 0.2862 | Train accuracy: 0.9200\n",
      "Test loss : 0.5276 | Test accuracy : 0.8700\n",
      "----------------------------------------------------------------\n",
      "Epoch 204\n",
      "Train loss: 0.2978 | Train accuracy: 0.9286\n",
      "Test loss : 0.6019 | Test accuracy : 0.8700\n",
      "----------------------------------------------------------------\n",
      "Epoch 205\n",
      "Train loss: 0.3006 | Train accuracy: 0.9100\n",
      "Test loss : 0.5578 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 206\n",
      "Train loss: 0.2780 | Train accuracy: 0.9200\n",
      "Test loss : 0.5006 | Test accuracy : 0.8833\n",
      "----------------------------------------------------------------\n",
      "Epoch 207\n",
      "Train loss: 0.2863 | Train accuracy: 0.9257\n",
      "Test loss : 0.5911 | Test accuracy : 0.8733\n",
      "----------------------------------------------------------------\n",
      "Epoch 208\n",
      "Train loss: 0.4106 | Train accuracy: 0.8829\n",
      "Test loss : 0.6838 | Test accuracy : 0.8433\n",
      "----------------------------------------------------------------\n",
      "Epoch 209\n",
      "Train loss: 0.3311 | Train accuracy: 0.9086\n",
      "Test loss : 0.5522 | Test accuracy : 0.8700\n",
      "----------------------------------------------------------------\n",
      "Epoch 210\n",
      "Train loss: 0.3336 | Train accuracy: 0.8986\n",
      "Test loss : 0.5156 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 211\n",
      "Train loss: 0.3317 | Train accuracy: 0.9014\n",
      "Test loss : 0.5875 | Test accuracy : 0.8600\n",
      "----------------------------------------------------------------\n",
      "Epoch 212\n",
      "Train loss: 0.3271 | Train accuracy: 0.9029\n",
      "Test loss : 0.6143 | Test accuracy : 0.8400\n",
      "----------------------------------------------------------------\n",
      "Epoch 213\n",
      "Train loss: 0.3338 | Train accuracy: 0.9014\n",
      "Test loss : 0.5849 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 214\n",
      "Train loss: 0.3470 | Train accuracy: 0.9057\n",
      "Test loss : 0.6791 | Test accuracy : 0.8600\n",
      "----------------------------------------------------------------\n",
      "Epoch 215\n",
      "Train loss: 0.3845 | Train accuracy: 0.9000\n",
      "Test loss : 0.7369 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 216\n",
      "Train loss: 0.3202 | Train accuracy: 0.9200\n",
      "Test loss : 0.6115 | Test accuracy : 0.8833\n",
      "----------------------------------------------------------------\n",
      "Epoch 217\n",
      "Train loss: 0.3054 | Train accuracy: 0.9057\n",
      "Test loss : 0.5702 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 218\n",
      "Train loss: 0.2831 | Train accuracy: 0.9186\n",
      "Test loss : 0.5336 | Test accuracy : 0.8800\n",
      "----------------------------------------------------------------\n",
      "Epoch 219\n",
      "Train loss: 0.2732 | Train accuracy: 0.9200\n",
      "Test loss : 0.4982 | Test accuracy : 0.8833\n",
      "----------------------------------------------------------------\n",
      "Epoch 220\n",
      "Train loss: 0.2956 | Train accuracy: 0.9100\n",
      "Test loss : 0.5574 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 221\n",
      "Train loss: 0.3011 | Train accuracy: 0.9257\n",
      "Test loss : 0.6029 | Test accuracy : 0.8733\n",
      "----------------------------------------------------------------\n",
      "Epoch 222\n",
      "Train loss: 0.2838 | Train accuracy: 0.9100\n",
      "Test loss : 0.5410 | Test accuracy : 0.8533\n",
      "----------------------------------------------------------------\n",
      "Epoch 223\n",
      "Train loss: 0.2792 | Train accuracy: 0.9129\n",
      "Test loss : 0.5677 | Test accuracy : 0.8533\n",
      "----------------------------------------------------------------\n",
      "Epoch 224\n",
      "Train loss: 0.2510 | Train accuracy: 0.9214\n",
      "Test loss : 0.5146 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 225\n",
      "Train loss: 0.5079 | Train accuracy: 0.8571\n",
      "Test loss : 0.8333 | Test accuracy : 0.8200\n",
      "----------------------------------------------------------------\n",
      "Epoch 226\n",
      "Train loss: 0.3183 | Train accuracy: 0.9214\n",
      "Test loss : 0.6162 | Test accuracy : 0.8767\n",
      "----------------------------------------------------------------\n",
      "Epoch 227\n",
      "Train loss: 0.2784 | Train accuracy: 0.9257\n",
      "Test loss : 0.5795 | Test accuracy : 0.8800\n",
      "----------------------------------------------------------------\n",
      "Epoch 228\n",
      "Train loss: 0.2659 | Train accuracy: 0.9271\n",
      "Test loss : 0.5197 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 229\n",
      "Train loss: 0.2782 | Train accuracy: 0.9014\n",
      "Test loss : 0.5152 | Test accuracy : 0.8633\n",
      "----------------------------------------------------------------\n",
      "Epoch 230\n",
      "Train loss: 0.2604 | Train accuracy: 0.9100\n",
      "Test loss : 0.4872 | Test accuracy : 0.8700\n",
      "----------------------------------------------------------------\n",
      "Epoch 231\n",
      "Train loss: 0.2674 | Train accuracy: 0.9257\n",
      "Test loss : 0.5717 | Test accuracy : 0.8833\n",
      "----------------------------------------------------------------\n",
      "Epoch 232\n",
      "Train loss: 0.3370 | Train accuracy: 0.8971\n",
      "Test loss : 0.5975 | Test accuracy : 0.8467\n",
      "----------------------------------------------------------------\n",
      "Epoch 233\n",
      "Train loss: 0.3346 | Train accuracy: 0.9071\n",
      "Test loss : 0.6086 | Test accuracy : 0.8567\n",
      "----------------------------------------------------------------\n",
      "Epoch 234\n",
      "Train loss: 0.4886 | Train accuracy: 0.8743\n",
      "Test loss : 0.8913 | Test accuracy : 0.8333\n",
      "----------------------------------------------------------------\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Retrieve study\n",
    "study = optuna.load_study(study_name=\"study_20241126-163837\", storage=OPTUNA_STORAGE)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "hidden_size = best_params['hidden_size']\n",
    "n_layers = best_params['n_layers']\n",
    "model = LSTMClassifier(num_features, hidden_size, 1, n_layers).to(device)\n",
    "\n",
    "lr = best_params['lr']\n",
    "optimizer_name = best_params['optimizer']\n",
    "optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "batch_size = best_params['batch_size']\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor(weights[1], dtype=torch.float32)\n",
    ")\n",
    "\n",
    "epochs = best_params['n_epochs']\n",
    "trained_model, y_train_accs, train_losses, y_test_accs, test_losses = train_validate_loop(\n",
    "    model, train_loader, test_loader, optimizer, loss_fn, epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features mean: tensor([0.9415, 1.0184, 1.0015, 0.9243])\n",
      "Test  features mean: tensor([0.9180, 1.0102, 0.9695, 0.9264])\n",
      "\n",
      "Sum of differences: 0.06566202640533447\n"
     ]
    }
   ],
   "source": [
    "trained_model.to('cpu')\n",
    "\n",
    "y_test_pred = trained_model(X_test_tensor)\n",
    "y_test_pred = predict(y_test_pred, loss_fn).squeeze()\n",
    "\n",
    "train_features_mean = get_features_mean(X_train_tensor, y_train_tensor)\n",
    "test_features_mean  = get_features_mean(X_test_tensor , y_test_pred)\n",
    "\n",
    "print(f\"Train features mean: {train_features_mean}\")\n",
    "print(f\"Test  features mean: {test_features_mean}\")\n",
    "print()\n",
    "print(f\"Sum of differences: {sum(abs(train_features_mean - test_features_mean))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_plot(y_test_tensor, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TrabajoFinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
