{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jaea6ppoSYFx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/bbas/.pyenv/versions/tf/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import optuna\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from constants import *\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from optuna.visualization import plot_pareto_front\n",
    "from optuna.study import MaxTrialsCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.load_data import *\n",
    "from utils.train_predict import train_step, validate_step, validate_step_with_metrics, predict\n",
    "from utils.metrics import *\n",
    "from utils.optuna_utils import *\n",
    "from utils.mlflow_logger import MLflowLogger\n",
    "\n",
    "from models.instantiate import instantiate_model\n",
    "from models.lstm_v1 import *\n",
    "from models.lstm_v2 import *\n",
    "from models.gru import *\n",
    "from models.dense import *\n",
    "from models.fcn import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(13)\n",
    "torch.manual_seed(13)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group': '1',\n",
      " 'simulation': '1',\n",
      " 'required_periods': 49,\n",
      " 'model_arch': 'lstm_v1',\n",
      " 'metrics': ['f1_score'],\n",
      " 'directions': ['maximize'],\n",
      " 'beta': 0.5,\n",
      " 'log_to_mlflow': 'False'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pprint.pp(config)\n",
    "\n",
    "# PARTITIONS = config['partitions']\n",
    "GROUP = \"Grupo\" + config['group']\n",
    "SIMULATION = \"Simulacion\" + config['simulation']\n",
    "REQ_PERIODS = config['required_periods']\n",
    "METRICS = config['metrics']\n",
    "DIRECTIONS = config['directions']\n",
    "BETA = config['beta']\n",
    "MODEL_ARCH = config['model_arch']\n",
    "LOG_TO_MLFLOW = (config['log_to_mlflow'] == \"True\")\n",
    "\n",
    "TEMP_FEATS = [f'y(t-{i})' for i in range(REQ_PERIODS, 0, -1)]\n",
    "STAT_FEATS = ['inicio_prog']\n",
    "FEATS = STAT_FEATS + TEMP_FEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log to MLflow: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Log to MLflow: {LOG_TO_MLFLOW}\")\n",
    "mlflow_logger = MLflowLogger(\n",
    "    LOG_TO_MLFLOW,\n",
    "    TRACKING_SERVER_URI,\n",
    "    EXPERIMENT_NAME,\n",
    "    EXPERIMENT_TAGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_DIR = os.path.join(DATA_DIR, GROUP)\n",
    "GROUP_PARAMS_FILE = os.path.join(GROUP_DIR, f\"params_{GROUP}.json\")\n",
    "if os.path.exists(GROUP_PARAMS_FILE):\n",
    "    with open(GROUP_PARAMS_FILE, 'r') as f:\n",
    "        group_params = json.load(f)\n",
    "        mlflow_logger.log_params(group_params)\n",
    "else:\n",
    "    print(f\"Group params file not found: {GROUP_PARAMS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stata_filepath = os.path.join(GROUP_DIR, SIMULATION + \".dta\")\n",
    "if os.path.exists(stata_filepath):\n",
    "    df = pd.read_stata(stata_filepath)\n",
    "else:\n",
    "    print(f\"File {stata_filepath} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "    simcase  id   t          y  inicio_prog       y_cf  tipo\n",
      "0         1   0   0  24.825693           49  24.825693   1.0\n",
      "1         1   0   1  26.186628           49  26.186628   1.0\n",
      "2         1   0   2  21.617460           49  21.617460   1.0\n",
      "3         1   0   3  23.110544           49  23.110544   1.0\n",
      "4         1   0   4  20.305117           49  20.305117   1.0\n",
      "5         1   0   5  14.850212           49  14.850212   1.0\n",
      "6         1   0   6  12.631165           49  12.631165   1.0\n",
      "7         1   0   7  11.932540           49  11.932540   1.0\n",
      "8         1   0   8   8.873283           49   8.873283   1.0\n",
      "9         1   0   9   7.075806           49   7.075806   1.0\n",
      "10        1   0  10   5.439288           49   5.439288   1.0\n",
      "11        1   0  11   9.297968           49   9.297968   1.0\n",
      "12        1   0  12   6.207757           49   6.207757   1.0\n",
      "13        1   0  13  10.678605           49  10.678605   1.0\n",
      "14        1   0  14   5.096826           49   5.096826   1.0\n",
      "15        1   0  15  -0.222429           49  -0.222429   1.0\n",
      "16        1   0  16  -2.027132           49  -2.027132   1.0\n",
      "17        1   0  17  -0.238938           49  -0.238938   1.0\n",
      "18        1   0  18  -1.594284           49  -1.594284   1.0\n",
      "19        1   0  19  -5.884704           49  -5.884704   1.0\n",
      "20        1   0  20   6.601670           49   6.601670   1.0\n",
      "21        1   0  21   1.491696           49   1.491696   1.0\n",
      "22        1   0  22   5.654326           49   5.654326   1.0\n",
      "23        1   0  23   4.670912           49   4.670912   1.0\n",
      "24        1   0  24   6.546967           49   6.546967   1.0\n",
      "25        1   0  25   9.787612           49   9.787612   1.0\n",
      "26        1   0  26  10.549369           49  10.549369   1.0\n",
      "27        1   0  27  11.153814           49  11.153814   1.0\n",
      "28        1   0  28   5.792342           49   5.792342   1.0\n",
      "29        1   0  29   5.471733           49   5.471733   1.0\n",
      "30        1   0  30  10.661984           49  10.661984   1.0\n",
      "31        1   0  31  12.814376           49  12.814376   1.0\n",
      "32        1   0  32  13.625093           49  13.625093   1.0\n",
      "33        1   0  33  13.667446           49  13.667446   1.0\n",
      "34        1   0  34  20.154083           49  20.154083   1.0\n",
      "35        1   0  35  24.360769           49  24.360769   1.0\n",
      "36        1   0  36  26.312677           49  26.312677   1.0\n",
      "37        1   0  37  28.947466           49  28.947466   1.0\n",
      "38        1   0  38  29.564219           49  29.564219   1.0\n",
      "39        1   0  39  37.365261           49  37.365261   1.0\n",
      "40        1   0  40  37.919163           49  37.919163   1.0\n",
      "41        1   0  41  39.374371           49  39.374371   1.0\n",
      "42        1   0  42  40.731876           49  40.731876   1.0\n",
      "43        1   0  43  43.361568           49  43.361568   1.0\n",
      "44        1   0  44  43.519379           49  43.519379   1.0\n",
      "45        1   0  45  51.624718           49  51.624718   1.0\n",
      "46        1   0  46  63.779907           49  63.779907   1.0\n",
      "47        1   0  47  68.983040           49  68.983040   1.0\n",
      "48        1   0  48  73.639137           49  73.639137   1.0\n",
      "49        1   0  49  71.433617           49  64.920998   1.0\n",
      "50        1   0  50  66.078590           49  59.064751   1.0\n",
      "51        1   0  51  57.553009           49  52.478741   1.0\n",
      "52        1   0  52  54.317566           49  48.919392   1.0\n",
      "53        1   0  53  53.794765           49  48.626495   1.0\n",
      "54        1   0  54  57.620438           49  53.376068   1.0\n",
      "55        1   0  55  58.538826           49  54.152103   1.0\n",
      "56        1   0  56  52.550125           49  47.583153   1.0\n",
      "57        1   0  57  58.744598           49  52.922901   1.0\n",
      "58        1   0  58  56.846916           49  51.896362   1.0\n",
      "59        1   0  59  52.356464           49  47.959267   1.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_stata(stata_filepath)\n",
    "type1 = df[df['tipo'] == 1]\n",
    "id0 = next(iter(type1.groupby('id')))\n",
    "# print(type(id0[0]))\n",
    "# print(id0[0])\n",
    "print(type(id0[1]))\n",
    "print(id0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PlHQsGhFSYF1"
   },
   "outputs": [],
   "source": [
    "mlflow_logger.log_params({\n",
    "    \"group\": GROUP,\n",
    "    \"simulation\": SIMULATION,\n",
    "    \"filepath\": stata_filepath,\n",
    "    \"required_periods\": REQ_PERIODS\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conjuntos de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5v_3f_FDqHc"
   },
   "source": [
    "**Terminología**:\n",
    "* Tipo 1: individuos tratados.\n",
    "* Tipo 2: individuos de control (i.e. podrían haber sido tratados pero por alguna razón no lo fueron)\n",
    "* Tipo 3: ni tratados ni de control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Separamos en tipo 1, tipo 2 y tipo 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "sjGpNBoTSYF2",
    "outputId": "a11baa73-7e16-4a5f-a30f-bb37905a19a7"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tratado'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/tf/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'tratado'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m type1_df, type2_df, type3_df = \u001b[43mget_dfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mREQ_PERIODS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Chequeo para asegurarnos que los que tienen target 1 de tipo 2 se corresponden\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# con el inicio_prog de la base original\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m(\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mall\u001b[39m(\n\u001b[32m      7\u001b[39m         type2_df[type2_df[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33minicio_prog\u001b[39m\u001b[33m'\u001b[39m] == \n\u001b[32m      8\u001b[39m         df[df[\u001b[33m'\u001b[39m\u001b[33mtipo\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m2\u001b[39m].groupby(\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33minicio_prog\u001b[39m\u001b[33m'\u001b[39m].first()\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TrabajoFinal/repo/Experimentos/utils/load_data.py:55\u001b[39m, in \u001b[36mget_dfs\u001b[39m\u001b[34m(data, required_periods)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_dfs\u001b[39m(data, required_periods=\u001b[32m4\u001b[39m):\n\u001b[32m     54\u001b[39m     type1_data = data[data[\u001b[33m'\u001b[39m\u001b[33mtipo\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     type1_df = \u001b[43mtransform_treated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype1_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_periods\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     type2_data = data[data[\u001b[33m'\u001b[39m\u001b[33mtipo\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m2\u001b[39m]\n\u001b[32m     58\u001b[39m     min_start = type1_df[\u001b[33m'\u001b[39m\u001b[33minicio_prog\u001b[39m\u001b[33m'\u001b[39m].min()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TrabajoFinal/repo/Experimentos/utils/load_data.py:26\u001b[39m, in \u001b[36mtransform_treated\u001b[39m\u001b[34m(treated_data, required_periods)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, individual \u001b[38;5;129;01min\u001b[39;00m treated_data.groupby(\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     25\u001b[39m     start = individual[\u001b[33m'\u001b[39m\u001b[33minicio_prog\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     row = \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindividual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_periods\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     transformed_treated.append(row)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(transformed_treated)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TrabajoFinal/repo/Experimentos/utils/load_data.py:13\u001b[39m, in \u001b[36mtransform\u001b[39m\u001b[34m(individual_data, start, required_periods, is_control)\u001b[39m\n\u001b[32m      7\u001b[39m periods = individual_data[periods.between(start-required_periods, start-\u001b[32m1\u001b[39m)]\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(periods) == required_periods:\n\u001b[32m     10\u001b[39m     row = {\n\u001b[32m     11\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m: individual_data[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m],\n\u001b[32m     12\u001b[39m         \u001b[33m'\u001b[39m\u001b[33minicio_prog\u001b[39m\u001b[33m'\u001b[39m: start,\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtratado\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mindividual_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtratado\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.iloc[\u001b[32m0\u001b[39m],\n\u001b[32m     14\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcontrol\u001b[39m\u001b[33m'\u001b[39m: individual_data[\u001b[33m'\u001b[39m\u001b[33mcontrol\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_control \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_control,\n\u001b[32m     15\u001b[39m     }\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(required_periods):\n\u001b[32m     17\u001b[39m         row[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my(t-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequired_periods-i\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m] = periods[\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m].values[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/tf/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/tf/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'tratado'"
     ]
    }
   ],
   "source": [
    "type1_df, type2_df, type3_df = get_dfs(df, REQ_PERIODS)\n",
    "\n",
    "# Chequeo para asegurarnos que los que tienen target 1 de tipo 2 se corresponden\n",
    "# con el inicio_prog de la base original\n",
    "assert(\n",
    "    all(\n",
    "        type2_df[type2_df['target'] == 1]['inicio_prog'] == \n",
    "        df[df['tipo'] == 2].groupby('id')['inicio_prog'].first()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cantidad de inicios de programa. Esto nos dice cuántos duplicados hay de cada\n",
    "# individuo de tipo 2y tipo 3.\n",
    "min_inicio_prog = type1_df['inicio_prog'].min()\n",
    "max_inicio_prog = type1_df['inicio_prog'].max()\n",
    "amount_inicio_prog = max_inicio_prog - min_inicio_prog + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Separamos en train (que es sobre el que despues se va a hacer KFold) y test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de individuos de cada tipo (con los duplicados)\n",
    "n1 = len(type1_df)\n",
    "n2 = len(type2_df)\n",
    "n3 = len(type3_df)\n",
    "\n",
    "# Cantidad total de individuos en el dataset POST-TRANSFORMACION. Estas son las\n",
    "# muestras que se van a usar en el proceso de entrenamiento y testing, por eso\n",
    "# se tienen en cuenta los duplicados.\n",
    "n = n1 + n2 + n3\n",
    "\n",
    "# Tamaño de los conjuntos de entrenamiento y testeo\n",
    "train_size = int(0.7 * n)\n",
    "test_size = n - train_size\n",
    "\n",
    "# En type2_df y type3_df, tenemos el mismo individuo pero con distinto inicio_prog\n",
    "# y por lo tanto distintos valores de y(t-1), y(t-2), ..., y(t-required_periods)\n",
    "# Lo que queremos es que todas las \"copias\" de un mismo individuo estén o todas\n",
    "# en train o todas en test. Por lo tanto, la selección no va a ser sobre filas\n",
    "# del dataframe sino sobre ids de individuos.\n",
    "type3_ids = type3_df.index.unique()\n",
    "\n",
    "# Todos los individuos de tipo 1 van al conjunto de entrenamiento, y los restantes\n",
    "# son de tipo 3 elegidos al azar\n",
    "# Dividimos por amount_inicio_prog porque vamos a seleccionar ids de individuos\n",
    "# de tipo 3, no filas\n",
    "# type3_train = int((train_size - n1) / amount_inicio_prog)\n",
    "n_type3_train = 1000\n",
    "\n",
    "# Ahora sí, seleccionamos aleatoriamente n3_train ids de individuos de tipo 3\n",
    "# para el conjunto de entrenamiento\n",
    "type3_train = np.random.choice(type3_ids, n_type3_train, replace=False)\n",
    "\n",
    "# Y nos quedamos con las filas del dataframe de tipo 3 que tienen los ids seleccionados\n",
    "type3_train_df = type3_df.loc[type3_train]\n",
    "\n",
    "# Los ids que no están en type3_train son para el conjunto de testeo\n",
    "n_type3_test = 500\n",
    "type3_test = list(set(type3_ids) - set(type3_train))\n",
    "type3_test = np.random.choice(type3_test, n_type3_test, replace=False)\n",
    "type3_test_df = type3_df.loc[type3_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([type1_df, type3_train_df])\n",
    "X_train_df, y_train_df = train_df[FEATS], train_df['target']\n",
    "smote = SMOTE(sampling_strategy=0.6, k_neighbors=5, random_state=13)\n",
    "X_train_df, y_train_df = smote.fit_resample(X_train_df, y_train_df)\n",
    "\n",
    "test_df = pd.concat([type2_df, type3_test_df])\n",
    "X_test_df, y_test_df = test_df[FEATS], test_df['target']\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(y_train_df), y=y_train_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.value_counts() / len(y_train_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.value_counts() / len(y_test_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.Estandarizamos ambos conjuntos en base a los datos de entrenamiento.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessor = DataPreprocessor(X_train_df, X_test_df, y_train_df, y_test_df)\n",
    "\n",
    "X_train_df_scaled, X_test_df_scaled = data_preprocessor.scale_data()\n",
    "X_train_df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Logueamos los datasets finales a MLFlow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build the datasets with the target column to load them into mlflow\n",
    "train_df = X_train_df_scaled.copy()\n",
    "train_df['target'] = y_train_df\n",
    "mlflow_logger.log_input(train_df, \"train\")\n",
    "\n",
    "test_df = X_test_df_scaled.copy()\n",
    "test_df['target'] = y_test_df\n",
    "mlflow_logger.log_input(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Obtenemos estructura necesaria según la red que querramos usar y construimos Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data_preprocessor.build_datasets(\n",
    "    MODEL_ARCH, TEMP_FEATS, STAT_FEATS, scale=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kptxCJGX-Swv"
   },
   "source": [
    "# **Búsqueda de hiperparámetros con Optuna**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Dejamos seleccionado el constructor de modelo para la búsqueda de hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match MODEL_ARCH:\n",
    "    case \"lstm_v1\":\n",
    "        define_model = define_lstm_v1_model\n",
    "    case \"lstm_v2\":\n",
    "        define_model = define_lstm_v2_model\n",
    "    case \"gru\":\n",
    "        define_model = define_gru_model\n",
    "    case \"dense\":\n",
    "        define_model = define_dense_model\n",
    "    case \"fcn\":\n",
    "        define_model = define_fcn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Definimos los parámetros de la búsqueda de hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "study_name = f\"study_{timestamp}\"\n",
    "study_n_trials = 30\n",
    "\n",
    "if len(METRICS) != len(DIRECTIONS):\n",
    "    raise ValueError(\"The number of metrics and directions should be the same\")\n",
    "\n",
    "mlflow_logger.log_params({\n",
    "    \"optuna_study_name\": study_name,\n",
    "    \"optuna_study_n_trials\": study_n_trials,\n",
    "    \"objective_metrics\": METRICS,\n",
    "    \"directions\": DIRECTIONS\n",
    "})\n",
    "\n",
    "if \"f_beta_score\" in METRICS:\n",
    "    mlflow_logger.log_param(\"f_beta_score\", BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=DIRECTIONS[0] if len(METRICS) == 1 else None,\n",
    "    directions=DIRECTIONS if len(METRICS) > 1 else None,\n",
    "    storage=OPTUNA_STORAGE,\n",
    "    study_name=study_name\n",
    ")\n",
    "study.set_metric_names(METRICS)\n",
    "\n",
    "study.optimize(\n",
    "    lambda trial: objective_cv(\n",
    "        trial, define_model, train_set, weights, METRICS, beta=BETA\n",
    "    ),\n",
    "    n_trials=20,\n",
    "    timeout=600,\n",
    "    n_jobs=-1,\n",
    "    callbacks=[MaxTrialsCallback(study_n_trials, states=(TrialState.COMPLETE,))],\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(METRICS) > 1:\n",
    "    print(f\"Number of trials on the Pareto front: {len(study.best_trials)}\")\n",
    "    for i, (metric, direction) in enumerate(zip(METRICS, DIRECTIONS)):\n",
    "        if direction == 'maximize':\n",
    "            best_trial = max(study.best_trials, key=lambda t: t.values[i])\n",
    "        elif direction == 'minimize':\n",
    "            best_trial = min(study.best_trials, key=lambda t: t.values[i])\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"\\tDirection: {direction}\")\n",
    "        print(f\"\\tTrial number: {best_trial.number}\")\n",
    "        print(f\"\\tValues: {best_trial.values}\")\n",
    "        print(f\"\\tParams: {best_trial.params}\")\n",
    "    \n",
    "    fig = plot_pareto_front(study, target_names=METRICS)\n",
    "    mlflow_logger.log_plot(fig, \"pareto_front_plot.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials_info = get_best_trials_info(study, METRICS)\n",
    "best_trials_numbers = [trial['trial_number'] for trial in best_trials_info]\n",
    "pprint.pp(f\"Best trials info: {best_trials_info}\")\n",
    "pprint.pp(f\"Best trials numbers: {best_trials_numbers}\")\n",
    "\n",
    "mlflow_logger.log_json(best_trials_info, \"best_trials_info.json\")\n",
    "mlflow_logger.log_params({\n",
    "    \"best_trials_numbers\": best_trials_numbers\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(best_trials_numbers) == 1:\n",
    "    selected_trial = best_trials_numbers[0]\n",
    "else:\n",
    "    selected_trial = select_trial(best_trials_numbers)\n",
    "\n",
    "mlflow_logger.log_param(\"selected_trial_number\", selected_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrenamiento del modelo con mejores hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.trials[selected_trial].params\n",
    "\n",
    "model = instantiate_model(MODEL_ARCH, params)\n",
    "mlflow_logger.log_model_architecture(model)\n",
    "\n",
    "# Common parameters for all models\n",
    "epochs = params['n_epochs']\n",
    "\n",
    "# optimizer_name and lr parameters are for specifying the optimizer\n",
    "optimizer_name = params['optimizer']\n",
    "lr = params['lr']\n",
    "optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "# batch_size is for the training loop\n",
    "batch_size = params['batch_size']\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True , num_workers=4)\n",
    "test_loader  = DataLoader(test_set , batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(weights[1], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {epoch} -----------------------------------------------------\")\n",
    "    avg_batch_loss_train = train_step(model, train_loader, loss_fn, optimizer)\n",
    "    print(f\"Average batch loss during training: {avg_batch_loss_train}\")\n",
    "\n",
    "    avg_batch_loss_test = validate_step(model, test_loader, loss_fn)\n",
    "    print(f\"Average batch loss during testing: {avg_batch_loss_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in tqdm(range(epochs)):\n",
    "#     print(f\"Epoch {epoch} -----------------------------------------------------\")\n",
    "#     avg_batch_loss_train = train_step(model, train_loader, loss_fn, optimizer)\n",
    "#     print(f\"Average batch loss during training: {avg_batch_loss_train}\")\n",
    "\n",
    "#     avg_batch_loss_test = validate_step(model, test_loader, loss_fn)\n",
    "#     print(f\"Average batch loss during testing: {avg_batch_loss_test}\")\n",
    "\n",
    "#     metrics_values = validate_step_with_metrics(\n",
    "#         model,\n",
    "#         X_test_tensor,\n",
    "#         y_test_tensor,\n",
    "#         loss_fn,\n",
    "#         METRICS,\n",
    "#         beta=BETA,\n",
    "#         train_features_mean=None\n",
    "#     )\n",
    "#     pprint.pp(metrics_values)\n",
    "#     mlflow_logger.log_metrics(metrics_values, step=epoch)\n",
    "\n",
    "# mlflow.pytorch.log_model(model, \"trained_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluación del modelo entrenado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor, y_train_tensor = train_set.tensors\n",
    "X_test_tensor, y_test_tensor = test_set.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "y_test_pred = model(X_test_tensor.to('cpu'))\n",
    "y_test_pred = predict(y_test_pred, loss_fn).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = confusion_matrix_plot(y_test_tensor, y_test_pred)\n",
    "mlflow_logger.log_plot(fig, \"confusion_matrix_plot.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_plot(y_test_tensor, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_logger.end_run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
