{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaea6ppoSYFx"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.exceptions\n",
    "import optuna\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from constants import *\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from optuna.visualization import plot_pareto_front, plot_intermediate_values\n",
    "from optuna.study import MaxTrialsCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils.data_classes import TemporalStaticDataset\n",
    "from utils.load_data import *\n",
    "from utils.train_predict import train_step, validate_step_with_metrics, predict\n",
    "from utils.metrics import *\n",
    "from utils.optuna_utils import *\n",
    "from utils.mlflow_utils import *\n",
    "\n",
    "from models.lstm_v1 import *\n",
    "from models.lstm_v2 import *\n",
    "from models.gru import *\n",
    "from models.dense import *\n",
    "from models.fcn import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(13)\n",
    "torch.manual_seed(13)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(TRACKING_SERVER_URI)\n",
    "try:\n",
    "    mlflow.create_experiment(name=EXPERIMENT_NAME, tags=EXPERIMENT_TAGS)\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(e)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "run = set_active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# PARTITIONS = config['partitions']\n",
    "GROUP = config['group']\n",
    "SIMULATION = config['simulation']\n",
    "REQ_PERIODS = config['required_periods']\n",
    "METRICS = config['metrics']\n",
    "DIRECTIONS = config['directions']\n",
    "BETA = config['beta']\n",
    "MODEL_ARCH = config['model_arch']\n",
    "\n",
    "TEMP_FEATS = [f'y(t-{i})' for i in range(REQ_PERIODS, 0, -1)]\n",
    "STAT_FEATS = ['inicio_prog']\n",
    "FEATS = STAT_FEATS + TEMP_FEATS\n",
    "\n",
    "stata_filepath = os.path.join(DATA_DIR, GROUP, SIMULATION)\n",
    "df = pd.read_stata(stata_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlHQsGhFSYF1"
   },
   "outputs": [],
   "source": [
    "mlflow.log_params({\n",
    "    \"group\": GROUP,\n",
    "    \"simulation\": SIMULATION,\n",
    "    \"filepath\": stata_filepath,\n",
    "    \"required_periods\": REQ_PERIODS\n",
    "    # \"partitions\": PARTITIONS\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conjuntos de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5v_3f_FDqHc"
   },
   "source": [
    "**Terminología**:\n",
    "* Tipo 1: individuos tratados.\n",
    "* Tipo 2: individuos de control (i.e. podrían haber sido tratados pero por alguna razón no lo fueron)\n",
    "* Tipo 3: ni tratados ni de control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Separamos en tipo 1, tipo 2 y tipo 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "sjGpNBoTSYF2",
    "outputId": "a11baa73-7e16-4a5f-a30f-bb37905a19a7"
   },
   "outputs": [],
   "source": [
    "type1_df, type2_df, type3_df = get_dfs(df, REQ_PERIODS)\n",
    "\n",
    "# Chequeo para asegurarnos que los que tienen target 1 de tipo 2 se corresponden\n",
    "# con el inicio_prog de la base original\n",
    "assert(\n",
    "    all(\n",
    "        type2_df[type2_df['target'] == 1]['inicio_prog'] == \n",
    "        df[df['tipo'] == 2].groupby('id')['inicio_prog'].first()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cantidad de inicios de programa. Esto nos dice cuántos duplicados hay de cada\n",
    "# individuo de tipo 2y tipo 3.\n",
    "min_inicio_prog = type1_df['inicio_prog'].min()\n",
    "max_inicio_prog = type1_df['inicio_prog'].max()\n",
    "amount_inicio_prog = max_inicio_prog - min_inicio_prog + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Separamos en train (que es sobre el que despues se va a hacer KFold) y test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de individuos de cada tipo (con los duplicados)\n",
    "n1 = len(type1_df)\n",
    "n2 = len(type2_df)\n",
    "n3 = len(type3_df)\n",
    "\n",
    "# Cantidad total de individuos en el dataset POST-TRANSFORMACION. Estas son las\n",
    "# muestras que se van a usar en el proceso de entrenamiento y testing, por eso\n",
    "# se tienen en cuenta los duplicados.\n",
    "n = n1 + n2 + n3\n",
    "\n",
    "# Tamaño de los conjuntos de entrenamiento y testeo\n",
    "train_size = int(0.7 * n)\n",
    "test_size = n - train_size\n",
    "\n",
    "# En type2_df y type3_df, tenemos el mismo individuo pero con distinto inicio_prog\n",
    "# y por lo tanto distintos valores de y(t-1), y(t-2), ..., y(t-required_periods)\n",
    "# Lo que queremos es que todas las \"copias\" de un mismo individuo estén o todas\n",
    "# en train o todas en test. Por lo tanto, la selección no va a ser sobre filas\n",
    "# del dataframe sino sobre ids de individuos.\n",
    "type3_ids = type3_df.index.unique()\n",
    "\n",
    "# Todos los individuos de tipo 1 van al conjunto de entrenamiento, y los restantes\n",
    "# son de tipo 3 elegidos al azar\n",
    "# Dividimos por amount_inicio_prog porque vamos a seleccionar ids de individuos\n",
    "# de tipo 3, no filas\n",
    "# type3_train = int((train_size - n1) / amount_inicio_prog)\n",
    "n_type3_train = 1000\n",
    "\n",
    "# Ahora sí, seleccionamos aleatoriamente n3_train ids de individuos de tipo 3\n",
    "# para el conjunto de entrenamiento\n",
    "type3_train = np.random.choice(type3_ids, n_type3_train, replace=False)\n",
    "\n",
    "# Y nos quedamos con las filas del dataframe de tipo 3 que tienen los ids seleccionados\n",
    "type3_train_df = type3_df.loc[type3_train]\n",
    "\n",
    "# Los ids que no están en type3_train son para el conjunto de testeo\n",
    "n_type3_test = 500\n",
    "type3_test = list(set(type3_ids) - set(type3_train))\n",
    "type3_test = np.random.choice(type3_test, n_type3_test, replace=False)\n",
    "type3_test_df = type3_df.loc[type3_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([type1_df, type3_train_df])\n",
    "X_train_df, y_train_df = train_df[FEATS], train_df['target']\n",
    "smote = SMOTE(sampling_strategy=0.6, k_neighbors=5, random_state=13)\n",
    "X_train_df, y_train_df = smote.fit_resample(X_train_df, y_train_df)\n",
    "\n",
    "test_df = pd.concat([type2_df, type3_test_df])\n",
    "X_test_df, y_test_df = test_df[FEATS], test_df['target']\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(y_train_df), y=y_train_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.value_counts() / len(y_train_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.value_counts() / len(y_test_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.Estandarizamos ambos conjuntos en base a los datos de entrenamiento.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_df)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_df)\n",
    "X_train_df_scaled = pd.DataFrame(\n",
    "    X_train_scaled, columns=X_train_df.columns, index=X_train_df.index\n",
    ")\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test_df)\n",
    "X_test_df_scaled = pd.DataFrame(\n",
    "    X_test_scaled, columns=X_test_df.columns, index=X_test_df.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Logueamos los datasets finales a MLFlow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build the datasets with the target column to load them into mlflow\n",
    "train_df = X_train_df_scaled.copy()\n",
    "train_df['target'] = y_train_df\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(train_df, targets='target'),\n",
    "    context=\"train\",\n",
    ")\n",
    "\n",
    "test_df = X_test_df_scaled.copy()\n",
    "test_df['target'] = y_test_df\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(test_df, targets='target'),\n",
    "    context=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Obtenemos estructura necesaria según la red que querramos usar y construimos Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basados en el documento `docs/lstm.md`, transformemos los datos que tenemos a la forma que necesitan las LSTM: `(batch_size, sequence_length, num_features)`.\n",
    "\n",
    "Cada fila es un individuo y en cada fila ya tenemos todo lo que necesitamos, los 4 datos temporales (`y(t-4)`, `y(t-3)`, `y(t-2)`, `y(t-1)`) y además el dato estático (`inicio_prog`) que lo vamos a tener que repetir cuatro veces para tener la dimensión que deseamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels should be of type float32 if using BCEWithLogitsLoss\n",
    "# labels should be of type long if using CrossEntropyLoss\n",
    "y_train_tensor = torch.tensor(y_train_df.values, dtype=torch.float32)\n",
    "y_test_tensor  = torch.tensor(y_test_df.values , dtype=torch.float32)\n",
    "\n",
    "if any(keyword in MODEL_ARCH for keyword in ['rnn', 'gru', 'lstm_v1']):\n",
    "    num_features = 2\n",
    "    X_train_tensor = get_lstm_input(X_train_df_scaled, TEMP_FEATS, STAT_FEATS)\n",
    "    X_test_tensor  = get_lstm_input(X_test_df_scaled , TEMP_FEATS, STAT_FEATS)\n",
    "    train_set = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_set  = TensorDataset(X_test_tensor , y_test_tensor)\n",
    "\n",
    "elif 'dense' in MODEL_ARCH:\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    X_test_tensor  = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    train_set = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_set  = TensorDataset(X_test_tensor , y_test_tensor)\n",
    "\n",
    "elif any(keyword in MODEL_ARCH for keyword in ['lstm_v2', 'fcn']):\n",
    "    X_train_temp_tensor = get_lstm_input(X_train_df_scaled, TEMP_FEATS)\n",
    "    X_test_temp_tensor  = get_lstm_input(X_test_df_scaled , TEMP_FEATS)\n",
    "    X_train_static_tensor = torch.tensor(\n",
    "        X_train_df['inicio_prog'].values, dtype=torch.float32\n",
    "    ).view(-1, 1)\n",
    "    X_test_static_tensor  = torch.tensor(\n",
    "        X_test_df['inicio_prog'].values , dtype=torch.float32\n",
    "    ).view(-1, 1)\n",
    "    train_set = TemporalStaticDataset(\n",
    "        X_train_temp_tensor, X_train_static_tensor, y_train_tensor\n",
    "    )\n",
    "    test_set = TemporalStaticDataset(\n",
    "        X_test_temp_tensor, X_test_static_tensor, y_test_tensor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kptxCJGX-Swv"
   },
   "source": [
    "## **Búsqueda de hiperparámetros con Optuna**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Dejamos seleccionado el constructor de modelo para la búsqueda de hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match MODEL_ARCH:\n",
    "    case \"lstm_v1\":\n",
    "        define_model = define_lstm_v1_model\n",
    "    case \"lstm_v2\":\n",
    "        define_model = define_lstm_v2_model\n",
    "    case \"gru\":\n",
    "        define_model = define_gru_model\n",
    "    case \"dense\":\n",
    "        define_model = define_dense_model\n",
    "    case \"fcn\":\n",
    "        define_model = define_fcn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Definimos los parámetros de la búsqueda de hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "study_name = f\"study_{timestamp}\"\n",
    "study_n_trials = 30\n",
    "\n",
    "if len(METRICS) != len(DIRECTIONS):\n",
    "    raise ValueError(\"The number of metrics and directions should be the same\")\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"optuna_study_name\": study_name,\n",
    "    \"optuna_study_n_trials\": study_n_trials,\n",
    "    \"objective_metrics\": METRICS,\n",
    "    \"directions\": DIRECTIONS\n",
    "})\n",
    "\n",
    "if \"f_beta_score\" in METRICS:\n",
    "    mlflow.log_param(\"f_beta_score\", BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=DIRECTIONS[0] if len(METRICS) == 1 else None,\n",
    "    directions=DIRECTIONS if len(METRICS) > 1 else None,\n",
    "    storage=OPTUNA_STORAGE,\n",
    "    study_name=study_name\n",
    ")\n",
    "study.set_metric_names(METRICS)\n",
    "\n",
    "study.optimize(\n",
    "    lambda trial: objective_cv(\n",
    "        trial, define_model, train_set, weights, METRICS, beta=BETA\n",
    "    ),\n",
    "    n_trials=20,\n",
    "    timeout=600,\n",
    "    n_jobs=-1,\n",
    "    callbacks=[MaxTrialsCallback(study_n_trials, states=(TrialState.COMPLETE,))],\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(METRICS) > 1:\n",
    "    print(f\"Number of trials on the Pareto front: {len(study.best_trials)}\")\n",
    "    for i, (metric, direction) in enumerate(zip(METRICS, DIRECTIONS)):\n",
    "        if direction == 'maximize':\n",
    "            best_trial = max(study.best_trials, key=lambda t: t.values[i])\n",
    "        elif direction == 'minimize':\n",
    "            best_trial = min(study.best_trials, key=lambda t: t.values[i])\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"\\tDirection: {direction}\")\n",
    "        print(f\"\\tTrial number: {best_trial.number}\")\n",
    "        print(f\"\\tValues: {best_trial.values}\")\n",
    "        print(f\"\\tParams: {best_trial.params}\")\n",
    "    \n",
    "    fig = plot_pareto_front(study, target_names=METRICS)\n",
    "    log_plot(fig, \"pareto_front_plot.png\")\n",
    "    fig.show()\n",
    "# else:\n",
    "#     fig = plot_intermediate_values(study)\n",
    "#     log_plot(fig, \"intermediate_values_plot.png\")\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials_info = get_best_trials_info(study, METRICS)\n",
    "best_trials_numbers = [trial['trial_number'] for trial in best_trials_info]\n",
    "\n",
    "log_json(best_trials_info, \"best_trials_info.json\")\n",
    "mlflow.log_params({\n",
    "    \"best_trials_numbers\": best_trials_numbers\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        selected_trial = int(input(\n",
    "            f\"Enter the trial number. Choose from {best_trials_numbers}: \"\n",
    "        ))\n",
    "        if selected_trial in best_trials_numbers:\n",
    "            print(f\"You selected Trial Number: {selected_trial}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Invalid input. Please select a number from {best_trials_numbers}.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "mlflow.log_param(\"selected_trial_number\", selected_trial, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entrenamiento del modelo con mejores hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.trials[selected_trial].params\n",
    "\n",
    "# Common parameters for all models\n",
    "epochs = params['n_epochs']\n",
    "dropout = params['dropout']\n",
    "\n",
    "# Model specific parameters\n",
    "if any(keyword in MODEL_ARCH for keyword in ['rnn', 'gru', 'lstm_v1']):\n",
    "    hidden_size = params['hidden_size']\n",
    "    n_layers = params['n_layers']\n",
    "    model = LSTMClassifier_v1(\n",
    "        input_size=num_features,\n",
    "        hidden_size=hidden_size,\n",
    "        output_size=1,\n",
    "        num_layers=n_layers,\n",
    "        dropout=dropout\n",
    "    )\n",
    "\n",
    "elif MODEL_ARCH == \"dense\":\n",
    "    n_layers = params['n_layers']\n",
    "    hidden_sizes = [params[f\"n_units_l{i}\"] for i in range(n_layers)]\n",
    "    input_size = len(FEATS)\n",
    "    model = DenseClassifier(input_size, hidden_sizes, dropout)\n",
    "\n",
    "elif MODEL_ARCH == \"lstm_v2\":\n",
    "    pass\n",
    "\n",
    "log_model_architecture(model)\n",
    "\n",
    "# optimizer_name and lr parameters are for specifying the optimizer\n",
    "optimizer_name = params['optimizer']\n",
    "lr = params['lr']\n",
    "optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "# batch_size is for the training loop\n",
    "batch_size = params['batch_size']\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor(weights[1], dtype=torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {epoch} -----------------------------------------------------\")\n",
    "    train_step(model, train_loader, loss_fn, optimizer)\n",
    "\n",
    "    metrics_values = validate_step_with_metrics(\n",
    "        model,\n",
    "        X_test_tensor,\n",
    "        y_test_tensor,\n",
    "        loss_fn,\n",
    "        METRICS,\n",
    "        beta=BETA,\n",
    "        train_features_mean=None\n",
    "    )\n",
    "    pprint.pp(metrics_values)\n",
    "    mlflow.log_metrics(metrics_values, step=epoch)\n",
    "\n",
    "mlflow.pytorch.log_model(model, \"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "y_test_pred = model(X_test_tensor.to('cpu'))\n",
    "y_test_pred = predict(y_test_pred, loss_fn).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = confusion_matrix_plot(y_test_tensor, y_test_pred)\n",
    "log_plot(fig, \"confusion_matrix_plot.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_plot(y_test_tensor, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TrabajoFinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
