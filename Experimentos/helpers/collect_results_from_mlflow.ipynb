{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbfb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import mlflow\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from constants import TRACKING_SERVER_URI, EXPERIMENT_PREFIX, DATA_DIR, RESULTS_PATH\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_SERVER_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff4ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND_DECIMALS = 5\n",
    "COMPARISON = \"ML\"\n",
    "MODEL_ARCHS = [\"lstm_v2\", \"conv\", \"lstm_conv\", \"psm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "GROUP = \"Grupo\" + str(config['group'])\n",
    "print(GROUP)\n",
    "\n",
    "GROUP_RESULTS_PATH = os.path.join(RESULTS_PATH, GROUP)\n",
    "if not os.path.exists(GROUP_RESULTS_PATH):\n",
    "    os.makedirs(GROUP_RESULTS_PATH)\n",
    "    print(f\"{GROUP_RESULTS_PATH} successfully created\")\n",
    "else:\n",
    "    print(f\"{GROUP_RESULTS_PATH} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_DIR = os.path.join(DATA_DIR, GROUP)\n",
    "GROUP_PARAMS_FILE = os.path.join(GROUP_DIR, f\"params_{GROUP}.json\")\n",
    "if os.path.exists(GROUP_PARAMS_FILE):\n",
    "    with open(GROUP_PARAMS_FILE, 'r') as f:\n",
    "        group_params = json.load(f)\n",
    "else:\n",
    "    print(f\"Group params file not found: {GROUP_PARAMS_FILE}\")\n",
    "\n",
    "REQ_PERIODS = group_params['first_tr_period'] - 1\n",
    "N_PER_DEP = group_params['n_per_dep']\n",
    "TR_STARTS = list(range(REQ_PERIODS, REQ_PERIODS + 3))\n",
    "\n",
    "print(f\"Períodos observados:     {REQ_PERIODS}\")\n",
    "print(f\"Períodos de dependencia: {N_PER_DEP}\")\n",
    "print(f\"Inicios de programa {TR_STARTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = f\"{EXPERIMENT_PREFIX}-{GROUP}-Comp{COMPARISON}\"\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "print(f\"{EXPERIMENT_NAME} - ID {experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428cbbb6",
   "metadata": {},
   "source": [
    "## **Listas de F1, precisión y recall por arquitectura**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce70b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_lists = {}\n",
    "\n",
    "for model_arch in MODEL_ARCHS:\n",
    "    print(f\"Getting results for {model_arch}\")\n",
    "    runs = mlflow.search_runs(\n",
    "        experiment_ids=[experiment_id],\n",
    "        output_format=\"list\",\n",
    "        filter_string=f\"params.model_arch = '{model_arch}'\",\n",
    "    )\n",
    "\n",
    "    if len(runs) != 100:\n",
    "        print(f\"{model_arch} doesn't have 100 runs for experiment {EXPERIMENT_NAME}\")\n",
    "\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "\n",
    "    for run in runs:\n",
    "        run_data = run.data\n",
    "        run_params = run_data.params\n",
    "\n",
    "        precisions.append(float(run_params['cohort_avg_precision']))\n",
    "        recalls.append(float(run_params['cohort_avg_recall']))\n",
    "        f1s.append(float(run_params['cohorts_avg_f1']))\n",
    "\n",
    "        metrics_lists[model_arch] = {\n",
    "            \"precisions\": precisions,\n",
    "            \"recalls\": recalls,\n",
    "            \"f1s\": f1s\n",
    "        }\n",
    "\n",
    "dst_path = os.path.join(GROUP_RESULTS_PATH, 'metrics_lists.json')\n",
    "with open(dst_path, 'w') as f:\n",
    "    json.dump(metrics_lists, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88194a7e",
   "metadata": {},
   "source": [
    "## **Promedio y desviación estándar de las métricas por arquitectura**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d59f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS_LISTS_PATH = os.path.join(GROUP_RESULTS_PATH, 'metrics_lists.json')\n",
    "with open(METRICS_LISTS_PATH, 'r') as f:\n",
    "    metrics_lists = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f791591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch_results = {}\n",
    "\n",
    "for model_arch, results in metrics_lists.items():\n",
    "    precisions = np.array(results[\"precisions\"])\n",
    "    recalls    = np.array(results[\"recalls\"])\n",
    "    f1s        = np.array(results[\"f1s\"])\n",
    "\n",
    "    avg_precision = float(round(np.mean(precisions), ROUND_DECIMALS))\n",
    "    avg_recall    = float(round(np.mean(recalls), ROUND_DECIMALS))\n",
    "    avg_f1        = float(round(np.mean(f1s), ROUND_DECIMALS))\n",
    "\n",
    "    precision_std = float(round(np.std(precisions, ddof=1), ROUND_DECIMALS))\n",
    "    recall_std    = float(round(np.std(recalls, ddof=1), ROUND_DECIMALS))\n",
    "    f1_std        = float(round(np.std(f1s, ddof=1), ROUND_DECIMALS))\n",
    "\n",
    "    model_arch_results[model_arch] = {\n",
    "        \"f1\":        f\"{avg_f1} ± {f1_std}\",\n",
    "        \"precision\": f\"{avg_precision} ± {precision_std}\",\n",
    "        \"recall\":    f\"{avg_recall} ± {recall_std}\"\n",
    "    }\n",
    "\n",
    "print(json.dumps(model_arch_results, indent=4, ensure_ascii=False))\n",
    "\n",
    "dst_path = os.path.join(GROUP_RESULTS_PATH, 'results.json')\n",
    "with open(dst_path, 'w') as f:\n",
    "    json.dump(model_arch_results, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45416f27",
   "metadata": {},
   "source": [
    "## **Frecuencia de valores de hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75562554",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = ['hidden_size', 'dropout', 'lr', 'batch_size']\n",
    "hps_results = {}\n",
    "\n",
    "for model_arch in MODEL_ARCHS:\n",
    "    if model_arch == 'psm': continue\n",
    "\n",
    "    print(f\"Getting results for {model_arch}\")\n",
    "    runs = mlflow.search_runs(\n",
    "        experiment_ids=[experiment_id],\n",
    "        output_format=\"list\",\n",
    "        filter_string=f\"params.model_arch = '{model_arch}'\",\n",
    "    )\n",
    "\n",
    "    if len(runs) != 100:\n",
    "        print(f\"{model_arch} doesn't have 100 runs for experiment {EXPERIMENT_NAME}\")\n",
    "\n",
    "    hps_results[model_arch] = {}\n",
    "\n",
    "    for run in runs:\n",
    "        run_params = run.data.params\n",
    "        train_params = ast.literal_eval(run_params['train_params'])\n",
    "\n",
    "        for hp in hps:\n",
    "            if hp in train_params:\n",
    "                value = train_params[hp]\n",
    "\n",
    "                if hp not in hps_results[model_arch]:\n",
    "                    hps_results[model_arch][hp] = {}\n",
    "                if value not in hps_results[model_arch][hp]:\n",
    "                    hps_results[model_arch][hp][value] = 0\n",
    "\n",
    "                hps_results[model_arch][hp][value] += 1\n",
    "\n",
    "print(json.dumps(hps_results, indent=4))\n",
    "\n",
    "dst_path = os.path.join(GROUP_RESULTS_PATH, 'hyperparams_counts.json')\n",
    "with open(dst_path, 'w') as f:\n",
    "    json.dump(hps_results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
