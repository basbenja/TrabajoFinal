{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef4499c",
   "metadata": {},
   "source": [
    "### **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "from constants import *\n",
    "from utils.metrics import compute_metrics\n",
    "from utils.mlflow_logger import MLflowLogger\n",
    "from utils.plots import confusion_matrix_plot\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42967c66",
   "metadata": {},
   "source": [
    "Ya chequeé que los IDs de NiNis de train y test sean los mismos para todas las simulaciones,\n",
    "entonces basta con elegir los de una simulación cualquiera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d670e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/basbenja/Facultad/TrabajoFinal/'\n",
    "\n",
    "ninis_ids_train_path = os.path.join(base_path, 'ninis_ids_train.json')\n",
    "ninis_ids_test_path  = os.path.join(base_path, 'ninis_ids_test.json')\n",
    "\n",
    "with open(ninis_ids_train_path, 'r') as f:\n",
    "    ninis_ids_train = json.load(f)['ninis_ids_train']\n",
    "with open(ninis_ids_test_path, 'r') as f:\n",
    "    ninis_ids_test = json.load(f)['ninis_ids_test']\n",
    "\n",
    "assert(len(ninis_ids_train) == 1000)\n",
    "assert(len(ninis_ids_test) == 2500)\n",
    "\n",
    "type3_ids_train = ninis_ids_train\n",
    "type3_ids_test  = ninis_ids_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687c303",
   "metadata": {},
   "source": [
    "### **Configuramos Stata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(STATA_PATH, 'utilities'))\n",
    "import pystata\n",
    "pystata.config.init('mp', splash=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b0c10",
   "metadata": {},
   "source": [
    "### **Carga de ajustes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pprint.pp(config)\n",
    "\n",
    "GROUP = \"Grupo\" + str(config['group'])\n",
    "SIMULATION = \"Simulacion\" + str(config['simulation'])\n",
    "METRICS = config['metrics']\n",
    "BETA = config['beta']\n",
    "LOG_TO_MLFLOW = (config['log_to_mlflow'] == \"True\")\n",
    "COMPARISON = config['comparison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c829b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_DIR = os.path.join(DATA_DIR, GROUP)\n",
    "GROUP_PARAMS_FILE = os.path.join(GROUP_DIR, f\"params_{GROUP}.json\")\n",
    "if os.path.exists(GROUP_PARAMS_FILE):\n",
    "    with open(GROUP_PARAMS_FILE, 'r') as f:\n",
    "        group_params = json.load(f)\n",
    "else:\n",
    "    print(f\"Group params file not found: {GROUP_PARAMS_FILE}\")\n",
    "\n",
    "REQ_PERIODS = group_params['first_tr_period'] - 1\n",
    "TEMP_FEATS = [f'y(t-{i})' for i in range(REQ_PERIODS, 0, -1)]\n",
    "STAT_FEATS = ['inicio_prog']\n",
    "FEATS = STAT_FEATS + TEMP_FEATS\n",
    "\n",
    "N_PER_DEP = group_params['n_per_dep']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061a1b9",
   "metadata": {},
   "source": [
    "### **Carga de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ea4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_DIR = os.path.join(DATA_DIR, GROUP)\n",
    "stata_filepath = os.path.join(GROUP_DIR, SIMULATION + \".dta\")\n",
    "if os.path.exists(stata_filepath):\n",
    "    df = pd.read_stata(stata_filepath)\n",
    "else:\n",
    "    print(f\"File {stata_filepath} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2747d1e2",
   "metadata": {},
   "source": [
    "### **Loguear parámetros a MLFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Log to MLflow: {LOG_TO_MLFLOW}\")\n",
    "mlflow_logger = MLflowLogger(\n",
    "    LOG_TO_MLFLOW,\n",
    "    TRACKING_SERVER_URI,\n",
    "    f\"{EXPERIMENT_PREFIX}-{GROUP}-Comp{COMPARISON}\",\n",
    "    EXPERIMENT_TAGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_logger.log_params({\n",
    "    \"group\": GROUP,\n",
    "    \"simulation\": SIMULATION,\n",
    "    \"filepath\": stata_filepath,\n",
    "    \"required_periods\": REQ_PERIODS,\n",
    "    \"n_per_dep\": N_PER_DEP,\n",
    "    \"model_arch\": \"psm\",\n",
    "    \"metrics\": METRICS,\n",
    "    \"ups_max_count\": group_params['ups_max_count'],\n",
    "    \"estimacion_logit\": \"tratados + ninis_train\",\n",
    "    \"inferencia_y_matching\": \"tratados + controles + ninis_test\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc63ac1",
   "metadata": {},
   "source": [
    "### **Transformaciones generales**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c185d7",
   "metadata": {},
   "source": [
    "**Primero, transformamos los datos a formato horizontal (esto lo hacemos una sola vez)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df.pivot(index='id', columns='t', values='y')\n",
    "df_wide.columns = [f'y{int(col)}' for col in df_wide.columns]\n",
    "df_wide.reset_index(inplace=True)\n",
    "\n",
    "static_cols = ['id', 'inicio_prog', 'tratado', 'control']\n",
    "df_static = df[static_cols].drop_duplicates(subset='id')\n",
    "\n",
    "df_wide = pd.merge(df_static, df_wide, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1662f",
   "metadata": {},
   "source": [
    "**Separamos en tipos de individuos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_df = df_wide[df_wide['tratado'] == 1]\n",
    "type2_df = df_wide[df_wide['control'] == 1]\n",
    "type3_df = df_wide[(df_wide['tratado'] == 0) & (df_wide['control'] == 0)]\n",
    "\n",
    "type3_df_train = type3_df.loc[type3_ids_train]\n",
    "type3_df_test  = type3_df.loc[type3_ids_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535ba73",
   "metadata": {},
   "source": [
    "**Obtenemos diferentes cohortes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc503e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_starts = type1_df['inicio_prog'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2233a2e",
   "metadata": {},
   "source": [
    "### **Lo hacemos para una cohorte**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b082222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con \"estimates save logit_model\" se guarda el modelo en un archivo llamdo\n",
    "# logit_model. El \"replace\" al final lo sobreescribe si ya existe.\n",
    "stata_code_estimate_logit = '''\n",
    "qui ds y*\n",
    "qui local vars `r(varlist)'\n",
    "qui logit tratado `vars'\n",
    "estimates save logit_model, replace\n",
    "'''\n",
    "\n",
    "# - Con \"estimates use logit_model\" usamos el modelo guardado anteriormente\n",
    "# - Con el noreplacement fuerzo a que me elija un control distinto por cada tratado.\n",
    "#   Esto es necesario porque en nuestros datos generamos la misma cantidad de controles\n",
    "#   que de tratados en cada cohorte. Si no pusiera esto y un individuo resultara elegido\n",
    "#   como de control para varios tratados, me degrada el F1 porque yo estoy esperando\n",
    "#   que me elija la mayor cantidad de controles\n",
    "stata_code_infer_logit = '''\n",
    "estimates use logit_model\n",
    "predict propensity_score, pr\n",
    "psmatch2 tratado, pscore(propensity_score) neighbor(1) common noreplacement\n",
    "qui drop _treated _nn _pscore `vars'\n",
    "qui rename _weight wlogit\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9949dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_y_columns(row, inicio_prog=None):\n",
    "    if not inicio_prog:\n",
    "        inicio_prog = int(row['inicio_prog'])\n",
    "    start = inicio_prog - REQ_PERIODS\n",
    "    end   = inicio_prog - 1\n",
    "    selected_cols = [f'y{t}' for t in range(start, end+1)]\n",
    "    return row[['id', 'inicio_prog', 'tratado', 'control'] + selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_metrics = defaultdict(list)\n",
    "for tr_start in treatment_starts:\n",
    "    print(f\"Inicio de programa: {tr_start}\")\n",
    "    inicio_prog_folder = f\"inicio_prog_{tr_start}\"\n",
    "\n",
    "    type1_in_cohort_df = type1_df[type1_df['inicio_prog'] == tr_start].apply(select_y_columns, axis=1)\n",
    "    type2_in_cohort_df = type2_df[type2_df['inicio_prog'] == tr_start].apply(select_y_columns, axis=1)\n",
    "\n",
    "    type3_df_train_for_cohort = type3_df_train.copy()\n",
    "    type3_df_test_for_cohort  = type3_df_test.copy()\n",
    "    type3_df_train_for_cohort['inicio_prog'] = tr_start\n",
    "    type3_df_test_for_cohort ['inicio_prog'] = tr_start\n",
    "    type3_df_train_for_cohort = type3_df_train_for_cohort.apply(select_y_columns, axis=1)\n",
    "    type3_df_test_for_cohort  = type3_df_test_for_cohort. apply(select_y_columns, axis=1)\n",
    "\n",
    "    logit_weights_df = pd.concat([type1_in_cohort_df, type3_df_train_for_cohort])\n",
    "    logit_infer_df   = pd.concat([type1_in_cohort_df, type2_in_cohort_df, type3_df_test_for_cohort])\n",
    "\n",
    "    true_1_ids = logit_infer_df[logit_infer_df['control'] == 1]['id'].to_list()\n",
    "    true_0_ids = logit_infer_df[(logit_infer_df['control'] == 0) & (logit_infer_df['tratado'] == 0)]['id'].to_list()\n",
    "\n",
    "    print(\"    Calculando pesos de la logit...\")\n",
    "    # Calculamos los pesos de la logit\n",
    "    pystata.stata.pdataframe_to_data(logit_weights_df, force=True)\n",
    "    pystata.stata.run(stata_code_estimate_logit, quietly=True)\n",
    "    logit_model_path = os.path.join(os.getcwd(), 'logit_model.ster')\n",
    "    mlflow_logger.log_artifact(logit_model_path, inicio_prog_folder)\n",
    "\n",
    "    print(\"    Haciendo la inferencia...\")\n",
    "    # Hacemos la inferencia\n",
    "    pystata.stata.pdataframe_to_data(logit_infer_df, force=True)\n",
    "    pystata.stata.run(stata_code_infer_logit, quietly=True)\n",
    "    df_psm = pystata.stata.pdataframe_from_data()\n",
    "\n",
    "    try:\n",
    "        os.remove(logit_model_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{logit_model_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    print(\"    Obteniendo resultados...\")\n",
    "    treated_df_psm     = df_psm[df_psm['tratado'] == 1]\n",
    "    not_treated_df_psm = df_psm[df_psm['tratado'] == 0]\n",
    "\n",
    "    # Los individudos identificados como control son los que aparecen en la columna _n1\n",
    "    # del DataFrame. Notar que este _n1 hace referencia a la columna _id, NO a id.\n",
    "    control_ids_psm = treated_df_psm['_n1']\n",
    "    control_df_psm  = not_treated_df_psm[not_treated_df_psm['_id'].isin(control_ids_psm)]\n",
    "    control_in_cohort_ids_pred = control_df_psm['id'].to_list()\n",
    "\n",
    "    ninis_df_psm = not_treated_df_psm[~not_treated_df_psm['_id'].isin(control_ids_psm)]\n",
    "    ninis_ids_pred = ninis_df_psm['id'].to_list()\n",
    "\n",
    "    pred_0_ids = ninis_ids_pred\n",
    "    pred_1_ids = control_in_cohort_ids_pred\n",
    "\n",
    "    all_ids = list(set(true_0_ids + true_1_ids + pred_0_ids + pred_1_ids))\n",
    "\n",
    "    # Create true and predicted label arrays\n",
    "    y_true = [0 if id in true_0_ids else 1 for id in all_ids]\n",
    "    y_pred = [0 if id in pred_0_ids else 1 for id in all_ids]\n",
    "\n",
    "    fig, ax, confusion_dict = confusion_matrix_plot(y_true, y_pred)\n",
    "    mlflow_logger.log_plot(fig, \"confusion_matrix_plot.png\", inicio_prog_folder)\n",
    "    mlflow_logger.log_json(confusion_dict, \"confusion_dict.json\", inicio_prog_folder)\n",
    "\n",
    "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "    mlflow_logger.log_json(report_dict, f\"classification_report.json\", inicio_prog_folder)\n",
    "\n",
    "    cohort_metrics_dict = compute_metrics(METRICS, y_true, y_pred)\n",
    "    for metric, value in cohort_metrics_dict.items():\n",
    "        avg_metrics[metric].append(value)\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6bd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, values in avg_metrics.items():\n",
    "    values_array = np.array(values)\n",
    "    metric_mean = values_array.mean()\n",
    "    avg_metrics[metric] = metric_mean\n",
    "    if metric == \"f1_score\":\n",
    "        mlflow_logger.log_param(\"cohorts_avg_f1\", metric_mean)\n",
    "    else:\n",
    "        mlflow_logger.log_param(f\"cohort_avg_{metric}\", metric_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca942b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_logger.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
