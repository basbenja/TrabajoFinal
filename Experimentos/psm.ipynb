{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef4499c",
   "metadata": {},
   "source": [
    "### **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "from constants import *\n",
    "from utils.metrics import compute_metrics\n",
    "from utils.mlflow_logger import MLflowLogger\n",
    "from utils.plots import confusion_matrix_plot\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687c303",
   "metadata": {},
   "source": [
    "### **Configuramos Stata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(STATA_PATH, 'utilities'))\n",
    "import pystata\n",
    "# NOTA: el splash solo aparece la primera vez que se carga pystata. O sea, si esta\n",
    "# celda se ejecuta varias veces, no se vuelve a mostrar el splash\n",
    "pystata.config.init('mp', splash=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b0c10",
   "metadata": {},
   "source": [
    "### **Carga de ajustes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pprint.pp(config)\n",
    "\n",
    "GROUP = \"Grupo\" + str(config['group'])\n",
    "SIMULATION = \"Simulacion\" + str(config['simulation'])\n",
    "METRICS = config['metrics']\n",
    "BETA = config['beta']\n",
    "LOG_TO_MLFLOW = (config['log_to_mlflow'] == \"True\")\n",
    "COMPARISON = config['comparison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c829b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_DIR = os.path.join(DATA_DIR, GROUP)\n",
    "GROUP_PARAMS_FILE = os.path.join(GROUP_DIR, f\"params_{GROUP}.json\")\n",
    "if os.path.exists(GROUP_PARAMS_FILE):\n",
    "    with open(GROUP_PARAMS_FILE, 'r') as f:\n",
    "        group_params = json.load(f)\n",
    "else:\n",
    "    print(f\"Group params file not found: {GROUP_PARAMS_FILE}\")\n",
    "\n",
    "REQ_PERIODS = group_params['first_tr_period'] - 1\n",
    "TEMP_FEATS = [f'y(t-{i})' for i in range(REQ_PERIODS, 0, -1)]\n",
    "STAT_FEATS = ['inicio_prog']\n",
    "FEATS = STAT_FEATS + TEMP_FEATS\n",
    "\n",
    "N_PER_DEP = group_params['n_per_dep']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061a1b9",
   "metadata": {},
   "source": [
    "### **Carga de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ea4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_DIR = os.path.join(DATA_DIR, GROUP)\n",
    "stata_filepath = os.path.join(GROUP_DIR, SIMULATION + \".dta\")\n",
    "if os.path.exists(stata_filepath):\n",
    "    df = pd.read_stata(stata_filepath)\n",
    "else:\n",
    "    print(f\"File {stata_filepath} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2747d1e2",
   "metadata": {},
   "source": [
    "### **Loguear parámetros a MLFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Log to MLflow: {LOG_TO_MLFLOW}\")\n",
    "# mlflow_logger = MLflowLogger(\n",
    "#     LOG_TO_MLFLOW,\n",
    "#     TRACKING_SERVER_URI,\n",
    "#     f\"{EXPERIMENT_PREFIX}-{GROUP}-Comp{COMPARISON}\",\n",
    "#     EXPERIMENT_TAGS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow_logger.log_params({\n",
    "#     \"group\": GROUP,\n",
    "#     \"simulation\": SIMULATION,\n",
    "#     \"filepath\": stata_filepath,\n",
    "#     \"required_periods\": REQ_PERIODS,\n",
    "#     \"n_per_dep\": N_PER_DEP,\n",
    "#     \"model_arch\": \"psm\",\n",
    "#     \"metrics\": METRICS,\n",
    "#     \"ups_max_count\": group_params['ups_max_count']\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a1988",
   "metadata": {},
   "source": [
    "### **Carga de IDs de NiNis**\n",
    "Los IDs de los NiNis fueron selecionados aleatoriamente en los primeros experimentos\n",
    "hechos con LSTM. Necesitamos traerlos para hacer las comparaciones con los mismos\n",
    "conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_SERVER_URI)\n",
    "\n",
    "experiment_name = f\"{EXPERIMENT_PREFIX}-{GROUP}-Comp{COMPARISON}\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "runs_list = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=(\n",
    "        f\"params.simulation = '{SIMULATION}' AND params.model_arch = 'lstm_v2'\"\n",
    "    ),\n",
    "    output_format=\"list\"\n",
    ")\n",
    "\n",
    "run = runs_list[0]\n",
    "run_id = run.info.run_id\n",
    "artifact_uri = run.info.artifact_uri\n",
    "\n",
    "ninis_ids_train = mlflow.artifacts.load_dict(artifact_uri + \"/ninis_ids_train.json\")\n",
    "ninis_ids_test  = mlflow.artifacts.load_dict(artifact_uri + \"/ninis_ids_test.json\")\n",
    "\n",
    "assert(ninis_ids_train['amount'] == 1000)\n",
    "assert(ninis_ids_test ['amount'] == 2500)\n",
    "\n",
    "type3_ids_train = ninis_ids_train['ninis_ids_train']\n",
    "type3_ids_test  = ninis_ids_test ['ninis_ids_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc63ac1",
   "metadata": {},
   "source": [
    "### **Transformaciones generales**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c185d7",
   "metadata": {},
   "source": [
    "**Primero, transformamos los datos a formato horizontal (esto lo hacemos una sola vez)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df.pivot(index='id', columns='t', values='y')\n",
    "df_wide.columns = [f'y{int(col)}' for col in df_wide.columns]\n",
    "df_wide.reset_index(inplace=True)\n",
    "\n",
    "static_cols = ['id', 'inicio_prog', 'tratado', 'control']\n",
    "df_static = df[static_cols].drop_duplicates(subset='id')\n",
    "\n",
    "df_wide = pd.merge(df_static, df_wide, on='id')\n",
    "\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1662f",
   "metadata": {},
   "source": [
    "**Separamos en tipos de individuos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_df = df_wide[df_wide['tratado'] == 1]\n",
    "type2_df = df_wide[df_wide['control'] == 1]\n",
    "type3_df = df_wide[(df_wide['tratado'] == 0) & (df_wide['control'] == 0)]\n",
    "\n",
    "type3_df_train = type3_df.loc[type3_ids_train]\n",
    "type3_df_test  = type3_df.loc[type3_ids_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535ba73",
   "metadata": {},
   "source": [
    "**Obtenemos diferentes cohortes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc503e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_starts = type1_df['inicio_prog'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2233a2e",
   "metadata": {},
   "source": [
    "### **Lo hacemos para una cohorte**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b082222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con \"estimates save logit_model\" se guarda el modelo en un archivo llamdo\n",
    "# logit_model. El \"replace\" al final lo sobreescribe si ya existe.\n",
    "stata_code_estimate_logit = '''\n",
    "qui ds y*\n",
    "qui local vars `r(varlist)'\n",
    "qui logit tratado `vars'\n",
    "estimates save logit_model, replace\n",
    "'''\n",
    "\n",
    "# con \"estimates use logit_model\" usamos el modelo guardado anteriormente\n",
    "stata_code_infer_logit = '''\n",
    "estimates use logit_model\n",
    "predict pscore, pr\n",
    "psmatch2 tratado, pscore(pscore) neighbor(1) common\n",
    "qui drop _treated _nn _pscore `vars'\n",
    "qui rename _weight wlogit\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9949dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_y_columns(row):\n",
    "    inicio_prog = int(row['inicio_prog'])\n",
    "    start = inicio_prog - REQ_PERIODS\n",
    "    end   = inicio_prog - 1\n",
    "    selected_cols = [f'y{t}' for t in range(start, end+1)]\n",
    "    return row[['id', 'inicio_prog', 'tratado', 'control'] + selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a53965",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr_start in treatment_starts:\n",
    "    print(f\"Inicio de programa: {tr_start}\")\n",
    "\n",
    "    type1_in_cohort_df = type1_df[type1_df['inicio_prog'] == tr_start].apply(select_y_columns, axis=1)\n",
    "    type2_in_cohort_df = type2_df[type2_df['inicio_prog'] == tr_start].apply(select_y_columns, axis=1)\n",
    "\n",
    "    type3_df_train_for_cohort = type3_df_train.copy()\n",
    "    type3_df_test_for_cohort  = type3_df_test.copy()\n",
    "    type3_df_train_for_cohort['inicio_prog'] = tr_start\n",
    "    type3_df_test_for_cohort ['inicio_prog'] = tr_start\n",
    "    type3_df_train_for_cohort = type3_df_train_for_cohort.apply(select_y_columns, axis=1)\n",
    "    type3_df_test_for_cohort  = type3_df_test_for_cohort. apply(select_y_columns, axis=1)\n",
    "\n",
    "    logit_weights_df = pd.concat([type1_in_cohort_df, type3_df_train_for_cohort])\n",
    "    logit_infer_df   = pd.concat([type1_in_cohort_df, type2_in_cohort_df, type3_df_test_for_cohort])\n",
    "\n",
    "    true_1_ids = logit_infer_df[logit_infer_df['control'] == 1]['id'].to_list()\n",
    "    true_0_ids = logit_infer_df[(logit_infer_df['control'] == 0) & (logit_infer_df['tratado'] == 0)]['id'].to_list()\n",
    "\n",
    "    print(\"    Calculando pesos de la logit...\")\n",
    "    # Calculamos los pesos de la logit\n",
    "    pystata.stata.pdataframe_to_data(logit_weights_df, force=True)\n",
    "    pystata.stata.run(stata_code_estimate_logit, quietly=True)\n",
    "\n",
    "    print(\"    Haciendo la inferencia...\")\n",
    "    # Hacemos la inferencia\n",
    "    pystata.stata.pdataframe_to_data(logit_infer_df, force=True)\n",
    "    pystata.stata.run(stata_code_infer_logit, quietly=True)\n",
    "    df_psm = pystata.stata.pdataframe_from_data()\n",
    "\n",
    "    print(\"    Obteniendo resultados...\")\n",
    "    treated_df_psm     = df_psm[df_psm['tratado'] == 1]\n",
    "    not_treated_df_psm = df_psm[df_psm['tratado'] == 0]\n",
    "\n",
    "    # Los individudos identificados como control son los que aparecen en la columna _n1\n",
    "    # del DataFrame. Notar que este _n1 hace referencia a la columna _id, NO a id.\n",
    "    control_ids_psm = treated_df_psm['_n1']\n",
    "    control_df_psm  = not_treated_df_psm[not_treated_df_psm['_id'].isin(control_ids_psm)]\n",
    "    control_in_cohort_ids_pred = control_df_psm['id'].to_list()\n",
    "\n",
    "    ninis_df_psm = not_treated_df_psm[~not_treated_df_psm['_id'].isin(control_ids_psm)]\n",
    "    ninis_ids_pred = ninis_df_psm['id'].to_list()\n",
    "\n",
    "    pred_0_ids = ninis_ids_pred\n",
    "    pred_1_ids = control_in_cohort_ids_pred\n",
    "\n",
    "    all_ids = list(set(true_0_ids + true_1_ids + pred_0_ids + pred_1_ids))\n",
    "\n",
    "    # Create true and predicted label arrays\n",
    "    y_true = [0 if id in true_0_ids else 1 for id in all_ids]\n",
    "    y_pred = [0 if id in pred_0_ids else 1 for id in all_ids]\n",
    "\n",
    "    fig, ax = confusion_matrix_plot(y_true, y_pred)\n",
    "    # mlflow_logger.log_plot(fig, f\"confusion_matrix_plot_inicio_prog_{tr_start}.png\")\n",
    "\n",
    "    report_str = classification_report(y_true, y_pred)\n",
    "    print(f\"    Métricas de la clasificación:\\n {report_str}\")\n",
    "    # mlflow_logger.log_json(\n",
    "    #     classification_report(y_true, y_pred, output_dict=True),\n",
    "    #     f\"classification_report_inicio_prog_{tr_start}.json\"\n",
    "    # )\n",
    "\n",
    "    metrics_dict = compute_metrics(METRICS, y_true, y_pred)\n",
    "    print(f\"    Métricas:\")\n",
    "    for metric, value in metrics_dict.items():\n",
    "        print(f\"        - {metric}: {value}\")\n",
    "        # mlflow_logger.log_param(metric value)\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda84832",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_start = treatment_starts[0]\n",
    "\n",
    "type1_in_cohort_df = type1_df[type1_df['inicio_prog'] == tr_start].apply(select_y_columns, axis=1)\n",
    "type2_in_cohort_df = type2_df[type2_df['inicio_prog'] == tr_start].apply(select_y_columns, axis=1)\n",
    "\n",
    "type3_df_train['inicio_prog'] = tr_start\n",
    "type3_df_test ['inicio_prog'] = tr_start\n",
    "type3_df_train = type3_df_train.apply(select_y_columns, axis=1)\n",
    "type3_df_test  = type3_df_test. apply(select_y_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(type1_in_cohort_df), len(type3_df_train))\n",
    "print(len(type2_in_cohort_df), len(type3_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d888e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_weights_df = pd.concat([type1_in_cohort_df, type3_df_train])\n",
    "logit_infer_df   = pd.concat([type1_in_cohort_df, type2_in_cohort_df, type3_df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_1_ids = logit_infer_df[logit_infer_df['control'] == 1]['id'].to_list()\n",
    "true_0_ids = logit_infer_df[(logit_infer_df['control'] == 0) & (logit_infer_df['tratado'] == 0)]['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed548ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos los pesos de la logit\n",
    "pystata.stata.pdataframe_to_data(logit_weights_df, force=True)\n",
    "pystata.stata.run(stata_code_estimate_logit)\n",
    "\n",
    "# Hacemos la inferencia\n",
    "pystata.stata.pdataframe_to_data(logit_infer_df, force=True)\n",
    "pystata.stata.run(stata_code_infer_logit)\n",
    "df_psm = pystata.stata.pdataframe_from_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667921b2",
   "metadata": {},
   "source": [
    "Sobre el comando `psmatch2` de Stata: [Stata Documentation for the psmatch2 command](https://www.pep-net.org/sites/pep-net.org/files/typo3doc/pdf/Training_Material/statadoc.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512ac41",
   "metadata": {},
   "source": [
    "**Vemos los controles identificados por el PSM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da025ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_df_psm     = df_psm[df_psm['tratado'] == 1]\n",
    "not_treated_df_psm = df_psm[df_psm['tratado'] == 0]\n",
    "\n",
    "# Los individudos identificados como control son los que aparecen en la columna _n1\n",
    "# del DataFrame. Notar que este _n1 hace referencia a la columna _id, NO a id.\n",
    "control_ids_psm = treated_df_psm['_n1']\n",
    "control_df_psm  = not_treated_df_psm[not_treated_df_psm['_id'].isin(control_ids_psm)]\n",
    "control_in_cohort_ids_pred = control_df_psm['id'].to_list()\n",
    "\n",
    "ninis_df_psm = not_treated_df_psm[~not_treated_df_psm['_id'].isin(control_ids_psm)]\n",
    "ninis_ids_pred = ninis_df_psm['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0_ids = ninis_ids_pred\n",
    "pred_1_ids = control_in_cohort_ids_pred\n",
    "\n",
    "all_ids = list(set(true_0_ids + true_1_ids + pred_0_ids + pred_1_ids))\n",
    "\n",
    "# Create true and predicted label arrays\n",
    "y_true = [0 if id in true_0_ids else 1 for id in all_ids]\n",
    "y_pred = [0 if id in pred_0_ids else 1 for id in all_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c333f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = confusion_matrix_plot(y_true, y_pred)\n",
    "fig.show()\n",
    "\n",
    "# mlflow_logger.log_plot(fig, f\"confusion_matrix_plot_inicio_prog_{tr_start}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36897ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_str = classification_report(y_true, y_pred)\n",
    "print(report_str)\n",
    "\n",
    "# mlflow_logger.log_json(\n",
    "#     classification_report(y_true, y_pred, output_dict=True),\n",
    "#     f\"classification_report_inicio_prog_{tr_start}.json\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = compute_metrics(METRICS, y_true, y_pred)\n",
    "\n",
    "for metric, value in metrics_dict.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "    # mlflow_logger.log_param(metric value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
