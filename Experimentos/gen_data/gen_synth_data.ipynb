{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import stata_setup\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from constants import DATA_DIR, STATA_PATH\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "\n",
    "# Seteamos pandas para que muestre todas las columnas y más filas\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# np.random.seed(12361)  # Semilla 2023\n",
    "# np.random.seed(345827) # Semilla 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Directorio base de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory /home/basbenja/Facultad/TrabajoFinal/data already exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "else:\n",
    "    print(f\"The directory {DATA_DIR} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configuramos Stata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ___  ____  ____  ____  ____ ®\n",
      " /__    /   ____/   /   ____/      17.0\n",
      "___/   /   /___/   /   /___/       MP—Parallel Edition\n",
      "\n",
      " Statistics and Data Science       Copyright 1985-2021 StataCorp LLC\n",
      "                                   StataCorp\n",
      "                                   4905 Lakeway Drive\n",
      "                                   College Station, Texas 77845 USA\n",
      "                                   800-STATA-PC        https://www.stata.com\n",
      "                                   979-696-4600        stata@stata.com\n",
      "\n",
      "Stata license: Single-user 8-core  perpetual\n",
      "Serial number: 501706363058\n",
      "  Licensed to: Benjamín Bas Peralta (Laptop)\n",
      "               Universidad Nacional de Córdoba - FAMAF\n",
      "\n",
      "Notes:\n",
      "      1. Unicode is supported; see help unicode_advice.\n",
      "      2. More than 2 billion observations are allowed; see help obs_advice.\n",
      "      3. Maximum number of variables is set to 5,000; see help set_maxvar.\n"
     ]
    }
   ],
   "source": [
    "stata_setup.config(STATA_PATH, 'mp', splash=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Número de grupo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of the last group generated\n",
    "\n",
    "# List all directories in the PATH\n",
    "groups_dirs = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "\n",
    "# Define a regular expression to extract the number from folder names like 'GrupoN'\n",
    "pattern = r'Grupo(\\d+)'\n",
    "\n",
    "# Extract numbers and find the maximum\n",
    "numbers = []\n",
    "for dir in groups_dirs:\n",
    "    match = re.search(pattern, dir)\n",
    "    if match:\n",
    "        numbers.append(int(match.group(1)))\n",
    "\n",
    "# Find the maximum number\n",
    "if numbers:\n",
    "    group_number = max(numbers) + 1\n",
    "    print(f\"The new group number is: {group_number}\")\n",
    "else:\n",
    "    print(\"No folders with the pattern 'GrupoN' found. Setting it to 1...\")\n",
    "    group_number = 1\n",
    "\n",
    "GROUP_PATH = os.path.join(DATA_DIR, f\"Grupo{group_number}\")\n",
    "print(f\"Creating the group directory: {GROUP_PATH}\")\n",
    "os.makedirs(GROUP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parámetros**\n",
    "Para más información sobre qué representa cada parámetro, leer el archivo `README.md` de este directorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parámetros fijos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = 200\n",
    "\n",
    "phiNini = 0.90\n",
    "phiT = 0.90\n",
    "phiC = 0.90\n",
    "phiTra = 0.90\n",
    "MeanFEN = 10.0\n",
    "MeanFET = 10.0\n",
    "MeanFEC = 10.0\n",
    "\n",
    "NivelN = MeanFEN\n",
    "NivelT = MeanFET\n",
    "NivelC = MeanFEC\n",
    "ImpactoProporcional = 0.05\n",
    "ImpactoNominal = NivelC * ImpactoProporcional\n",
    "STDImpacto = 0.05\n",
    "\n",
    "dependence = 1\n",
    "\n",
    "porcentaje  = 0.05\n",
    "hetecohorte = 1\n",
    "n_per_dep = 3\n",
    "nolineal = 0\n",
    "\n",
    "StdErrorSerie = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cargamos parámetros variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_PATH = os.path.join(os.getcwd(), 'params.json')\n",
    "with open(PARAMS_PATH, 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "n_simulations = params['n_simulations']\n",
    "\n",
    "n_total = params['n_total']\n",
    "treated_pctg = params['treated_pctg']\n",
    "control_pctg = params['control_pctg']\n",
    "\n",
    "n_treated = round(treated_pctg * n_total)\n",
    "n_control = n_treated\n",
    "n = n_treated + n_control\n",
    "n_nini = n_total - n\n",
    "\n",
    "T = params['T']\n",
    "total_periods = T + ini\n",
    "first_tr_period = params['first_tr_period']\n",
    "\n",
    "n_cohorts = params['n_cohorts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribimos los parámetros usados a la carpeta del nuevo grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"group_number\"] = group_number\n",
    "group_params_path = os.path.join(GROUP_PATH, f\"params_Grupo{group_number}.json\")\n",
    "with open(group_params_path, \"w\") as f:\n",
    "    json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_entry(y, t, n_dep_periods, non_linear, pctg, dependence):\n",
    "    \"\"\"\n",
    "    Evaluates if the time series is increasing in the last n_dep_periods periods\n",
    "    starting from the period t and optionally if the series is increasing in the\n",
    "    last two periods with a percentage greater than pctg.\n",
    "\n",
    "    Args:\n",
    "        y (array): time series\n",
    "        t (int): current time index\n",
    "        n_dep_periods (int): amount of periods to consider for the temporal dependency\n",
    "        non_linear (bool): indicates whether to check for an extra condition\n",
    "        pctg (float): _description_\n",
    "        dependence (bool): indicates whether to check for the increasing trend\n",
    "        in the series\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the condition is met, False otherwise\n",
    "    \"\"\"\n",
    "    if dependence == 1:\n",
    "        start = t - n_dep_periods\n",
    "        condition = all(\n",
    "            y[start+i] < y[start+i+1] for i in range(n_dep_periods-1)\n",
    "        )\n",
    "        if non_linear:\n",
    "            condition &= (abs(y[t-2] - y[t-1]) / y[t-2]) > pctg\n",
    "    else:\n",
    "        condition = True\n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable evolution matrix for control and treated\n",
    "YPanel = np.zeros(shape=(n_simulations*n*T,9))\n",
    "\n",
    "# Variable evolution matrix for nini\n",
    "YPanelNiNi = np.zeros(shape=(n_simulations*n_nini*T,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in range(n_simulations):\n",
    "    EfectoFijoT = np.random.normal(0,1,n) + MeanFET\n",
    "    EfectoTemporalT = np.random.normal(0,1,T+ini)\n",
    "\n",
    "    Y = np.zeros(shape=(n,T))   # n = n_treated + n_control\n",
    "    y_control = np.zeros(shape=(n_control, T))\n",
    "    y_counterfac = np.zeros(shape=(n, T))\n",
    "    treatment_starts = []\n",
    "\n",
    "    n_treated_in_cohort = int(n_treated / n_cohorts) # Amount of treated units per cohort\n",
    "    i = 0\n",
    "\n",
    "    for dataset, label in [(Y, 'Tratados'), (y_control, 'Controles')]:\n",
    "        for cohort in range(n_cohorts):\n",
    "            print(f\"Cohorte {cohort+1} de {n_cohorts}\")\n",
    "            i = cohort * n_treated_in_cohort\n",
    "            ii = 0\n",
    "            while i <= ((cohort + 1) * n_treated_in_cohort - 1):\n",
    "                y = np.zeros(total_periods)\n",
    "                y[0] = (\n",
    "                    MeanFET + EfectoFijoT[i] + EfectoTemporalT.mean()\n",
    "                    + np.random.normal(0, 1) * StdErrorSerie\n",
    "                )\n",
    "                Tr, use = 0, False\n",
    "                treatment_start = ini + first_tr_period + cohort\n",
    "                for t in range(total_periods):\n",
    "                    if (t == treatment_start) and (Tr == 0):\n",
    "                        use = process_entry(y, t, n_per_dep, nolineal, porcentaje, dependence)\n",
    "                        if use:\n",
    "                            Tr = t - ini\n",
    "                    y[t] = (\n",
    "                        (1 - phiT) * (MeanFET + EfectoFijoT[i]\n",
    "                        + EfectoTemporalT.mean()) + phiT * y[t - 1]\n",
    "                        + np.random.normal(0, 1) * StdErrorSerie\n",
    "                    )\n",
    "                if use:\n",
    "                    if ii % 100 == 0:\n",
    "                        print(\n",
    "                            f\"{label}: entrada en {treatment_start-ini} {ii} de {n_treated_in_cohort} \"\n",
    "                            f\"Simulación {sim+1} de {n_simulations}\"\n",
    "                        )\n",
    "                    treatment_starts.append(treatment_start-ini)\n",
    "                    dataset[i, :] = y[ini:]\n",
    "                    i += 1\n",
    "                    ii += 1\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    Y[n_treated:,] = y_control\n",
    "    treatment_starts += treatment_starts\n",
    "    y_counterfac[:n_treated,] = Y[:n_treated,]\n",
    "\n",
    "    # INCORPORACIÓN DEL TRATAMIENTO\n",
    "    for i in range(n_treated):\n",
    "        iniTr = treatment_starts[i]\n",
    "        if hetecohorte == 1:\n",
    "            arparams = np.array([phiTra, 0])\n",
    "            maparams = np.array([0, 0])\n",
    "            arparams = np.r_[1, -arparams]\n",
    "            maparams = np.r_[1, maparams]\n",
    "            impacto = arma_generate_sample(\n",
    "                arparams, maparams, (T-iniTr+1), burnin=5000\n",
    "            ) + ImpactoNominal\n",
    "            Y[i,(iniTr-1):] += impacto\n",
    "        else:\n",
    "            TraCondicion = np.array(treatment_starts)\n",
    "            Y[i,(iniTr-1):] += np.random.normal(ImpactoNominal,STDImpacto,(T-iniTr+1))\n",
    "            TraCondicion = np.array(treatment_starts)\n",
    "\n",
    "    ycte = np.zeros(shape=(n*T,1))\n",
    "    ycte_Cfactual = np.zeros(shape=(n*T,1))\n",
    "    tiempo = np.zeros(shape=(n*T,1))\n",
    "    individuo = np.zeros(shape=(n*T,1))\n",
    "    IniTratmiento = np.zeros(shape=(n*T,1))\n",
    "    tratado = np.zeros(shape=(n*T,1))\n",
    "    control = np.zeros(shape=(n*T,1))\n",
    "    Nini = np.zeros(shape=(n*T,1))\n",
    "    for i in range(n):\n",
    "        iniTr = treatment_starts[i]\n",
    "        cte1 = Y[i,:]\n",
    "        ycte[(i*T):((i+1)*T)] = np.reshape(cte1,(T,1))\n",
    "        cte1_Cfactual = y_counterfac[i,:]\n",
    "        ycte_Cfactual[(i*T):((i+1)*T)] = np.reshape(cte1_Cfactual,(T,1))\n",
    "        cte2 = list(range(1,T+1))\n",
    "        tiempo[(i*T):((i+1)*T)] = np.reshape(cte2, (T,1))\n",
    "        individuo[(i*T):((i+1)*T)] = i\n",
    "        IniTratmiento[(i*T):((i+1)*T)] = iniTr\n",
    "        if i<n_treated:\n",
    "            tratado[(i*T):((i+1)*T)] = 1\n",
    "        else:\n",
    "            control[(i*T):((i+1)*T)] = 1\n",
    "\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),0] = sim+1\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),1] = np.reshape(individuo, (n*T,))\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),2] = np.reshape(tiempo, (n*T,))\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),3] = np.reshape(ycte, (n*T,))\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),4] = np.reshape(IniTratmiento, (n*T,))\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),5] = np.reshape(tratado, (n*T,))\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),6] = np.reshape(control, (n*T,))\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),7] = np.reshape(Nini, (n*T,))\n",
    "    YPanel[(sim*(n*T)):((n*T)*(sim+1)),8] = np.reshape(ycte_Cfactual, (n*T,))\n",
    "\n",
    "    YN = np.zeros(shape=(n_nini,T))\n",
    "    EfectoFijoT = np.random.normal(0,1,n_nini)+MeanFEN\n",
    "\n",
    "    ycte = np.zeros(shape=(n_nini*T,1))\n",
    "    tiempo = np.zeros(shape=(n_nini*T,1))\n",
    "    individuo = np.zeros(shape=(n_nini*T,1))\n",
    "    IniTratmiento = np.zeros(shape=(n_nini*T,1))\n",
    "    tratado = np.zeros(shape=(n_nini*T,1))\n",
    "    control = np.zeros(shape=(n_nini*T,1))\n",
    "    Nini = np.zeros(shape=(n_nini*T,1))\n",
    "    for i in range(n_nini):\n",
    "        y = np.zeros(total_periods)\n",
    "        y[0] = MeanFEN + EfectoFijoT[i] + EfectoTemporalT.mean() + np.random.normal(0,1) * StdErrorSerie\n",
    "        for t in range(total_periods):\n",
    "            y[t] = (1-phiNini) * (MeanFEN + EfectoFijoT[i] + EfectoTemporalT.mean()) + phiNini * y[t - 1] + np.random.normal(0, 1) * StdErrorSerie\n",
    "        YN[i,:] = y[ini:]\n",
    "        cte1 = YN[i,:] + 0\n",
    "        ycte[(i*T):((i+1)*T)] = np.reshape(cte1,(T,1))\n",
    "        cte2 = list(range(1,T+1))\n",
    "        tiempo[(i*T):((i+1)*T)] = np.reshape(cte2, (T,1))\n",
    "        individuo[(i*T):((i+1)*T)] = i + n\n",
    "        Nini[(i*T):((i+1)*T)] = 1\n",
    "\n",
    "    YPanelNiNi[(sim*(n_nini*T)):((n_nini*T)*(sim+1)),0] = sim+1\n",
    "    YPanelNiNi[(sim*(n_nini*T)):((n_nini*T)*(sim+1)),1] = np.reshape(individuo, (n_nini*T,))\n",
    "    YPanelNiNi[(sim*(n_nini*T)):((n_nini*T)*(sim+1)),2] = np.reshape(tiempo, (n_nini*T,))\n",
    "    YPanelNiNi[(sim*(n_nini*T)):((n_nini*T)*(sim+1)),3] = np.reshape(ycte, (n_nini*T,))\n",
    "    YPanelNiNi[(sim*(n_nini*T)):((n_nini*T)*(sim+1)),7] = np.reshape(Nini, (n_nini*T,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos el numpy array a un dataframe en short format\n",
    "columns = ['SimCase','id','time','Y','StartTreat','Treated','Control','Nini','y_ContraFac']\n",
    "\n",
    "panel_treated_and_control_Out = pd.DataFrame(YPanel, columns=columns)\n",
    "panel_NiNi_Out = pd.DataFrame(YPanelNiNi, columns=columns)\n",
    "\n",
    "panel_out = pd.concat([panel_treated_and_control_Out, panel_NiNi_Out])\n",
    "panel_out.head(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el dataframe en un archivo csvs\n",
    "filename = (\n",
    "    'dependence=' + str(dependence) + '-cohorts=' + str(n_cohorts) +\n",
    "    '-NoLineal=' + str(nolineal) +  '-T=' + str(T) + '-n=' + str(n_total) +\n",
    "    '-M='+ str(n_simulations) + '.csv'\n",
    ")\n",
    "CSV_PATH = os.path.join(GROUP_PATH, filename)\n",
    "panel_out.to_csv(CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystata import stata\n",
    "\n",
    "stata.run(f'''\n",
    "import delimited \"{CSV_PATH}\", clear\n",
    "\n",
    "forvalues i=1/{n_simulations} {{\n",
    "    preserve\n",
    "    keep if simcase == `i'\n",
    "    rename time t\n",
    "    rename treated tratado\n",
    "    generate d_tratamiento = (starttreat <= t) * tratado\n",
    "    *drop if t>12\n",
    "    *drop if t<=2\n",
    "    *replace t=t-2\n",
    "    rename starttreat inicio_prog\n",
    "    generate tipo = 1 if tratado == 1\n",
    "    replace tipo = 2 if control == 1\n",
    "    replace tipo = 3 if nini == 1\n",
    "    drop nini\n",
    "    save \"{GROUP_PATH}/Simulacion`i'.dta\", replace\n",
    "    restore\n",
    "}}\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gen-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
