{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaea6ppoSYFx"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import mlflow\n",
    "import mlflow.exceptions\n",
    "import optuna\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from constants import *\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from optuna.visualization import plot_pareto_front, plot_intermediate_values\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils.load_data import *\n",
    "from utils.train_predict import train_validate_loop, predict\n",
    "from utils.early_stopping import EarlyStopping\n",
    "from utils.metrics import *\n",
    "from utils.optuna_utils import *\n",
    "from utils.mlflow_utils import *\n",
    "\n",
    "from models.lstm import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.manual_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(TRACKING_SERVER_URI)\n",
    "try:\n",
    "    mlflow.create_experiment(name=EXPERIMENT_NAME, tags=EXPERIMENT_TAGS)\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(e)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "run = set_active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "group = config['group']\n",
    "simulation = config['simulation']\n",
    "required_periods = config['required_periods']\n",
    "partitions = config['partitions']\n",
    "\n",
    "stata_filepath = os.path.join(DATA_DIR, group, simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PlHQsGhFSYF1"
   },
   "outputs": [],
   "source": [
    "mlflow.log_params({\n",
    "    \"group\": group,\n",
    "    \"simulation\": simulation,\n",
    "    \"filepath\": stata_filepath,\n",
    "    \"required_periods\": required_periods,\n",
    "    \"partitions\": partitions\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5v_3f_FDqHc"
   },
   "source": [
    "**Terminología**:\n",
    "* Tipo 1: individuos tratados.\n",
    "* Tipo 2: individuos de control (i.e. podrían haber sido tratados pero por alguna razón no lo fueron)\n",
    "* Tipo 3: ni tratados ni de control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "sjGpNBoTSYF2",
    "outputId": "a11baa73-7e16-4a5f-a30f-bb37905a19a7"
   },
   "outputs": [],
   "source": [
    "value_columns = ['inicio_prog'] + [f'y(t-{i})' for i in range(required_periods, 0, -1)]\n",
    "type1_df, type2_df, type3_df = get_dfs(stata_filepath, required_periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conjuntos de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df, y_train_df, X_valid_df, y_valid_df, X_test_df, y_test_df = build_train_valid_test_dfs(\n",
    "    type1_df, type2_df, type3_df, partitions\n",
    ")\n",
    "\n",
    "# Class balancing\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(y_train_df), y=y_train_df\n",
    ")\n",
    "print(f\"Peso para la clase 0 (mayoritaria): {weights[0]:.4f}\")\n",
    "print(f\"Peso para la clase 1 (minoritaria): {weights[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stanadarize with training data\n",
    "scaler =  StandardScaler().fit(X_train_df[value_columns])\n",
    "\n",
    "X_train_df[value_columns] = scaler.transform(X_train_df[value_columns])\n",
    "X_valid_df[value_columns] = scaler.transform(X_valid_df[value_columns])\n",
    "X_test_df [value_columns] = scaler.transform(X_test_df [value_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build the datasets with the target column to load them into mlflow\n",
    "train_df = X_train_df.copy()\n",
    "train_df['target'] = y_train_df\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(train_df, targets='target'),\n",
    "    context=\"train\",\n",
    ")\n",
    "\n",
    "valid_df = X_valid_df.copy()\n",
    "valid_df['target'] = y_valid_df\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(valid_df, targets='target'),\n",
    "    context=\"validation\",\n",
    ")\n",
    "\n",
    "test_df = X_test_df.copy()\n",
    "test_df['target'] = y_test_df\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(test_df, targets='target'),\n",
    "    context=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkTV_FJRYJB4"
   },
   "source": [
    "# **LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basados en el documento `docs/lstm.md`, transformemos los datos que tenemos a la forma que necesitan las LSTM:\n",
    "`(batch_size, sequence_length, num_features)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0EVPE5UaP9d"
   },
   "source": [
    "Cada fila es un individuo y en cada fila ya tenemos todo lo que necesitamos, los 4 datos temporales (`y(t-4)`, `y(t-3)`, `y(t-2)`, `y(t-1)`) y además el dato estático (`inicio_prog`) que lo vamos a tener que repetir cuatro veces para tener la dimensión que deseamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WRK3llPh5a2D"
   },
   "outputs": [],
   "source": [
    "time_steps = required_periods\n",
    "\n",
    "# The 2 features are:\n",
    "#  - inicio_prog (static, reamins the same for all time steps)\n",
    "#  - y (dynamic, changes for each time step)\n",
    "num_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = get_lstm_input(X_train_df, time_steps, num_features)\n",
    "X_valid_tensor = get_lstm_input(X_valid_df, time_steps, num_features)\n",
    "X_test_tensor  = get_lstm_input(X_test_df , time_steps, num_features)\n",
    "\n",
    "# When using BCEWithLogitsLoss as loss function, the targets should be casted to\n",
    "# float\n",
    "y_train_tensor = torch.tensor(y_train_df.values, dtype=torch.float)\n",
    "y_valid_tensor = torch.tensor(y_valid_df.values, dtype=torch.float)\n",
    "y_test_tensor  = torch.tensor(y_test_df.values , dtype=torch.float)\n",
    "\n",
    "train_set = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "valid_set = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "test_set  = TensorDataset(X_test_tensor , y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kptxCJGX-Swv"
   },
   "source": [
    "## **Búsqueda de hiperparámetros con Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "study_name = f\"study_{timestamp}\"\n",
    "study_n_trials = 50\n",
    "\n",
    "metrics = config['metrics']\n",
    "directions = config['directions']\n",
    "beta = config['beta']\n",
    "\n",
    "if len(metrics) != len(directions):\n",
    "    raise ValueError(\"The number of metrics and directions should be the same\")\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"study_name\": study_name,\n",
    "    \"study_n_trials\": study_n_trials,\n",
    "    \"objective_metrics\": metrics,\n",
    "    \"directions\": directions\n",
    "})\n",
    "\n",
    "if \"f_beta_score\" in metrics:\n",
    "    mlflow.log_param(\"beta\", beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    directon=directions[0] if len(metrics) == 1 else None,\n",
    "    directions=directions if len(metrics) > 1 else None,\n",
    "    storage=OPTUNA_STORAGE,\n",
    "    study_name=study_name\n",
    ")\n",
    "study.set_metric_names(metrics)\n",
    "study.optimize(\n",
    "    lambda trial: objective(trial, train_set, valid_set, weights, metrics, beta=beta),\n",
    "    n_trials=study_n_trials,\n",
    "    timeout=600,\n",
    "    n_jobs=-1,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(metrics) > 1:\n",
    "    fig = plot_pareto_front(study, target_names=metrics)\n",
    "    log_plot(fig, \"pareto_front_plot.png\")\n",
    "    fig.show()\n",
    "else:\n",
    "    fig = plot_intermediate_values(study)\n",
    "    log_plot(fig, \"intermediate_values_plot.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of trials on the Pareto front: {len(study.best_trials)}\")\n",
    "\n",
    "for i, (metric, direction) in enumerate(zip(metrics, directions)):\n",
    "    if direction == 'maximize':\n",
    "        best_trial = max(study.best_trials, key=lambda t: t.values[i])\n",
    "    elif direction == 'minimize':\n",
    "        best_trial = min(study.best_trials, key=lambda t: t.values[i])\n",
    "    \n",
    "    print(f\"Metric: {metric}\")\n",
    "    print(f\"\\tDirection: {direction}\")\n",
    "    print(f\"\\tTrial number: {best_trial.number}\")\n",
    "    print(f\"\\tValues: {best_trial.values}\")\n",
    "    print(f\"\\tParams: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials_info = get_best_trials_info(study, metrics)\n",
    "log_json(best_trials_info, \"best_trials_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials_numbers = [trial['trial_number'] for trial in best_trials_info]\n",
    "mlflow.log_params({\n",
    "    \"best_trials_numbers\": best_trials_numbers\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entrenamiento del modelo con mejores hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_trial = 14\n",
    "params = study.trials[chosen_trial].params\n",
    "\n",
    "hidden_size = params['hidden_size']\n",
    "n_layers = params['n_layers']\n",
    "lr = params['lr']\n",
    "batch_size = params['batch_size']\n",
    "optimizer_name = params['optimizer']\n",
    "epochs = params['n_epochs']\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = LSTMClassifier(num_features, hidden_size, 1, n_layers).to(device)\n",
    "\n",
    "optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "X_test_tensor = test_set.tensors[0].to(device)\n",
    "\n",
    "if 'avg_feats_diff' in metrics:\n",
    "    train_features_mean = get_features_mean(X_train_tensor, y_train_tensor).to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor(weights[1], dtype=torch.float32)\n",
    ")\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {epoch} -----------------------------------------------------\")\n",
    "    train_step(model, train_loader, loss_fn, optimizer)\n",
    "    \n",
    "    logits = model(X_test_tensor)\n",
    "    y_test_pred = predict(logits, loss_fn).squeeze()\n",
    "\n",
    "    metrics_kwargs = {}\n",
    "    if 'avg_feats_diff' in metrics:\n",
    "        metrics_kwargs['X_valid'] = X_test_tensor\n",
    "        metrics_kwargs['train_features_mean'] = train_features_mean\n",
    "    if 'f_beta_score' in metrics:\n",
    "        metrics_kwargs['beta'] = beta\n",
    "    metrics_values = compute_metrics(metrics, y_test_tensor, y_test_pred, **metrics_kwargs)\n",
    "    pprint.pp(metrics_values)\n",
    "\n",
    "    mlflow.log_metrics(metrics_values, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "y_test_pred = model(X_test_tensor.to('cpu'))\n",
    "y_test_pred = predict(y_test_pred, loss_fn).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = confusion_matrix_plot(y_test_tensor, y_test_pred)\n",
    "log_plot(fig, \"confusion_matrix_plot.png\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TrabajoFinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
