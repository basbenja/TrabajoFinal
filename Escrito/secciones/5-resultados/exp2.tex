\documentclass[../../main.tex]{subfiles}

\begin{document}

\section{Experimento 2: 45 períodos observados, 10 de dependencia}
En este, utilizamos la misma cantidad de períodos observados que en el escenario anterior,
pero disminuimos los períodos de dependencia a la mitad, pasando de 20 a 10, y también la
cantidad máxima de subidas en ellos, pasando de 6 a 3. De esta manera, la proporción entre
períodos de dependencia y períodos observados es de 0.22, y la de subidas sobre períodos
de dependencia se mantiene igual que antes.

% La Tabla \ref{tab:params_exp2} muestra todos los parámetros de este Experimento.
% \begin{table}[H]
%     \centering
%     \begin{tabular}{|c|c|c|c|c|c|c|}
%         \hline
%         \(L\) & \(n_{pd}\) & \(m\) & \(c\) & \(\mu_{EF_T}\) & \(\mu_{EF_C}\) & \(\mu_{EF_{NiNi}}\) \\ \hline\hline
%         45 & 20 & 6 & 3 & 10 & 10 & 10 \\
%         \hline
%     \end{tabular}
%     \caption{Parámetros para la generación de datos utilizados en el Experimento 2.}
%     \label{tab:params_exp2}
% \end{table}

Los resultados obtenidos se encuentran en la Tabla \ref{tab:results_exp2}. Vemos que todas
las métricas disminuyeron considerablemente en comparación al escenario anterior. El
rendimiento del PSM fue muy bajo; y en el caso de las redes resulta particularmente
alarmante el caso de la precisión, que en todos las redes se ubicó cerca de 0.5, indicando
que de los controles identificados por ellas, aproximadamente la mitad realmente lo era.

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|c|c|c|c|}
        \hline
         & \textbf{Puntaje} \(F_1\) & \textbf{Precisión} & \textbf{Sensibilidad} \\ \hline\hline
        \textbf{LSTM}
            & 0.561542 & 0.436014 & 0.793377 \\ \hline
        \textbf{Convolucional}
            & \textbf{0.603795} & \textbf{0.486965} & 0.797973 \\ \hline
        \textbf{LSTM + Convolucional}
            & 0.597708 & 0.47867 & \textbf{0.800186} \\ \hline
        \textbf{PSM}
            & 0.360865 & 0.361332 & 0.3604 \\
        \hline
    \end{tabular}
    \caption{Promedio de las métricas \(F_1\), precisión y sensibilidad sobre la
    clase positiva (controles) en el conjunto de test en las 100 simulaciones del
    Experimento 2.}
    \label{tab:results_exp2}
\end{table}

Los valores de los hiperparámetros se encuentran en la Tabla \ref{tab:results_exp2},
en donde sí se ve la misma tendencia que en el caso anterior: la mejor tasa de aprendizaje
fue por lejos 0.001 en todos los casos, y el mejor dropout fue de 0.3.


\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
            & \makecell{\textbf{Tamaño}\\\textbf{de lote}}
            & \makecell{\textbf{Neuronas en}\\\textbf{capas ocultas}}
            & \makecell{\textbf{Tasa de}\\\textbf{aprendizaje}}
            & \textbf{Dropout} \\ \hline\hline
        \textbf{LSTM}
            & 32 (39\%) & 128 (78\%) & 0.001 (99\%) & 0.3 (51\%) \\ \hline
        \textbf{Convolucional}
            & 32 (42\%) & -          & 0.001 (78\%) & 0.3 (80\%) \\ \hline
        \makecell{\textbf{LSTM +}\\\textbf{Convolucional}}
            & 32 (56\%) & 32 (41\%)  & 0.001 (67\%) & 0.3 (84\%) \\
        \hline
    \end{tabular}
    \caption{Valores de hiperparámetros seleccionados con mayor frecuencia en las 100
    simulaciones en cada arquitectura. Cada celda contiene dicho valor y entre paréntesis
    el porcentaje de simulaciones en el resultó ser el mejor, de acuerdo a la optimización
    realizada por Optuna mediante validación cruzada.}
    \label{tab:hyperparams_exp2}
\end{table}

\end{document}