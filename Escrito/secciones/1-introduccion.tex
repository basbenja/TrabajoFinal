\documentclass[../main.tex]{subfiles}

\begin{document}

Cuando se invierten recursos en un proyecto, suele haber un propósito claro por detrás y,
con el paso del tiempo, surge la necesidad de cuestionarse si lo invertido tuvo algún
efecto real sobre el objetivo que se estaba tratando de lograr. Por ejemplo, si uno decide
dedicarle más horas fuera de clase al estudio de una materia, es normal que nos surja la
pregunta de si realmente esas horas sirvieron. En el caso de una empresa, quizás se espera
que contratando más empleados, se aumenten la productividad y las ganancias. Las políticas
públicas tampoco son una excepción: tomemos el caso de un programa de subsidios para la
compra de alimentos en un determinado sector de la población; aquí resulta aún más
importante analizar si luego de un tiempo, esto ayudó a mejorar, por ejemplo, los niveles
de salud de dicho sector.

En este contexto, cobra relevancia la metodología conocida como \textbf{evaluación de
impacto} \cite{bernal}\cite{gertler-2016}. La evaluación de impacto es una técnica que
permite estimar cuantitativamente los efectos - positivos o negativos - que ha tenido la
implementación de un programa, proyecto o tratamiento sobre determinadas variables de
interés - las variables objetivo - de la población receptora del mismo. La forma en la que
esto se logra es a través de un \textbf{análisis contrafactual}: ¿qué hubiera pasado con
las variables de la población receptora - los ``tratados'' - si el programa no hubiera
existido?

La situación anterior, que recibe comúnmente el nombre de ``el contrafactual'', es sin
dudas un escenario hipotético, no observable en la realidad; y es por esto que es
necesario aproximarlo de alguna forma. Para ello, una técnica consiste en construir un
\textbf{grupo de control} o \textbf{comparación}. Este debería estar formado por unidades
que no han sido beneficiarias del programa pero que, idealmente, antes del inicio del
mismo, eran muy similares a quienes sí lo fueron. Con el grupo de control identificado, se
puede estimar el \textbf{efecto promedio del programa en los tratados} (\(ATT\))
comparando los resultados de ambos grupos \cite{rubin1974}.

Dicho esto, el principal desafío en una evaluación de impacto es construir un grupo de
control \textit{válido}. Esto es, uno que permita asegurar que la diferencia observada en
los resultados se debe pura y exclusivamente al tratamiento en cuestión, y no a otros
factores. Si la asignación al programa es aleatoria, este grupo es todo el conjunto de los
no tratados (dentro de la población elegible). Sin embargo, en políticas donde la
asignación no tiene reglas claras, y se desconocen cuáles son las verdaderas razones que
han llevado a las unidades a participar o no del programa, tomar a los no tratados como
grupo de comparación puede producir estimaciones sesgadas, resultantes de no haber
considerado las diferencias preexistentes entre ambos grupos. Este problema es conocido
como \textbf{sesgo de autoselección} \cite{bernal}\cite{mostly-harmless-econometrics}.

Existen diferentes métodos que buscan mitigar este sesgo, siendo uno bastante utilizada el
\textbf{pareamiento por puntaje de propensión} (PSM)
\cite{psm1983}\cite{a-primer-for-applying-psm}. El PSM consiste en estimar el puntaje de
propensión - también llamado probabilidad de participación - tanto para tratados y no
tratados, y construir un grupo de control emparejando a cada tratado con uno o varios
individuos no tratados que tengan puntajes similares. Para el cálculo de esta
probabilidad, los evaluadores deben seleccionar ciertas variables que consideren
determinantes en la decisión de participar.

Ahora bien, cuando se cree que esta decisión puede estar influida por comportamientos
observados a lo largo del tiempo en períodos previos a la implementación del programa, los
métodos estadísticos utilizados para calcular el puntaje de propensión no son los más
efectivos para capturar posibles patrones y dinámicas, y hacer un emparejamiento adecuado.

Es en estos escenarios donde consideramos que los modelos de \textbf{aprendizaje
automático} \cite{deep-learning}\cite{ai-a-modern-approach} pueden contribuir a una mejor
selección de unidades pertenecientes al grupo de control. El aprendizaje automático es un
campo de la inteligencia artificial cuyo enfoque está en desarrollar técnicas que permitan
a las computadoras aprender automáticamente a partir de los datos, sin la necesidad de
tener que proveerlas de reglas. Esta estrategia facilita la identificación de patrones,
incluso cuando pueden parecer muy difíciles de identificar a simple vista.

Cuando los datos a partir de los cuales los algoritmos aprenden consisten de pares de
``entrada-salida esperada'' - donde la entrada es un conjunto de características que
identifican a cada unidad y la salida esperada puede ser por ejemplo un número o una
categoría -, se utiliza el término \textbf{aprendizaje supervisado}.

Por ejemplo, si se intenta predecir si un alumno va a aprobar o no un examen, cada unidad
sería justamente un alumno, y la entrada podría estar compuesta por sus condiciones
socioeconómicas, su promedio de notas del año anterior, y el nivel de educación de sus
padres. La salida esperada sería ``el alumno aprobó o no''. De esta forma, el algoritmo
aprende a partir de muchos ejemplos de estos para poder predecir la aprobación del examen
de un nuevo alumno.

Un método muy potente dentro del aprendizaje automático que ha tenido un gran desarrollo
en los últimos años es el conocido como \textbf{redes neuronales artificiales}
\cite{nielsen}, cuya inspiración estuvo en el intento de modelar el aprendizaje en el
cerebro humano. Dentro de estas, existen algunos tipos específicos adecuados para el
procesamiento de datos temporales, como las \textbf{redes neuronales recurrentes} (en
particular, las de tipo \textit{long short-term memory}\cite{lstm-paper-1997} ) y las
\textbf{redes neuronales convolucionales} \cite{prince2024understanding}.

En el presente trabajo, proponemos la utilización de estos dos tipos de redes neuronales
para la identificación de grupos de control válidos en contextos donde la asignación al
programa es no aleatoria, potencialmente dependiente de compartamientos temporales
pasados, y cuya implementación se desarrolla en múltiples períodos de tiempo. Con esto,
buscamos aportar una herramienta alternativa para mejorar la calidad de las evaluaciones
de impacto en este tipo de tratamientos.

Para la evaluación de nuestro enfoque, generamos datos sintéticos diseñados para imitar
situaciones reales, y comparamos el desempeño de las redes con el del PSM. Los resultados
obtenidos en los diferentes escenarios modelados indican que las redes superan
consistentemente al PSM, aunque no siempre con valores aceptables. Específicamente, los
mejores valores se vieron en situaciones con una alta cantidad de períodos observados y
tendencias prolongadas con ``ruido'' y en aquellas con una menor cantidad de datos
temporales pero con tendencias monótonas. De esta manera, consideramos que nuestro enfoque
es prometedor y tiene potencial para aplicarse en casos reales.

A continuación, se describe la estructura del trabajo, presentando a grandes rasgos
sobre qué trata cada uno de los capítilos.

\section*{Estructura del trabajo}
En el Capítulo 2, se presentan los conceptos fundamentales necesarios para comprender el
desarrollo de este trabajo. En particular, explicamos en profundidad la metodología de la
evaluación de impacto, los problemas que aparecen y algunas de las técnicas utilizadas.
Luego, nos enfocamos en el aprendizaje automático, centrándonos en las redes neuronales, y
más particularmente en las de tipo LSTM y convoluciones.

Posteriormente, en el Capítulo 3, se describen algunas de las limitaciones que presenta el
PSM en los escenarios estudiados en este trabajo y argumentamos por qué consideramos que
el enfoque propuesto debería de superarlas.

En el Capítulo 4, se detalla el marco experimental utilizado. Se mencionan todas las
decisiones tomadas en las diferentes etapas, desde la generación de datos sintéticos, la
búsqueda de hiperparámetros, las métricas de importancia y la forma de comparar el
desempeño de las redes neuronales con el del PSM.

En el Capítulo 5, se muestran los resultados obtenidos en los diferentes experimentos
llevados a cabo, haciendo especial énfasis en el puntaje \(F_1\), la precisión y la
cobertura, y en los valores de los hiperparámetros hallados en las diferentes
simulaciones.

Finalmente, en el Capítulo 6, se presentan las conclusiones derivadas a partir de los
resultados, se propone una manera de aplicar nuestra alternativa en casos reales, y se
introducen algunos aspectos de nuestro desarrollo que podrían mejorarse en trabajos
futuros.

\end{document}