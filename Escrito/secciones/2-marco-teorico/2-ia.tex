\documentclass[../../main.tex]{subfiles}
% \graphicspath{{\subfix{../images/}}}

\begin{document}
La definición más general acerca de la Inteligencia Artificial (IA) establece que es el
área de las Ciencias de la Computación que se enfoca tanto en entender como en crear
sistemas que simulen comportamientos \textit{inteligentes}. Si bien existen distintas
perspectivas sobre qué significa que una computadora actúe de manera inteligente, la que
más ha prevalecido a lo largo de los años es aquella que refiere con la capacidad de
computar cómo actuar de la mejor manera posible en una determinada situación
\cite{ai-a-modern-approach}.

En sus comienzos, los métodos desarrollados en el área de la IA estaban principalmente
\textbf{basados en conocimiento}, es decir reglas matemáticas formales que permitían a las
computadoras llevar a cabo inferencias lógicas y de esta forma resolver problemas que eran
intelectualmente difíciles para los humanos \cite{deep-learning}.

Sin embargo, determinar reglas que describan la complejidad y diversidad de la realidad no
era una tarea fácil. De esta manera, con el objetivo de hacer a estos sistemas más
flexibles y capaces de adaptarse y entender diferentes situaciones, se transicionó hacia
un enfoque en el que estos pudieran obtener su propio conocimiento aprendiendo patrones
directamente a partir de los datos en lugar de depender exclusivamente de reglas
predefinidas.

Este cambio de paradigma dio lugar a lo que hoy se conoce como \textbf{Aprendizaje
Automático}, la subdisciplina de la IA que permite a los algoritmos mejorar su desempeño
en una tarea específica automáticamente a partir de la experiencia. Diversos factores como
la creciente disponibilidad de datos, el aumento en la capacidad computacional, y los
avances en los algoritmos de optimización \cite{deep-learning} han hecho que esta área sea
la que mayor desarrollo e impacto ha tenido durante las últimas décadas.

Actualmente, la IA abarca una diversidad de tareas, que van desde lo general, como son las
habilidades de aprendizaje, razonamiento, y percepción, entre otras; hasta lo específico,
como probar teoremas matemáticos, manejar vehículos, mejorar procesos industriales o
incluso diagnosticar enfermedades.

\subsection{Aprendizaje Automático}
El Aprendizaje Automático, más conocido por su nombre en inglés \textit{Machine Learning}
(ML), es un campo dentro de la IA cuyo objetivo es desarrollar técnicas que permitan que
las computadoras \textit{aprendan} automáticamente a partir de la \textit{experiencia} -
los datos -, sin la necesidad de ser explícitamente programadas para hacerlo.

Un ejemplo de estos algoritmos puede ser un clasificador de correo spam, que aprende a
distinguir correos spam de regulares viendo ejemplos de cada tipo de correo. Otro ejemplo
puede ser un sistema que aprenda a predecir la edad de una persona a partir de una imagen
habiendo experimentado previamente algunos ejemplos de imagen-edad.

En 1997, Tom Mitchell definió en su libro Machine Learning \cite{ml-tom-mitchell} el
concepto de ``aprender'' de la siguiente manera: ``Se dice que un programa de computadora
aprende de la experiencia E con respecto a una clase de tareas T y una medida de desempeño
P, si su desempeño en las tareas de T, medido por P, mejora con la experiencia E''. Para
tener un mejor entendimiento, nos enfocamos a continuación en cada uno de estos tres
componentes.

Las tareas de ML se describen usualmente en términos de cómo el sistema debería procesar
un \textit{ejemplo} o \textit{entrada}, entendiendo a esta como un conjunto de
características (o en inglés, \textit{features}) medidas cuantitativamente a partir de un
cierto objeto o evento \cite{deep-learning}. Por ejemplo, una entrada puede estar
compuesta por los datos de un hogar, como la cantidad de habitaciones y de baños, si tiene
patio o no, el tamaño de la cocina, etcétera. Dentro de las tareas que pueden ser
resueltas por un sistema de ML se encuentran la clasificación, la regresión, la
traducción, la detección de objetos en imágenes, la generación de nuevos datos, la
detección de valores atípicos, entre muchas otras.

La experiencia hace referencia al tipo de información que el algoritmo ``puede ver''
durante su proceso de aprendizaje o \textit{entrenamiento} \cite{hands-on-ML-sklearn-tf}.
A esta información se la conoce como ``conjunto (de datos) de entrenamiento'', y es un
subconjunto del \textit{dataset}, que es simplemente el conjunto de todos los ejemplos o
datos con los que se cuenta. En base a la experiencia, los algoritmos de ML se clasifican
en dos grandes categorías:
\begin{itemize}
    \item \textbf{Algoritmos de Aprendizaje Supervisado}: experimentan un dataset que
    contiene pares de entrada-salida, esto es cada ejemplo contiene sus features pero
    también su ``etiqueta'', que vendría a ser la ``respuesta correcta'' para dicha
    entrada. El algoritmo aprende una función que asigna (\textit{mapea}) entradas a
    salidas. Las tareas más comunes llevadas a cabo con este tipo de aprendizaje son las
    de regresión, en donde la etiqueta corresponde a un valor continuo; y clasificación,
    en donde la solución viene dada por la categoría (dentro de un conjunto predefinido de
    categorías) a la que pertenece un ejemplo.
    \item \textbf{Algoritmos de Aprendizaje No Supervisado}: ven un dataset que cuenta
    solamente con características de cada entrada pero sin etiquetas, e intentan aprender
    automáticamente patrones y propiedades útiles de la estructura de los datos. Algunas
    tareas que se llevan a cabo con este tipo de aprendizaje son \textit{clustering},
    reducción de dimensionalidad, y detección de anomalías.
\end{itemize}
También existen otros tipos de algoritmos, como los de \textbf{Aprendizaje
Semi-supervisado}, en donde el dataset contiene algunos ejemplos etiquetados y otros sin
etiquetas; y los de \textbf{Aprendizaje por Refuerzo}, en donde el algoritmo aprende la
mejor estrategia para una situación a partir de la interacción con su entorno en forma de
recompensas y castigos.

Por último, para medir el desempeño de estos algoritmos, se definen métricas cuantitativas
que dependen de la tarea que se esté realizando y del objetivo que se intente lograr. Por
ejemplo, en clasificación, una de las más comunes es la de exactitud (\textit{accuracy}),
que es la proporción de ejemplos para los cuales se predijo la salida correcta (dada por
el dataset); aunque también existen otras como la precisión, sensibilidad, especificidad,
y el puntaje F1, que pueden resultar más adecuadas según el dominio del problema. Por otro
lado, en tareas de regresión, algunas métricas que se suelen utilizar son el Error
Cuadrático Medio y el Error Absoluto Medio.

El objetivo fundamental del ML es que un algoritmo actúe correctamente ante nuevas
entradas desconocidas, es decir que \textbf{generalice} más allá de los ejemplos del
conjunto de entrenamiento. Por ello, aunque las métricas anteriores pueden calcularse
durante el entrenamiento para verificar que el algoritmo esté mejorando, su verdadero
desempeño se evalúa en un subconjunto del dataset distinto al de entrenamiento, denominado
``conjunto de test''. Como buena práctica, este conjunto debe permanecer completamente
separado del proceso de aprendizaje para obtener una estimación realista de la capacidad
de generalización del algoritmo.

\bigskip
Habiendo presentado una idea general sobre cuál es el objetivo de los algoritmos de
Aprendizaje Automático, ahora nos enfocaremos en los de Aprendizaje Supervisado, que son
los que usaremos en este trabajo.

\subsection{Aprendizaje Supervisado}
Como mencionamos anteriormente, en el Aprendizaje Supervisado el algoritmo aprende una
función que mapea entradas a salidas a partir de un conjunto de entrenamiento compuesto
por datos etiquetados. El objetivo es que al presentarle a esta función una nueva entrada
no vista previamente, esta sea capaz de computar la salida que mejor se ajusta a los
\textbf{patrones} aprendidos durante el entrenamiento.

Resulta conveniente introducir en este punto un término muy utilizado en el ML:
\textbf{modelo}. Un modelo es simplemente una ecuación matemática, que se presenta como
una forma simplificada de describir hechos de la realidad. En este contexto, será una
manera de intentar capturar las relaciones entre los datos, con el objetivo de hacer
predicciones basadas en los patrones aprendidos de ejemplos previos. Habiendo presentado
este concepto, en general se suele utilizar la palabra modelo para referirse a la función
de la que hablamos en el párrafo anterior.

Formalmente, una tarea de Aprendizaje Supervisado es la siguiente:
\begin{quote}
    Dado un conjunto de entrenamiento de \(N\) ejemplos de entrada-salida:
    \[(\mathbf{x}_1, \mathbf{y}_1), (\mathbf{x}_2, \mathbf{y}_2), ..., (\mathbf{x}_N,
    \mathbf{y}_N)\] donde cada \(\mathbf{x}_i\) es un vector de características
    (\(\mathbf{x}_i \in \mathbb{R}^n\) para algún \(n \in \mathbb{N}\)) e \(\mathbf{y}_i\)
    es la salida correspondiente (\(\mathbf{y}_i \in \mathbb{R}^m\) para algún \(m \in
    \mathbb{N}\)), y cada par fue generado por una \textbf{función desconocida}
    \(\mathbf{\mathbf{y}}=f(\mathbf{x})\), descubrir una función \(h\) que aproxime a la
    función real \(f\) \cite{ai-a-modern-approach}.\\
    Denotaremos con \(\mathbf{X}\) al vector de entradas del conjunto de entrenamiento, y
    con \(\mathbf{Y}\) al vector de salidas, ambos de tamaño \(N\) y bien ordenados. Es
    decir:
    \begin{quote}
        \(\mathbf{X}=(\mathbf{x}_1, \mathbf{x}_2, ..., \mathbf{x}_N)\)\\
        \(\mathbf{Y}=(\mathbf{y}_1, \mathbf{y}_2, ..., \mathbf{y}_N)\)
    \end{quote}
\end{quote}
De esta forma, el modelo es la función \(h\), que toma un vector de entrada \(\mathbf{x}\)
y devuelve una salida \(\mathbf{y}\), y se presenta como una \textbf{hipótesis} de \(f\).
La suposición sobre la que se trabaja es que si el modelo funciona bien para los pares de
entrenamiento, entonces se espera que va a realizar buenas predicciones para nuevas
entradas cuya etiqueta se desconoce.

Ahora bien, esta función \(h\) se obtiene a partir de un \textbf{espacio de funciones},
que es elegido por quien diseña el modelo. Este espacio podría ser el conjunto de
funciones lineales, de polinomios de grado 2, de polinomios de grado 3, etcétera. Por lo
tanto, el espacio determina la forma o ``\textbf{arquitectura}'' que va a tener la función
\(h\), y consecuentemente cuáles son sus parámetros, cuyo vector denotaremos con la letra
\(\bm{\bm{w}}\), y a los que también se suele llamar ``''\textbf{pesos}''. De esta forma,
este espacio determina la familia de posibles relaciones entre entradas y salidas, y los
parámetros especifican la relación particular (el modelo).

Por ejemplo, si suponemos que cada entrada \(\mathbf{x} \in \mathbb{R}\), y establecemos
como espacio el conjunto de funciones lineales, entonces la forma de \(h\) será:
\[h(\mathbf{x}) = w_1 \mathbf{x} + w_0\] y sus parámetros \(\bm{w}=(w_0, w_1)\). Este caso
es comúnmente conocido como regresión lineal unidimensional (ya que la entrada es
simplemente un número real). Dentro de este espacio, distintas asignaciones de valores
a los parámetros generan distintos modelos. Por ejemplo, tomando la asignación
\(\), tenemos el modelo \(h(x) = 5\mathbf{x} + 13\), y tomando \(\),
\(h(\mathbf{x}) = \pi \mathbf{x} + 1.25\), entre muchos otros.

En cambio, si tomamos el conjunto de polinomios de grado 2 y seguimos suponiendo
\(\mathbf{x} \in \mathbb{R}\), entonces la forma de \(h\) será:
\[h(\mathbf{x}) = w_2 \mathbf{x}^2 + w_1 \mathbf{x} + w_0\] y sus parámetros
\(\bm{w}=(w_0, w_1, w_2)\). A este caso se lo suele llamar regresión polinómica de segundo
grado unidimensional.

Otro caso un poco más ``complejo'' podría ser en el que \(\mathbf{x} \in \mathbb{R}^3\), es decir
\(\mathbf{x}=(x_1, x_2, x_3)\) y seguimos tomando una relación lineal. Aquí, \(h\) sería:
\[h(\mathbf{x}) = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_0\] y sus parámetros \(\bm{w}=(w_0, w_1,
w_2, w_3)\)\footnotemark. \footnotetext{Para simplificar la notación, lo que se suele hacer
es asumir que la entrada \(\mathbf{x}\) tiene un componente adicional constante \(x_0\)
con el valor 1, es decir \(\mathbf{x}=(x_0, x_1, x_2, x_3)=(1, x_1, x_2, x_3)\). De esta
forma, podríamos escribir: \(h(\mathbf{x}) = \mathbf{x} \cdot \bm{w}\), donde el operador
\(\cdot\) representa el producto escalar. Retomaremos esta idea más adelante.}

Notemos entonces que, fijado un espacio de funciones, quienes van a determinar qué modelo
es ``mejor'' que otro en este espacio, es decir qué modelo aproxima mejor a \(f\), son los
valores de los parámetros \(w_i\). Por lo tanto, \(h\) en realidad es una función de la
entrada \(\mathbf{x}\) pero también de los parámetros, establecidos por el espacio de funciones
elegido:
\[h(\mathbf{x}, \bm{w})\]
Y lo que querremos idealmente es:
\[f(\mathbf{x}) \approx h(\mathbf{x}, \bm{w})\]

Entonces, cuando un modelo se entrena o aprende, lo que realmente hace es intentar
encontrar los valores de los parámetros que describan la verdadera relación entre entradas
y salidas \cite{prince2024understanding}. Un algoritmo de aprendizaje toma el conjunto de
entrenamiento y manipula los parámetros hasta que las predicciones dadas por él sean lo
más cercanas posible a las etiquetas verdaderas.

Para que el algoritmo sepa cómo modificar estos parámetros para mejorar sus predicciones,
necesita una forma de saber cómo está siendo su desempeño. Para esto, se define lo que se
conoce como \textbf{función de pérdida} o \textbf{función de error}, que denotaremos con
la letra \(L\) y que justamente hace eso: retorna un número que resume qué tan bien o mal
está funcionando el modelo con sus parámetros \(\bm{w}\) actuales, en términos de qué tan
lejos están sus predicciones de las respuestas reales del conjunto de entrenamiento.

Una vez establecida su forma, la \textit{performance} del modelo va a estar dada por los
valores actuales de sus parámetros. Por lo tanto, tiene sentido tratar a la función de
pérdida como una que depende de los parámetros del modelo, es decir
\(L(\bm{w})\)\footnotemark. \footnotetext{En realidad la función de pérdida también depende
de los datos de entrenamiento, por lo que si somos estrictos deberíamos escribir
\(L(\left\{\mathbf{X}, \mathbf{Y}\right\}, \bm{w}\)). Sin embargo, como estos datos están
fijos durante todo el proceso de aprendizaje, podemos omitirlos.} A continuación, se
mencionan dos ejemplos de funciones de error:
\begin{itemize}
    \item Una función de pérdida que se es común usar en problemas de regresión es la de
    Error Cuadrático Medio (ECM), dada por:
    \[
    ECM(\bm{w}) = \frac{1}{N} \sum_{i=1}^{N} \left(h(\mathbf{x}_i, \bm{w}) - \mathbf{y}_i\right)^2
    \]
    \item Para problemas de clasificación binaria como el que tratamos en este trabajo, vamos a tener
    \(\mathbf{y}_i \in \mathbb{R}\), y se suele emplear la Entropía Cruzada Binaria (ECB), dada por:
    \[
    ECB(\bm{w}) = -\frac{1}{N} \sum_{i=1}^{N}
        \left[
            \mathbf{y}_i\ log(h(\mathbf{x}_i, \bm{w})) + (1 - \mathbf{y}_i)\ log(1 - h(\mathbf{x}_i, \bm{w}))
        \right]
    \]
    Sin entrar en detalles, lo que mide esta función es la diferencia entre dos
    distribuciones de probabilidad, que en este caso son la distribución real de los datos
    dada por el conjunto de entrenamiento y la distribución predicha por el modelo en su
    estado actual.
\end{itemize}

En general, se asume que un valor más bajo de \(L(\bm{w})\) indica un mejor desempeño del
modelo, y por lo tanto el objetivo del proceso de entrenamiento se convierte en
\textbf{encontrar los parámetros \(\bm{w}^*\) que minimicen la función de pérdida}
(en los datos del conjunto de entrenamiento):
\[
\bm{w}^* = \arg\min_{\bm{w}} L(\bm{w})
\]
Si luego de la minimización la pérdida es baja, quiere decir que hemos encontrado
parámetros que predicen precisamente las salidas de entrenamiento \(\mathbf{y}_i\) a partir de los
entradas \(\mathbf{x}_i\) (con \(i=1,...,N\)). Sin embargo, como explicamos previamente, la
evaluación final del modelo se debe hacer con el conjunto de test, sobre el cual se puede
también calcular la pérdida.

La pregunta que surge entonces es cómo hacer para lograr esta minimización. Dependiendo
del espacio de funciones y de la función de costo seleccionada, puede que exista una
fórmula cerrada para \(\bm{w}^*\), que se calcule analíticamente. Por ejemplo, en el
caso de la regresión lineal multivariada y tomando como función de pérdida el ECM, se
puede demostrar que la solución cerrada es:
\[
    \bm{w}^* = \left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{Y}
\]

Sin embargo, si la función de costo tiene muchas variables (parámetros) o los modelos son
complejos, resulta más útil recurrir a métodos numéricos para aproximar este mínimo.

El algoritmo más genérico que se utiliza para resolver este problema de optimización es el
llamado \textbf{Descenso por el Gradiente} (DG). Es muy potente ya que se puede aplicar a
cualquier función de pérdida \cite{ai-a-modern-approach}, sin importar el espacio de
funciones elegido.

La idea del DG es ir modificando los parámetros iterativamente hasta eventualmente llegar
a un ``valle'' de la función de pérdida. El algoritmo se basa en que la dirección dada por
el gradiente\footnotemark{} de una función en un punto es la de máximo crecimiento, y por
lo tanto su opuesta es la de máximo decrecimiento. En este caso, la función de la cual se
calcula el gradiente es la de error, con respecto a los parámetros en \(\bm{w}\).
\footnotetext{Dada una función \(g\) de varias variables, es decir, \(g(v_1, v_2, ...,
v_M)\), el \textbf{gradiente} de \(g\) es el vector formado por las derivadas parciales de
\(g\) con respecto a cada uno de sus parámetros:
\[
\nabla g = \left( \frac{\partial g}{\partial v_1}, \frac{\partial g}{\partial v_2},
\dots, \frac{\partial g}{\partial v_M} \right)
\]
donde la notación \(\frac{\partial g}{\partial v_i}\) representa la \textbf{derivada
parcial} de \(g\) con respecto a \(v_i\), que mide cómo cambia \(g\) cuando se varía
\(v_i\) mientras se mantienen constantes las demás variables. Algo a notar es que
el vector resultante es un vector de funciones, y cuando se lo evalúa en un punto,
da la dirección de mayor crecimiento de \(g\) desde ese punto.}

Concretamente, se empieza con un vector de parámetros \(\bm{w}\) con valores arbitrarios que
va mejorando gradualmente, tomando un paso a la vez en dirección opuesta al gradiente, con
el objetivo de reducir el valor de la función de pérdida, hasta que el algoritmo
\textit{converja} a un mínimo (local) de la función de pérdida.

Un hiperparámetro\footnotemark{} determinante en el algoritmo del DG es el tamaño de los
pasos, llamado \textbf{tasa de aprendizaje}, que denotaremos con la letra \(\alpha\) y
supondremos por el momento que se mantiene constante en todo el proceso. Si el valor
\(\alpha\) es muy pequeño, entonces el algoritmo va a tener que realizar muchas
iteraciones para converger \cite{hands-on-ML-sklearn-tf}. Si en cambio el valor es muy
alto, entonces puede ser que vayamos ``saltando'' de un lado a otro de un valle de la
función, haciendo que el algoritmo diverja \cite{hands-on-ML-sklearn-tf}.
\footnotetext{Hablaremos más adelante sobre qué es un hiperparámetro, pero lo importante
es que no es un parámetro que se aprende, como lo son los contenidos en el vector \(\bm{w}\).}

De esta forma, la regla del DG está dada por:
\[
\bm{w}_{p+1} = \bm{w}_{p} - \alpha \nabla L(\bm{w})
\]
donde \(p\) indica el número de iteración actual, \(\nabla L\) representa el
gradiente de la función \(L\), y \(\nabla L(\bm{w})\) es el gradiente evaluado
en los pesos del modelo.

Algo importante a notar es que en la forma que lo presentamos hasta ahora, el cómputo del
gradiente de la función de peso involucra recorrer todas las muestras del conjunto de
entrenamiento, lo cual computacionalmente es ``pesado'' y puede demorar el tiempo de
entrenamiento. Es decir, en cada iteración, el cálculo del gradiente requiere evaluar la
contribución de cada una de las muestras, lo que puede ser caro cuando \(N\) es muy
grande. Para mitigar este problema, existen variantes del DG que buscan aproximar
el gradiente utilizando subconjuntos del conjunto de entrenamiento. Retomaremos este tema
en la proxima sección de Redes Neuronales.

\subsubsection{Resumen}
Hasta aquí hemos hablado de cómo está compuesto prácticamente cualquier algoritmo de
Aprendizaje Supervisado. Los distintos elementos presentes son:
\begin{itemize}[noitemsep]
    \item Un \textbf{conjunto de entrenamiento}, que contiene ejemplos de entrada-salida.
    \item Un \textbf{conjunto de test}, que servirá para evaluar el desempeño real del modelo,
    y nos dará una noción de su capacidad de \textbf{generalización} una vez entrenado.
    \item Un \textbf{espacio de funciones}, que determina la forma de la función \(h\) y los
    parámetros \(\bm{w}\).
    \item Una \textbf{función de pérdida} \(L(\bm{w})\), que mide el desempeño del modelo.
    \item Un \textbf{algoritmo de optimización}, que busca minimizar la función de pérdida,
    siendo el más común el Descenso por el Gradiente.
\end{itemize}

Con esto, el objetivo es encontrar los parámetros \(\bm{w}^*\) que minimicen la función de
pérdida en el conjunto de entrenamiento. Para esto, se comienza con pesos \(\bm{w}\)
arbitarios y, haciendo uso del algoritmo de optimización, se los va modificando iterativamente
hasta llegar a un mínimo (local o global) de \(L(\bm{w})\).

Se trabaja sobre la hipótesis que minimizando el error en el conjunto de entrenamiento, el
modelo tendrá una buena capacidad de generalización. Es decir, habiendo llegado a
\(\bm{w}^*\), se espera que el modelo encontrado tendrá un buen desempeño en el
conjunto de test.

\bigskip
Algo que no hemos discutido hasta el momento es de la correspondencia del espacio de
funciones con el conjunto de datos con el que estamos tratando.

El éxito del Aprendizaje Supervisado depende en gran medida de elegir un espacio de
funciones adecuado que sea capaz de capturar la distribución de los datos. Por ejemplo, si
elegimos un modelo lineal cuando los datos tienen una relación cuadrática, el modelo no
podrá representar correctamente la estructura del problema. Por otro lado, si
seleccionamos un espacio de funciones altamente flexibles - o \textit{expresivas} -, como
polinomios de grado alto, puede ocurrir que el modelo termine describiendo peculiaridades
de los datos de entrenamiento que son atípicas y llevan a predicciones inusuales
\cite{prince2024understanding}.

Si bien existen otros modelos que permiten identificar relaciones no lineales y no
polinómicas, varios de ellos requieren tener un buen conocimiento sobre la estructura de
los datos, y muchas veces su desempeño está condicionado a ciertas transformaciones,
proceso que se conoce por su nombre en inglés \textit{feature engineering}.

En este punto es donde aparecen los modelos conocidos como \textbf{Redes Neuronales}, que
permiten describir un espacio de funciones complejas, expresivas, y no lineales sin la
necesidad de tener un conocimiento profundo sobre los datos. En cambio, son capaces de
aprender las representaciones subyacentes automáticamente. En la sección siguiente,
explicaremos el funcionamiento de estos algoritmos.

\end{document}