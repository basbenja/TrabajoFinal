\documentclass[../../main.tex]{subfiles}
% \graphicspath{{\subfix{../images/}}}

\begin{document}
La definición más general acerca de la Inteligencia Artificial (IA) establece que es el
área de las Ciencias de la Computación que se enfoca tanto en entender como en crear
sistemas que simulen comportamientos \textit{inteligentes}. Si bien existen distintas
perspectivas sobre qué significa que una computadora actúe de manera inteligente, la que
más ha prevalecido a lo largo de los años es aquella que refiere con la capacidad de
computar cómo actuar de la mejor manera posible en una determinada situación
\cite{ai-a-modern-approach}.

En sus comienzos, los métodos desarrollados en el área de la IA estaban principalmente
\textbf{basados en conocimiento}, es decir reglas matemáticas formales que permitían a las
computadoras llevar a cabo inferencias lógicas y de esta forma resolver problemas que eran
intelectualmente difíciles para los humanos \cite{deep-learning}.

Sin embargo, determinar reglas que describan la complejidad y diversidad de la realidad no
era una tarea fácil. De esta manera, con el objetivo de hacer a estos sistemas más
flexibles y capaces de adaptarse y entender diferentes situaciones, se transicionó hacia
un enfoque en el que estos pudieran obtener su propio conocimiento aprendiendo patrones
directamente a partir de los datos en lugar de depender exclusivamente de reglas
predefinidas.

Este cambio de paradigma dio lugar a lo que hoy se conoce como \textbf{Aprendizaje
Automático}, la subdisciplina de la IA que permite a los algoritmos mejorar su desempeño
en una tarea específica automáticamente a partir de la experiencia. Diversos factores como
la creciente disponibilidad de datos, el aumento en la capacidad computacional, y los
avances en los algoritmos de optimización \cite{deep-learning} han hecho que esta área sea
la que mayor desarrollo e impacto ha tenido durante las últimas décadas.

Actualmente, la IA abarca una diversidad de tareas, que van desde lo general, como son las
habilidades de aprendizaje, razonamiento, y percepción, entre otras; hasta lo específico,
como probar teoremas matemáticos, manejar vehículos, mejorar procesos industriales o
incluso diagnosticar enfermedades.

\subsection{Aprendizaje Automático}
El Aprendizaje Automático, más conocido por su nombre en inglés \textit{Machine Learning}
(ML), es un campo dentro de la IA cuyo objetivo es desarrollar técnicas que permitan que
las computadoras \textit{aprendan} automáticamente a partir de la \textit{experiencia} -
los datos -, sin la necesidad de ser explícitamente programadas para hacerlo.

Un ejemplo de estos algoritmos puede ser un clasificador de correo spam, que aprende a
distinguir correos spam de regulares viendo ejemplos de cada tipo de correo. Otro ejemplo
puede ser un sistema que aprenda a predecir la edad de una persona a partir de una imagen
habiendo experimentado previamente algunos ejemplos de imagen-edad.

En 1997, Tom Mitchell definió en su libro Machine Learning \cite{ml-tom-mitchell} el
concepto de ``aprender'' de la siguiente manera: ``Se dice que un programa de computadora
aprende de la experiencia E con respecto a una clase de tareas T y una medida de desempeño
P, si su desempeño en las tareas de T, medido por P, mejora con la experiencia E''. Para
tener un mejor entendimiento, nos enfocamos a continuación en cada uno de estos tres
componentes.

Las tareas de ML se describen usualmente en términos de cómo el sistema debería procesar
un \textit{ejemplo} o \textit{entrada}, entendiendo a esta como un conjunto de
características (o en inglés, \textit{features}) medidas cuantitativamente a partir de un
cierto objeto o evento \cite{deep-learning}. Por ejemplo, una entrada puede estar
compuesta por los datos de un hogar, como la cantidad de habitaciones y de baños, si tiene
patio o no, el tamaño de la cocina, etcétera. Dentro de las tareas que pueden ser
resueltas por un sistema de ML se encuentran la clasificación, la regresión, la
traducción, la detección de objetos en imágenes, la generación de nuevos datos, la
detección de valores atípicos, entre muchas otras. Siguiendo con el ejemplo, podríamos
querer que, en base a las features de las casa, el sistema nos provea un estimado
de su valor.

La experiencia hace referencia al tipo de información que el algoritmo ``puede ver''
durante su proceso de aprendizaje o \textit{entrenamiento} \cite{hands-on-ML-sklearn-tf}.
A esta información se la conoce como ``conjunto (de datos) de entrenamiento'', y es un
subconjunto del \textit{dataset}, que es simplemente el conjunto de todos los ejemplos o
datos con los que se cuenta. En base a la experiencia, los algoritmos de ML se clasifican
en dos grandes categorías:
\begin{itemize}
    \item \textbf{Algoritmos de Aprendizaje Supervisado}: experimentan un dataset que
    contiene pares de entrada-salida, esto es cada ejemplo contiene sus características pero
    también su ``etiqueta'', que vendría a ser la ``respuesta correcta'' para dicha
    entrada, y la que se espera que el sistema aprenda. De esta forma, el algoritmo
    aprende una función que asigna (\textit{mapea}) entradas a salidas. Las tareas más
    comunes llevadas a cabo con este tipo de aprendizaje son las de regresión, en donde la
    etiqueta corresponde a un valor continuo; y clasificación, en donde la solución viene
    dada por la categoría (dentro de un conjunto predefinido de categorías) a la que
    pertenece un ejemplo.
    \item \textbf{Algoritmos de Aprendizaje No Supervisado}: ven un dataset que cuenta
    solamente con features de cada entrada pero sin etiquetas, e intentan aprender
    automáticamente patrones y propiedades útiles de la estructura de los datos. Algunas
    tareas que se llevan a cabo con este tipo de aprendizaje son \textit{clustering},
    reducción de dimensionalidad, y detección de anomalías.
\end{itemize}
También existen otros tipos de algoritmos, como los de \textbf{Aprendizaje
Semi-supervisado}, en donde el dataset contiene algunos ejemplos etiquetados y otros sin
etiquetas; y los de \textbf{Aprendizaje por Refuerzo}, en donde el algoritmo aprende la
mejor estrategia para una situación a partir de la interacción con su entorno en forma de
recompensas y castigos.

Por último, para medir el desempeño de estos algoritmos, se definen métricas cuantitativas
que dependen de la tarea que se esté realizando y del objetivo que se intente lograr. Por
ejemplo, en clasificación, una de las más comunes es la de exactitud (\textit{accuracy}),
que es la proporción de ejemplos para los cuales se predijo la salida correcta (dada por
el dataset); aunque también existen otras como la precisión, sensibilidad, especificidad,
y el puntaje F1, que pueden resultar más adecuadas según el dominio del
problema\footnotetext{Hablaremos de estas más adelante, dando sus fórmulas y lo que
representan.}. Por otro lado, en tareas de regresión, algunas métricas que se suelen
utilizar son el Error Cuadrático Medio y el Error Absoluto Medio.

El objetivo fundamental del ML es que un algoritmo actúe correctamente ante nuevas
entradas desconocidas, es decir que \textbf{generalice} más allá de los ejemplos del
conjunto de entrenamiento. Por ello, aunque las métricas anteriores pueden calcularse
durante el entrenamiento para verificar que el algoritmo esté mejorando, su verdadero
desempeño se evalúa en un subconjunto del dataset distinto al de entrenamiento, denominado
``conjunto de test''. Como buena práctica, este conjunto debe permanecer completamente
separado del proceso de aprendizaje para obtener una estimación realista de la capacidad
de generalización del algoritmo.

\bigskip
Habiendo presentado una idea general sobre cuál es el objetivo de los algoritmos de
Aprendizaje Automático, ahora nos enfocaremos en los de Aprendizaje Supervisado, que son
los que usaremos en este trabajo.

\subsection{Aprendizaje Supervisado}
Como mencionamos anteriormente, en el Aprendizaje Supervisado el algoritmo aprende una
función que mapea entradas a salidas a partir de un conjunto de entrenamiento compuesto
por datos etiquetados. El objetivo es que al presentarle a esta función una nueva entrada
no vista previamente, esta sea capaz de computar la salida que mejor se ajusta a los
\textbf{patrones} aprendidos durante el entrenamiento.

Resulta conveniente introducir en este punto un término muy utilizado en el ML:
\textbf{modelo}. Un modelo es simplemente una ecuación matemática, que se presenta como
una forma simplificada de describir hechos de la realidad. En este contexto, será una
manera de intentar capturar las relaciones entre los datos, con el objetivo de hacer
predicciones basadas en los patrones aprendidos de ejemplos previos. En general, se suele
utilizar la palabra modelo para referirse a la función de la que hablamos en el párrafo
anterior.

Formalmente, una tarea de Aprendizaje Supervisado es la siguiente:
\begin{quote}
    Dado un conjunto de entrenamiento de \(N\) ejemplos de entrada-salida:
    \[(\bm{x}_1, \bm{y}_1), (\bm{x}_2, \bm{y}_2), ..., (\bm{x}_N,
    \bm{y}_N)\] donde cada \(\bm{x}_i\) es un vector de características
    (\(\bm{x}_i \in \mathbb{R}^n\) para algún \(n \in \mathbb{N}\)) e \(\bm{y}_i\)
    es la salida correspondiente (\(\bm{y}_i \in \mathbb{R}^m\) para algún \(m \in
    \mathbb{N}\)), y cada par fue generado por una \textbf{función desconocida}
    \(\bm{\bm{y}}=f(\bm{x})\), descubrir una función \(h\) que aproxime a la
    función real \(f\) \cite{ai-a-modern-approach}.\\
    Denotaremos con \(\bm{X}\) al vector de entradas del conjunto de entrenamiento, y
    con \(\bm{Y}\) al vector de salidas, ambos de tamaño \(N\) y bien ordenados. Es
    decir:
    \begin{quote}
        \(\bm{X}=(\bm{x}_1, \bm{x}_2, ..., \bm{x}_N)\)\\
        \(\bm{Y}=(\bm{y}_1, \bm{y}_2, ..., \bm{y}_N)\)
    \end{quote}
\end{quote}
De esta forma, el modelo es la función \(h\), que toma un vector de entrada \(\bm{x}\)
y devuelve una salida \(\bm{y}\), y se presenta como una \textbf{hipótesis} de \(f\).
La suposición sobre la que se trabaja es que si el modelo funciona bien para los pares de
entrenamiento, entonces se espera que va a realizar buenas predicciones para nuevas
entradas cuya etiqueta se desconoce.

Ahora bien, esta función \(h\) se obtiene a partir de un \textbf{espacio de funciones},
que es elegido por quien diseña el modelo. Este espacio podría ser el conjunto de
funciones lineales, de polinomios de grado 2, de polinomios de grado 3, etcétera. Por lo
tanto, el espacio determina la forma o ``\textbf{arquitectura}'' que va a tener la función
\(h\), y consecuentemente cuáles son sus parámetros, cuyo vector denotaremos con la letra
\(\bm{\bm{w}}\), y a los que también se suele llamar ``\textbf{pesos}''. De esta forma,
este espacio determina la familia de posibles relaciones entre entradas y salidas, y los
parámetros especifican la relación particular (el modelo).

Por ejemplo, si suponemos que cada entrada \(\bm{x} \in \mathbb{R}\), y establecemos
como espacio el conjunto de funciones lineales, entonces la forma de \(h\) será:
\[h(\bm{x}) = w_1 \bm{x} + w_0\] y sus parámetros \(\bm{w}=(w_0, w_1)\). Este caso
es comúnmente conocido como regresión lineal unidimensional (ya que la entrada es
simplemente un número real). Dentro de este espacio, distintas asignaciones de valores
a los parámetros generan distintos modelos. Por ejemplo, tomando la asignación
\(\bm{w}=(13, 5)\), tenemos el modelo \(h(x) = 5\bm{x} + 13\), y tomando \(\bm{w}=(1{.}25, \pi)\),
\(h(\bm{x}) = \pi \bm{x} + 1{.}25\), entre muchos otros.

En cambio, si tomamos el conjunto de polinomios de grado 2 y seguimos suponiendo
\(\bm{x} \in \mathbb{R}\), entonces la forma de \(h\) será:
\[h(\bm{x}) = w_2 \bm{x}^2 + w_1 \bm{x} + w_0\] y sus parámetros
\(\bm{w}=(w_0, w_1, w_2)\). A este caso se lo suele llamar regresión polinómica de segundo
grado unidimensional.

Otro caso un poco más ``complejo'' podría ser en el que \(\bm{x} \in \mathbb{R}^3\), es decir
\(\bm{x}=(x_1, x_2, x_3)\) y seguimos tomando una relación lineal. Aquí, \(h\) sería:
\[h(\bm{x}) = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_0\] y sus parámetros \(\bm{w}=(w_0, w_1,
w_2, w_3)\)\footnotemark. \footnotetext{Para simplificar la notación, lo que se suele hacer
es asumir que la entrada \(\bm{x}\) tiene un componente adicional constante \(x_0\)
con el valor 1, es decir \(\bm{x}=(x_0, x_1, x_2, x_3)=(1, x_1, x_2, x_3)\). De esta
forma, podríamos escribir: \(h(\bm{x}) = \bm{x} \cdot \bm{w}\), donde el operador
\(\cdot\) representa el producto escalar. Retomaremos esta idea más adelante al hablar
sobre Redes Neuronales.}

Notemos entonces que, fijado un espacio de funciones, quienes van a determinar qué modelo
es ``mejor'' que otro en este espacio, es decir qué modelo aproxima mejor a \(f\), son los
valores de los parámetros \(w_i\). Por lo tanto, \(h\) en realidad es una función de la
entrada \(\bm{x}\) pero también de los parámetros, establecidos por el espacio de funciones
elegido:
\[h(\bm{x}, \bm{w})\]

Y lo que querremos idealmente es hallar el vector de parámetros \(\bm{w}^*\) que hagan que
el modelo resultante cumpla:
\[f(\bm{x}) \approx h(\bm{x}, \bm{w}^*)\]
para cada \(\bm{x}\) en el conjunto de entrenamiento.

Entonces, cuando un modelo se entrena o aprende, lo que realmente hace es intentar
encontrar los valores de los parámetros que describan la verdadera relación entre entradas
y salidas \cite{prince2024understanding}. Un algoritmo de aprendizaje toma el conjunto de
entrenamiento y manipula los parámetros de forma iterativa hasta que las predicciones
dadas por él sean lo más cercanas posible a las etiquetas verdaderas.

Para que el algoritmo sepa cómo modificar estos parámetros para mejorar sus predicciones,
necesita una forma de conocer cómo está siendo su desempeño. Para esto, se define lo que se
conoce como \textbf{función de pérdida} o \textbf{función de error}, que denotaremos con
la letra \(L\) y que justamente hace eso: retorna un número que resume qué tan bien o mal
está funcionando el modelo con sus parámetros \(\bm{w}'\) actuales, en términos de qué tan
lejos están sus predicciones de las respuestas reales del conjunto de entrenamiento.

Como venimos enfatizando, lo que caracteriza al modelo en cada iteración es el valor de
sus parámetros. Por lo tanto, tiene sentido tratar a la función de pérdida como una que
depende de estos, es decir \(L(\bm{w})\)\footnotemark. \footnotetext{En realidad la
función de pérdida también depende de los datos de entrenamiento, por lo que si somos
estrictos deberíamos escribir \(L(\left\{\bm{X}, \bm{Y}\right\}, \bm{w}\)). Sin
embargo, como estos datos están fijos durante todo el proceso de aprendizaje, podemos
omitirlos.} A continuación, se mencionan dos ejemplos de funciones de error:
\begin{itemize}
    \item Una función de pérdida que se es común usar en problemas de regresión es la de
    Error Cuadrático Medio (ECM), dada por:
    \[
    ECM(\bm{w}) = \frac{1}{N} \sum_{i=1}^{N} \left(h(\bm{x}_i, \bm{w}) - \bm{y}_i\right)^2
    \]
    \item Para problemas de clasificación binaria como el que tratamos en este trabajo, vamos a tener
    \(\bm{y}_i \in \mathbb{R}\), y se suele emplear la Entropía Cruzada Binaria (ECB), dada por:
    \[
    ECB(\bm{w}) = -\frac{1}{N} \sum_{i=1}^{N}
        \left[
            \bm{y}_i\ ln(h(\bm{x}_i, \bm{w})) + (1 - \bm{y}_i)\ ln(1 - h(\bm{x}_i, \bm{w}))
        \right]
    \]
    donde \(ln\) es la función de logaritmo natural. A grandes rasgos, lo que mide esta
    función es la diferencia entre dos distribuciones de probabilidad, que en este caso
    son la distribución real de los datos dada por el conjunto de entrenamiento y la
    distribución predicha por el modelo en su estado actual.

    Para comprender un poco mejor cómo funciona de manera intuitiva, tomemos un ejemplo
    simple. Supongamos que tenemos una entrada \(\bm{x}'\) cuya etiqueta es \(\bm{y}'=1\),
    y que la salida del modelo es \(h(\bm{x}', \bm{w}') = 0{.}95\). En primera instancia,
    vamos a tener que el lado derecho del término de la sumatoria directamente se anula
    (ya que \(1-\bm{y}' = 1-1 = 0\)). Y, para ver qué pasa con el lado izquierdo, notemos
    que \(ln(h(\bm{x}', \bm{w}')) = ln(0{.}95) \approx -0{.}05\), por lo que multiplicando
    por el (\(-1\)) del comienzo de la fórmula, vamos a tener como resultado \(0{.}05\),
    lo cual es bajo e indica una buena predicción del modelo. Si en cambio la predicción
    hubiera sido \(h(\bm{x}', \bm{w}') = 0{.}25\), tendríamos \(ln(h(\bm{x}', \bm{w}')) =
    ln(0{.}25) \approx -1{.}39\), dando una pérdida de \(1{.}39\).

    Lo que se puede ver es que el lado izquierdo influye cuando la salida esperada para la
    entrada actual es 1, y el lado derecho lo hará cuando la salida esperada es 0.
\end{itemize}

En general, se asume que un valor más bajo de \(L(\bm{w})\) indica un mejor desempeño del
modelo, y por lo tanto el objetivo del proceso de entrenamiento se convierte en
\textbf{encontrar los parámetros \(\bm{w}^*\) que minimicen la función de pérdida}
(en los datos del conjunto de entrenamiento):
\[
\bm{w}^* = \arg\min_{\bm{w}} L(\bm{w})
\]
donde el operador \(\arg\min_{\alpha} g(\alpha)\) da el valor de \(\alpha\)
que minimiza \(g(\alpha)\).

Si luego de la minimización la pérdida es baja, quiere decir que hemos encontrado
parámetros que hacen que el modelo prediga precisamente las salidas de entrenamiento
\(\bm{y}_i\) a partir de los entradas \(\bm{x}_i\) (con \(i=1,...,N\)). Sin
embargo, como explicamos previamente, la evaluación final del modelo se debe hacer con el
conjunto de test, sobre el cual se puede también calcular la pérdida.

La pregunta que surge entonces es cómo hacer para lograr esta minimización. Dependiendo
del espacio de funciones y de la función de costo seleccionada, puede que exista una
fórmula cerrada para \(\bm{w}^*\), que se calcule analíticamente.

Sin embargo, si la función de costo tiene muchas variables (parámetros) o los modelos son
complejos, resulta más útil recurrir a métodos numéricos para aproximar este mínimo.

El algoritmo por defecto que se utiliza para resolver este problema de optimización es el
llamado \textbf{Descenso por el Gradiente} (DG), y es muy potente ya que se puede aplicar a
una gran variedad de funciones de pérdida \cite{ai-a-modern-approach}, siempre que esta
sea diferenciable (a continuación veremos por qué).

La idea del DG es ir modificando los parámetros iterativamente hasta eventualmente llegar
a un ``valle'' de la función de pérdida. El algoritmo se basa en que la dirección dada por
el gradiente\footnotemark{} de una función en un punto es la de máximo crecimiento, y por
lo tanto su opuesta es la de máximo decrecimiento. En este caso, la función de la cual se
calcula el gradiente es la de error, con respecto a los parámetros en \(\bm{w}\).
\footnotetext{Dada una función \(g\) de varias variables, es decir, \(g(v_1, v_2, ...,
v_M)\), el \textbf{gradiente} de \(g\) es el vector formado por las derivadas parciales de
\(g\) con respecto a cada uno de sus parámetros:
\[
\nabla g = \left( \frac{\partial g}{\partial v_1}, \frac{\partial g}{\partial v_2},
\dots, \frac{\partial g}{\partial v_M} \right)
\]
donde la notación \(\frac{\partial g}{\partial v_i}\) representa la \textbf{derivada
parcial} de \(g\) con respecto a \(v_i\), que mide cómo cambia \(g\) cuando se varía
\(v_i\) mientras se mantienen constantes las demás variables. Algo a notar es que
el vector resultante es un vector de funciones, y cuando se lo evalúa en un punto,
da la dirección de mayor crecimiento de \(g\) desde ese punto.}

Concretamente, se empieza con un vector de parámetros \(\bm{w}_0\) con valores arbitrarios
que va mejorando gradualmente, tomando un paso a la vez en dirección opuesta al gradiente,
con el objetivo de reducir el valor de la función de pérdida, hasta que el algoritmo
\textit{converja} a un mínimo (local o global) de la función de pérdida.

Un hiperparámetro\footnotemark{} determinante en el algoritmo del DG es el tamaño de los
pasos, llamado \textbf{tasa de aprendizaje}, que denotaremos con la letra \(\eta\) y
supondremos por el momento que se mantiene constante en todo el proceso. Si el valor
\(\eta\) es muy pequeño, entonces el algoritmo va a tener que realizar muchas
iteraciones para converger \cite{hands-on-ML-sklearn-tf}. Si en cambio el valor es muy
alto, entonces puede ser que vayamos ``saltando'' de un lado a otro de un valle de la
función, haciendo que el algoritmo diverja \cite{hands-on-ML-sklearn-tf}.
\footnotetext{Hablaremos más adelante sobre qué es un hiperparámetro, pero lo importante
es que no es un parámetro que se aprende, como lo son los contenidos en el vector \(\bm{w}\).}

De esta forma, la regla del DG está dada por:
\[
\bm{w}^{(p+1)} = \bm{w}^{(p)} - \eta \nabla L(\bm{w}^{(p)})
\]
donde \(p\) indica el número de iteración actual, y \(\nabla L(\bm{w}^{(p)})\) es el
gradiente de la función de error con respecto a los pesos del modelo, evaluado en los
valores de los pesos de la iteración actual.

Algo importante a notar es que en la forma que lo presentamos hasta ahora, el cómputo del
gradiente de la función de peso involucra recorrer todas las muestras del conjunto de
entrenamiento, lo cual computacionalmente es ``pesado'' y puede demorar el tiempo de
entrenamiento. Es decir, en cada iteración, el cálculo del gradiente requiere evaluar la
contribución de cada una de las muestras, lo que puede ser caro cuando \(N\) es muy
grande. Para mitigar este problema, existen variantes del DG que buscan aproximar
el gradiente utilizando subconjuntos del conjunto de entrenamiento. Retomaremos este tema
en la proxima sección de Redes Neuronales.

\subsubsection{Hiperparámetros}
La mayoría de los algoritmos de ML tienen \textbf{hiperparámetros}, que son ajustes que
permiten controlar tanto la capacidad del modelo como el proceso de entrenamiento. Los
valores de los hiperparámetros no son aprendidos por el algoritmo \cite{deep-learning},
sino que se fijan de antemano y no se modifican a lo largo del entrenamiento.

Con lo visto hasta ahora, podemos pensar en dos ejemplos: el grado del polinomio con el
cual ajustar los datos, y la tasa de aprendizaje del DG. En la sección siguiente, veremos
que existen varios más.

Los hiperparámetros pueden contribuir a que el modelo mejore su desempeño, por lo que
surge el problema de cómo hacer para encontrar el valor óptimo de cada uno. La respuesta a
esto es un proceso llamado \textbf{búsqueda u optimización de hiperparámetros}.

Esta búsqueda se hace de forma empírica: se entrenan distintos modelos con diferentes
hiperparámetros sobre el mismo conjunto de entrenamiento, se mide el desempeño de cada
uno de ellos, y se elige el mejor. Ahora bien, el desempeño no se mide sobre el
conjunto de test, ya que esto admitiría la posibilidad que los hiperparámetros elegidos
funcionen bien para ese conjunto, pero no permitan al modelo generalizar a nuevos
datos \cite{prince2024understanding}.

Por lo tanto, una técnica para realizar correctamente esta búsqueda consiste en construir
una tercera partición del conjunto de datos, además de la de entrenamiento y la de test,
llamada \textbf{conjunto de validación}. De esta forma, en la búsqueda de hiperparámetros,
el modelo se sigue entrenando con el conjunto de entrenamiento, pero su performance se
mide en el de validación, dejando al de test como si no existiese. Una vez que se han
elegido los mejores hiperparámetros, se entrena el modelo con el conjunto de entrenamiento
y se mide su capacidad real de generalización sobre el conjunto de test.

Otra estrategia para llevar a cabo esta optimización se denomina \textbf{validación
cruzada} (\textit{cross-validation}). Consiste en dividir el conjunto de entrenamiento en
\(k\) partes (disjuntas), y luego entrenar el modelo \(k\) veces, cada vez utilizando
\(k-1\) partes para el entrenamiento y la parte restante para la validación. En este caso,
habiendo seleccionado una métrica particular, el rendimiento del modelo con ciertos
hiperparámetros va a estar dado por el promedio del puntaje obtenido en cada partición. Al
igual que antes, una vez que se han elegido los mejores hiperparámetros, se entrena el
modelo con el conjunto de entrenamiento (sin particionar) y se mide su capacidad real de
generalización sobre el conjunto de test.

Algo a tener en cuenta es que aunque el espacio de hiperparámetros suele ser más pequeño
que el de los parámetros del modelo en sí, puede seguir siendo lo suficientemente grande
como para probar cada combinación de manera exhaustiva \cite{prince2024understanding}.
Ante esto, existen algoritmos de optimización de hiperparámetros que eligen
inteligentemente qué combinaciones ir probando, con base en resultados anteriores
\cite{prince2024understanding}. Sin embargo, cabe notar que esta parte del entrenamiento
de un modelo es una de las más costosas computacionalmente y en tiempo.

\subsubsection{Resumen}
Hasta aquí hemos hablado de cómo está compuesto prácticamente cualquier algoritmo de
Aprendizaje Supervisado. Los distintos elementos presentes son:
\begin{itemize}[noitemsep]
    \item Un \textbf{conjunto de entrenamiento}, que contiene ejemplos de entrada-salida.
    \item Un \textbf{conjunto de test}, que servirá para evaluar el desempeño real del modelo,
    y nos dará una noción de su capacidad de \textbf{generalización} una vez entrenado.
    \item Un \textbf{espacio de funciones}, que determina la forma de la función \(h\) y los
    parámetros \(\bm{w}\).
    \item Una \textbf{función de pérdida} \(L(\bm{w})\), que mide el desempeño del modelo
    y ayuda a guiar el entrenamiento.
    \item Un \textbf{algoritmo de optimización}, que busca minimizar la función de pérdida,
    siendo el más común el Descenso por el Gradiente.
\end{itemize}

Con esto, el objetivo es encontrar los parámetros \(\bm{w}^*\) que minimicen la función de
pérdida en el conjunto de entrenamiento. Para esto, se comienza con pesos \(\bm{w}\)
arbitarios y, haciendo uso del algoritmo de optimización, se los va modificando iterativamente
hasta llegar a un mínimo (local o global) de \(L(\bm{w})\).

Se trabaja sobre la hipótesis que minimizando el error en el conjunto de entrenamiento, el
modelo tendrá una buena capacidad de generalización. Es decir, habiendo llegado a
\(\bm{w}^*\), se espera que el modelo encontrado tendrá un buen desempeño en el
conjunto de test.

\bigskip
Como venimos enfatizando, el principal desafío del ML es hacer que un modelo tenga una
buena capacidad de generalización, es decir que actúe de manera correcta ante entradas aún
no vistas. Por un lado, esto depende de qué tan representativo es el conjunto de
entrenamiento. Pero por otro, también depende de la elección de un espacio de
funciones adecuado, cuyos modelos sean lo suficientemente \textit{expresivos} como para
capturar la distribución de los datos.

Sin embargo, más allá de la expresividad que otorgue el espacio de funciones y de la
representatividad del conjunto de entrenamiento, existe otra variable presente, que es la
dimensionalidad de los datos. La capacidad de generalizar se vuelve aún más complicada
cuando los datos son de altas dimensiones, es decir cada entrada contiene muchas
características.

En este contexto, aparecen los modelos conocidos como \textbf{Redes Neuronales}, que no
solo permiten describir conjuntos de funciones complejas, expresivas, y no lineales sin la
necesidad de tener un conocimiento profundo sobre la estructura subyacente de los datos,
sino que también son capaces de trabajar con espacios de alta dimensión. En la sección
siguiente, explicaremos el funcionamiento de estos modelos.

% A grandes rasgos, los factores que determinan qué tan bien un algoritmo de ML
% se va a desempeñar son sus capacidades para \cite{deep-learning}:
% \begin{itemize}[itemsep=0.1cm]
%     \item Reducir el error en el conjunto de entrenamiento.
%     \item Reducir la brecha entre el error en el conjunto de entrenamiento y en el de
%     test.
% \end{itemize}

% Estos dos factores están relacionados con dos conceptos fundamentales en el ML: el
% \textbf{subajuste} (\textit{underfitting}) y el \textbf{sobreajuste}
% (\textit{overfitting}).

% El underfitting ocurre cuando el modelo no es lo suficientemente ``potente'' como para
% lograr tener un error bajo en el conjunto de entrenamiento. Generalmente, esto sucede
% porque las funciones del espacio elegido son demasiado simples como para lograr aprender
% correctamente la estructura subyacente del problema. Un ejemplo podría ser elegir un modelo
% lineal cuando los datos en realidad tienen una relación cuadrática.

% Por otro lado, si seleccionamos un espacio de funciones altamente flexibles como pueden
% ser polinomios de grado alto, puede ocurrir que el modelo aprenda tan bien los datos de
% entrenamiento que termine describiendo peculiaridades atípicas de ellos que posteriormente
% llevan a predicciones inusuales sobre nuevos datos \cite{prince2024understanding}. Es
% decir, en estos casos la brecha entre el error en el conjunto de entrenamiento y el de
% test sea probablemente grande. Esta situación es lo que se llama sobreajuste.

% Si bien existen otros modelos que permiten identificar relaciones no lineales y no
% polinómicas, varios de ellos requieren tener un buen conocimiento sobre la estructura de
% los datos, y muchas veces su desempeño está condicionado a ciertas transformaciones sobre
% los mismos, proceso que se conoce por su nombre en inglés \textit{feature engineering}.
\end{document}