\documentclass[../../main.tex]{subfiles}
% \graphicspath{{\subfix{../images/}}}

\begin{document}
La definición más general acerca de la Inteligencia Artificial (IA) establece que es el área de las Ciencias de la Computación que se enfoca tanto en entender como en crear sistemas que simulen comportamientos \textit{inteligentes}. Si bien existen distintas perspectivas sobre qué significa que una computadora actúe de manera inteligente, la que más ha prevalecido a lo largo de los años es aquella que refiere con la capacidad de computar cómo actuar de la mejor manera posible en una determinada situación \cite{ai-a-modern-approach}. 

En sus comienzos, los métodos desarrollados en el área de la IA estaban principalmente \textbf{basados en conocimiento}, es decir reglas matemáticas formales que permitían a las computadoras llevar a cabo inferencias lógicas y de esta forma resolver problemas que eran intelectualmente difíciles para los humanos \cite{deep-learning}.

Sin embargo, determinar reglas que describan la complejidad y diversidad de la realidad no era una tarea fácil. De esta manera, con el objetivo de hacer a estos sistemas más flexibles y capaces de adaptarse y entender diferentes situaciones, se transicionó hacia un enfoque en el que estos pudieran obtener su propio conocimiento aprendiendo patrones directamente a partir de los datos en lugar de depender exclusivamente de reglas predefinidas.

Este cambio de paradigma dio lugar a lo que hoy se conoce como \textbf{Aprendizaje Automático}, la subdisciplina de la IA que permite a los algoritmos mejorar su desempeño en una tarea específica automáticamente a partir de la experiencia. Diversos factores como la creciente disponibilidad de datos, el aumento en la capacidad computacional, y los avances en los algoritmos de optimización \cite{deep-learning} han hecho que esta área sea la que mayor desarrollo e impacto ha tenido durante las últimas décadas. 

Actualmente, la IA abarca una diversidad de tareas, que van desde lo general, como son las habilidades de aprendizaje, razonamiento, y percepción, entre otras; hasta lo específico, como probar teoremas matemáticos, manejar vehículos, mejorar procesos industriales o incluso diagnosticar enfermedades.

\subsection{Aprendizaje Automático}
El Aprendizaje Automático, más conocido por su nombre en inglés \textit{Machine Learning} (ML), es un campo dentro de la IA cuyo objetivo es desarrollar técnicas que permitan que las computadoras \textit{aprendan} automáticamente a partir de la \textit{experiencia} - los datos -, sin la necesidad de ser explícitamente programadas para hacerlo.

Un ejemplo de estos algoritmos puede ser un clasificador de correo spam, que aprende a distinguir correos spam de regulares viendo ejemplos de cada tipo de correo. Otro ejemplo puede ser un sistema que aprenda a predecir la edad de una persona a partir de una imagen habiendo experimentado previamente algunos ejemplos de imagen-edad.

En 1997, Tom Mitchell definió en su libro \textit{Machine Learning} \cite{ml-tom-mitchell} el concepto de ``aprender'' de la siguiente manera: ``Se dice que un programa de computadora aprende de la experiencia E con respecto a una clase de tareas T y una medida de desempeño P, si su desempeño en las tareas de T, medido por P, mejora con la experiencia E''. Para tener un mejor entendimiento, nos enfocamos a continuación en cada uno de estos tres componentes.

Las tareas de ML se describen usualmente en términos de cómo el sistema debería procesar un \textit{ejemplo} o \textit{entrada}, entendiendo a esta como un conjunto de características (o en inglés, \textit{features}) medidas cuantitativamente a partir de un cierto objeto o evento \cite{deep-learning}. Por ejemplo, una entrada puede estar compuesta por los datos de un hogar, como la cantidad de habitaciones y de baños, si tiene patio o no, el tamaño de la cocina, etcétera. Dentro de las tareas que pueden ser resueltas por un sistema de ML se encuentran la clasificación, la regresión, la traducción, la detección de objetos en imágenes, la generación de nuevos datos, la detección de valores atípicos, entre muchas otras.

La experiencia hace referencia al tipo de información que el modelo ``puede ver'' durante su proceso de aprendizaje o \textit{entrenamiento} \cite{hands-on-ML-sklearn-tf}. A esta información se la conoce como ``conjunto (de datos) de entrenamiento'', y es un subconjunto del \textit{dataset}, que es simplemente el conjunto de todos los ejemplos o datos con los que se cuenta. En base a la experiencia, los algoritmos de ML se clasifican en dos grandes categorías:
\begin{itemize}
    \item \textbf{Algoritmos de Aprendizaje Supervisado}: experimentan un dataset que contiene pares de entrada-salida, esto es cada ejemplo contiene sus features pero también su ``etiqueta'', que vendría a ser la ``respuesta correcta'' para dicha entrada. El algoritmo aprende una función que asigna (\textit{mapea}) entradas a salidas. Las tareas más comunes llevadas a cabo con este tipo de aprendizaje son las de regresión, en donde la etiqueta corresponde a un valor continuo; y clasificación, en donde la solución viene dada por la categoría (dentro de un conjunto de predefinido de categorías) a la que pertenece un ejemplo.
    \item \textbf{Algoritmos de Aprendizaje No Supervisado}: ven un dataset que cuenta solamente con características de cada entrada pero sin etiquetas, e intentan aprender automáticamente patrones y propiedades útiles de la estructura de los datos. Algunas tareas que se llevan a cabo con este tipo de aprendizaje son \textit{clustering}, reducción de dimensionalidad, y detección de anomalías.
\end{itemize}
También existen otros tipos de algoritmos, como los de \textbf{Aprendizaje Semi-supervisado}, en donde el dataset contiene algunos ejemplos etiquetados y otros sin etiquetas; y los de \textbf{Aprendizaje por Refuerzo}, en donde el algoritmo aprende la mejor estrategia para una situación a partir de la interacción con su entorno en forma de recompensas y castigos.

Por último, para medir el desempeño de estos modelos, se definen métricas cuantitativas que dependen de la tarea que se esté realizando y del objetivo que se intente lograr. Por ejemplo, en clasificación, una de las más comunes es la de exactitud (\textit{accuracy}), que es la proporción de ejemplos para los cuales el modelo predijo la salida correcta (dada por el dataset); aunque también existen otras como la precisión, sensibilidad, especificidad, y el puntaje F1, que pueden resultar más adecuadas según el dominio del problema. Por otro lado, en tareas de regresión, algunas métricas que se suelen utilizar son el Error Cuadrático Medio y el Error Absoluto Medio. 

El objetivo fundamental del ML es que un algoritmo actúe correctamente antes nuevas entradas aún no vistas, es decir que \textbf{generalice} más allá de los ejemplos del conjunto de entrenamiento. Por ello, aunque las métricas anteriores pueden calcularse durante el entrenamiento para verificar que el modelo esté mejorando, su verdadero desempeño se evalúa en un subconjunto del dataset distinto al de entrenamiento, denominado ``conjunto de test''. Como buena práctica, este conjunto debe permanecer completamente separado del proceso de aprendizaje para obtener una estimación realista de la capacidad de generalización del modelo.

\bigskip
Habiendo presentado una idea general sobre cuál es el objetivo de los algoritmos de Aprendizaje Automático, ahora nos enfocaremos en los de Aprendizaje Supervisado, que son los que usaremos en este trabajo.

\subsubsection{Aprendizaje Supervisado}
Como mencionamos anteriormente, en el Aprendizaje Supervisado el algoritmo aprende a partir de un conjunto de entrenamiento compuesto por pares de entrada y salida. El objetivo es que cuando al modelo se le presente una nueva entrada no vista previamente, este sea capaz de predecir la salida que mejor se ajusta a los \textbf{patrones} aprendidos durante el entrenamiento.

Formalmente, una tarea de Aprendizaje Supervisado es la siguiente:
\begin{quote}
    Dado un conjunto de entrenamiento de \(N\) ejemplos de entrada-salida:
    \[(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\]
    donde cada par fue generado por una \textbf{función desconocida} \(y=f(x)\), descubrir una función \(h\) que aproxime a la función real \(f\) \cite{ai-a-modern-approach}.
\end{quote}
De esta forma, el modelo es simplemente una función \(h\) que toma una entrada \(x\) y una salida \(y\), y se presenta como una \textbf{hipótesis} de \(f\). La suposición sobre la que se trabaja es que si el modelo funciona bien para los pares de entrenamiento, entonces se espera que va a realizar buenas predicciones para nuevas entradas cuya etiqueta se desconoce.

Ahora bien, esta función \(h\) se obtiene a partir de un \textbf{espacio de funciones}, que es elegido por quien diseña el modelo. Este espacio podría ser el conjunto de funciones lineales, de polinomios de grado 2, de polinomios de grado 3, etcétera. Por lo tanto, el espacio determina la forma que va a tener la función \(h\), y consecuentemente cuáles son sus parámetros, que denotaremos con la letra \(\phi\).

Por ejemplo, si establecemos como espacio el conjunto de funciones lineales, entonces la forma de \(h\) será:
\[h(x) = \phi_1 x + \phi_0\]
y sus parámetros \(\phi_1\) y \(\phi_0\).

En cambio, si tomamos el conjunto de polinomios de grado 2, entonces la forma de \(h\) será:
\[h(x) = \phi_2 x^2 + \phi_1 x + \phi_0\]
y sus parámetros \(\phi_2\), \(\phi_1\) y \(\phi_0\).

Notemos entonces que quienes van a determinar qué modelo es ``mejor'' que otro, es decir qué modelo aproxima mejor a \(f\), son los valores de los parámetros \(\phi_i\). Por lo tanto, \(h\) en realidad es una función de la entrada \(x\) pero también de los parámetros, establecidos por el espacio de funciones elegido:
\[h(x, \phi)\]
Y lo que querremos idealmente es:
\[f(x) \approx h(x, \phi)\]

Entonces, cuando un modelo se entrena o aprende, lo que realmente hace es encontrar los valores de los parámetros que describan la verdadera relación entre entradas y salidas \cite{prince2024understanding}. Un algoritmo de aprendizaje toma el conjunto de entrenamiento y manipula los parámetros hasta que las predicciones dadas por él sean lo más cercanas posible a las etiquetas verdaderas.

Para que el algoritmo sepa cómo modificar estos parámetros para mejorar sus predicciones, necesita una forma de saber cómo está siendo desempeño. Para esto, se define lo que se conoce como \textbf{función de pérdida}, que denotaremos con la letra \(L\) y que justamente hace eso: retorna un número que resume qué tan bien o mal está funcionando el modelo con sus parámetros \(\phi\) actuales, en términos de qué tan lejos están sus predicciones de las respuestas reales del conjunto de entrenamiento. A esta función la denotaremos con la letra \(L\).

Por lo tanto, podemos tratar a esta función como una que depende de los parámetros del modelo, es decir \(L(\phi)\). Y, como por convención se asume que un valor más bajo de \(L(\phi)\) indica un mejor desempeño del modelo, el objetivo del proceso de entrenamiento es encontrar los parámetros \(\phi^*\) que minimicen esta función de pérdida:
\[
\phi^* = \arg\min_{\phi} L(\phi)
\]
Si luego de la minimización la pérdida es baja, quiere decir que hemos encontrado parámetros que predicen precisamente las salidas de entrenamiento \(y_i\) a partir de los entradas \(x_i\) (con \(i=1,...,N\)).

% Agregar que en realidad la función de pérdida también depende de los datos de entrenamiento pero que están fijos entonces no se los escribe


\end{document}