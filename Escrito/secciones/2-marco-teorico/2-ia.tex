\documentclass[../../main.tex]{subfiles}
% \graphicspath{{\subfix{../images/}}}

\begin{document}
La definición más general acerca de la Inteligencia Artificial (IA) establece que es el
área de las Ciencias de la Computación que se enfoca tanto en entender como en crear
sistemas que simulen comportamientos \textit{inteligentes}. Si bien existen distintas
perspectivas sobre qué significa que una computadora actúe de manera inteligente, la que
más ha prevalecido a lo largo de los años es aquella que refiere con la capacidad de
computar cómo actuar de la mejor manera posible en una determinada situación
\cite{ai-a-modern-approach}.

En sus comienzos, los métodos desarrollados en el área de la IA estaban principalmente
\textbf{basados en conocimiento}, es decir reglas matemáticas formales que permitían a las
computadoras llevar a cabo inferencias lógicas y de esta forma resolver problemas que eran
intelectualmente difíciles para los humanos \cite{deep-learning}.

Sin embargo, determinar reglas que describan la complejidad y diversidad de la realidad no
era una tarea fácil. De esta manera, con el objetivo de hacer a estos sistemas más
flexibles y capaces de adaptarse y entender diferentes situaciones, se transicionó hacia
un enfoque en el que estos pudieran obtener su propio conocimiento aprendiendo patrones
directamente a partir de los datos en lugar de depender exclusivamente de reglas
predefinidas.

Este cambio de paradigma dio lugar a lo que hoy se conoce como \textbf{Aprendizaje
Automático}, la subdisciplina de la IA que permite a los algoritmos mejorar su desempeño
en una tarea específica automáticamente a partir de la experiencia. Diversos factores como
la creciente disponibilidad de datos, el aumento en la capacidad computacional, y los
avances en los algoritmos de optimización \cite{deep-learning} han hecho que esta área sea
la que mayor desarrollo e impacto ha tenido durante las últimas décadas.

Actualmente, la IA abarca una diversidad de tareas, que van desde lo general, como son las
habilidades de aprendizaje, razonamiento, y percepción, entre otras; hasta lo específico,
como probar teoremas matemáticos, manejar vehículos, mejorar procesos industriales o
incluso diagnosticar enfermedades.

\subsection{Aprendizaje Automático}
El Aprendizaje Automático, más conocido por su nombre en inglés \textit{Machine Learning}
(ML), es un campo dentro de la IA cuyo objetivo es desarrollar técnicas que permitan que
las computadoras \textit{aprendan} automáticamente a partir de la \textit{experiencia} -
los datos -, sin la necesidad de ser explícitamente programadas para hacerlo.

Un ejemplo de estos algoritmos puede ser un clasificador de correo spam, que aprende a
distinguir correos spam de regulares viendo ejemplos de cada tipo de correo. Otro ejemplo
puede ser un sistema que aprenda a predecir la edad de una persona a partir de una imagen
habiendo experimentado previamente algunos ejemplos de imagen-edad.

En 1997, Tom Mitchell definió en su libro Machine Learning \cite{ml-tom-mitchell} el
concepto de ``aprender'' de la siguiente manera: ``Se dice que un programa de computadora
aprende de la experiencia E con respecto a una clase de tareas T y una medida de desempeño
P, si su desempeño en las tareas de T, medido por P, mejora con la experiencia E''. Para
tener un mejor entendimiento, nos enfocamos a continuación en cada uno de estos tres
componentes.

Las tareas de ML se describen usualmente en términos de cómo el sistema debería procesar
un \textit{ejemplo} o \textit{entrada}, entendiendo a esta como un conjunto de
características (o en inglés, \textit{features}) medidas cuantitativamente a partir de un
cierto objeto o evento \cite{deep-learning}. Por ejemplo, una entrada puede estar
compuesta por los datos de un hogar, como la cantidad de habitaciones y de baños, si tiene
patio o no, el tamaño de la cocina, etcétera. Dentro de las tareas que pueden ser
resueltas por un sistema de ML se encuentran la clasificación, la regresión, la
traducción, la detección de objetos en imágenes, la generación de nuevos datos, la
detección de valores atípicos, entre muchas otras.

La experiencia hace referencia al tipo de información que el algoritmo ``puede ver''
durante su proceso de aprendizaje o \textit{entrenamiento} \cite{hands-on-ML-sklearn-tf}.
A esta información se la conoce como ``conjunto (de datos) de entrenamiento'', y es un
subconjunto del \textit{dataset}, que es simplemente el conjunto de todos los ejemplos o
datos con los que se cuenta. En base a la experiencia, los algoritmos de ML se clasifican
en dos grandes categorías:
\begin{itemize}
    \item \textbf{Algoritmos de Aprendizaje Supervisado}: experimentan un dataset que
    contiene pares de entrada-salida, esto es cada ejemplo contiene sus features pero
    también su ``etiqueta'', que vendría a ser la ``respuesta correcta'' para dicha
    entrada. El algoritmo aprende una función que asigna (\textit{mapea}) entradas a
    salidas. Las tareas más comunes llevadas a cabo con este tipo de aprendizaje son las
    de regresión, en donde la etiqueta corresponde a un valor continuo; y clasificación,
    en donde la solución viene dada por la categoría (dentro de un conjunto predefinido de
    categorías) a la que pertenece un ejemplo.
    \item \textbf{Algoritmos de Aprendizaje No Supervisado}: ven un dataset que cuenta
    solamente con características de cada entrada pero sin etiquetas, e intentan aprender
    automáticamente patrones y propiedades útiles de la estructura de los datos. Algunas
    tareas que se llevan a cabo con este tipo de aprendizaje son \textit{clustering},
    reducción de dimensionalidad, y detección de anomalías.
\end{itemize}
También existen otros tipos de algoritmos, como los de \textbf{Aprendizaje
Semi-supervisado}, en donde el dataset contiene algunos ejemplos etiquetados y otros sin
etiquetas; y los de \textbf{Aprendizaje por Refuerzo}, en donde el algoritmo aprende la
mejor estrategia para una situación a partir de la interacción con su entorno en forma de
recompensas y castigos.

Por último, para medir el desempeño de estos algoritmos, se definen métricas cuantitativas
que dependen de la tarea que se esté realizando y del objetivo que se intente lograr. Por
ejemplo, en clasificación, una de las más comunes es la de exactitud (\textit{accuracy}),
que es la proporción de ejemplos para los cuales se predijo la salida correcta (dada por
el dataset); aunque también existen otras como la precisión, sensibilidad, especificidad,
y el puntaje F1, que pueden resultar más adecuadas según el dominio del problema. Por otro
lado, en tareas de regresión, algunas métricas que se suelen utilizar son el Error
Cuadrático Medio y el Error Absoluto Medio.

El objetivo fundamental del ML es que un algoritmo actúe correctamente ante nuevas
entradas desconocidas, es decir que \textbf{generalice} más allá de los ejemplos del
conjunto de entrenamiento. Por ello, aunque las métricas anteriores pueden calcularse
durante el entrenamiento para verificar que el algoritmo esté mejorando, su verdadero
desempeño se evalúa en un subconjunto del dataset distinto al de entrenamiento, denominado
``conjunto de test''. Como buena práctica, este conjunto debe permanecer completamente
separado del proceso de aprendizaje para obtener una estimación realista de la capacidad
de generalización del algoritmo.

\bigskip
Habiendo presentado una idea general sobre cuál es el objetivo de los algoritmos de
Aprendizaje Automático, ahora nos enfocaremos en los de Aprendizaje Supervisado, que son
los que usaremos en este trabajo.

\begin{comment}
En este contexto, un modelo será una forma de intentar capturar las relaciones entre los
datos, con el objetivo de hacer predicciones o tomar decisiones basadas en patrones
aprendidos de ejemplos previos.
\end{comment}

\subsubsection{Aprendizaje Supervisado}
Como mencionamos anteriormente, en el Aprendizaje Supervisado el algoritmo aprende una
función que mapea entradas a salidas a partir de un conjunto de entrenamiento compuesto
por datos etiquetados. El objetivo es que al presentarle a esta función una nueva entrada
no vista previamente, esta sea capaz de computar la salida que mejor se ajusta a los
\textbf{patrones} aprendidos durante el entrenamiento.

Resulta conveniente introducir en este punto un término muy utilizado en el ML:
\textbf{modelo}. Un modelo es simplemente una ecuación matemática, que se presenta como
una forma simplificada de describir hechos de la realidad. En este contexto, será una
manera de intentar capturar las relaciones entre los datos, con el objetivo de hacer
predicciones basadas en los patrones aprendidos de ejemplos previos. Habiendo presentado
este concepto, la función de la que hablamos en el párrafo anterior se suele llamar
modelo.

Formalmente, una tarea de Aprendizaje Supervisado es la siguiente:
\begin{quote}
    Dado un conjunto de entrenamiento de \(N\) ejemplos de entrada-salida:
    \[(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\] donde cada par fue generado por una
    \textbf{función desconocida} \(y=f(x)\) (\(x\) denota una entrada cualquiera del mismo
    tamaño que los \(x_i\)), descubrir una función \(h\) que aproxime a la función real
    \(f\) \cite{ai-a-modern-approach}.\\
    Por comodidad, denotaremos con \(\mathbf{x}\) al vector de entradas del conjunto de
    entrenamiento, y con \(\mathbf{y}\) al vector de salidas, ambos de tamaño \(N\) y bien
    ordenados (notar la \textit{negrita}). Es decir:
    \begin{quote}
        \(\mathbf{x}=(x_1, x_2, ..., x_N)\)\\
        \(\mathbf{y}=(y_1, y_2, ..., y_N)\)
    \end{quote}
    Cabe notar que cada \(x_i\) puede ser a su vez un vector, que por convención
    asumiremos que es de números reales. Es decir \(x_i \in \mathbb{R}^n\), con \(n \in
    \mathbb{N}\).
\end{quote}
De esta forma, el modelo es la función \(h\), que toma una entrada \(x\) y devuelve una
salida \(y\), y se presenta como una \textbf{hipótesis} de \(f\). La suposición sobre la
que se trabaja es que si el modelo funciona bien para los pares de entrenamiento, entonces
se espera que va a realizar buenas predicciones para nuevas entradas cuya etiqueta se
desconoce.

Ahora bien, esta función \(h\) se obtiene a partir de un \textbf{espacio de funciones},
que es elegido por quien diseña el modelo. Este espacio podría ser el conjunto de
funciones lineales, de polinomios de grado 2, de polinomios de grado 3, etcétera. Por lo
tanto, el espacio determina la forma o ``\textbf{arquitectura}'' que va a tener la función
\(h\), y consecuentemente cuáles son sus parámetros, cuyo vector denotaremos con la letra
\(\phi\). De esta forma, este espacio determina la familia de posibles relaciones entre
entradas y salidas, y los parámetros especifican la relación particular (el modelo).

Por ejemplo, si suponemos que cada entrada \(x\) es un número real y establecemos como
espacio el conjunto de funciones lineales, entonces la forma de \(h\) será:
\[h(x) = \phi_1 x + \phi_0\] y sus parámetros \(\phi=(\phi_0, \phi_1)\). Este caso es
comúnmente conocido como regresión lineal unidimensional (ya que la entrada es simplemente
un número real). Modelos particulares dentro de este espacio son \(h(x) = 5x + 13\),
\(h(x) = \pi x + 1.25\), entre muchos otros.

Otro caso un poco más complejo podría ser el que \(x \in \mathbb{R}^3\), es decir
\(x=(x_1, x_2, x_3)\) y seguimos tomando una relación lineal. Aquí, \(h\) sería:
\[h(x) = \phi_1 x_1 + \phi_2 x_2 + \phi_3 x_3 + \phi_0\] y sus parámetros \(\phi=(\phi_0,
\phi_1, \phi_2, \phi_3)\)\footnotemark
\footnotetext{Para simplificar la notación, lo que
se suele hacer es asumir que la entrada \(x\) tiene un componente adicional constante con
el valor 1, es decir \(x=(x_1, x_2, x_3, 1)\). De esta forma, podríamos escribir: \(h(x) =
x \cdot \phi\), donde el operador \(\cdot\) representa el producto escalar}.

En cambio, si tomamos el conjunto de polinomios de grado 2, entonces la forma de \(h\) será:
\[h(x) = \phi_2 x^2 + \phi_1 x + \phi_0\] y sus parámetros \(\phi=(\phi_0, \phi_1,
\phi_2)\). A este caso se lo suele llamar regresión polinómica de segundo grado
unidimensional.

Notemos entonces que quienes van a determinar qué modelo es ``mejor'' que otro, es decir
qué modelo aproxima mejor a \(f\), son los valores de los parámetros \(\phi_i\). Por lo
tanto, \(h\) en realidad es una función de la entrada \(x\) pero también de los
parámetros, establecidos por el espacio de funciones elegido:
\[h(x, \phi)\]
Y lo que querremos idealmente es:
\[f(x) \approx h(x, \phi)\]

Entonces, cuando un modelo se entrena o aprende, lo que realmente hace es encontrar los
valores de los parámetros que describan la verdadera relación entre entradas y salidas
\cite{prince2024understanding}. Un algoritmo de aprendizaje toma el conjunto de
entrenamiento y manipula los parámetros hasta que las predicciones dadas por él sean lo
más cercanas posible a las etiquetas verdaderas.

Para que el algoritmo sepa cómo modificar estos parámetros para mejorar sus predicciones,
necesita una forma de saber cómo está siendo su desempeño. Para esto, se define lo que se
conoce como \textbf{función de pérdida} o \textbf{función de error}, que denotaremos con
la letra \(L\) y que justamente hace eso: retorna un número que resume qué tan bien o mal
está funcionando el modelo con sus parámetros \(\phi\) actuales, en términos de qué tan
lejos están sus predicciones de las respuestas reales del conjunto de entrenamiento.

Una vez establecida su forma, la \textit{performance} del modelo va a estar dada por los
valores actuales de sus parámetros. Por lo tanto, tiene sentido tratar a la función de
pérdida como una que depende de los parámetros del modelo, es decir
\(L(\phi)\)\footnotemark. \footnotetext{En realidad la función de pérdida también depende
de los datos de entrenamiento, por lo que si somos estrictos deberíamos escribir
\(L(\left\{\mathbf{x}, \mathbf{y}\right\}, \phi\)). Sin embargo, como estos datos están
fijos durante todo el proceso de aprendizaje, podemos omitirlos.} A continuación, se
mencionan dos ejemplos de funciones de error:
\begin{itemize}
    \item Una función de pérdida que se es común usar en problemas de regresión es la de
    Error Cuadrático Medio (ECM), dada por:
    \[
    ECM(\phi) = \frac{1}{N} \sum_{i=1}^{N} \left(h(x_i, \phi) - y_i\right)^2
    \]
    \item Para problemas de clasificación binaria como el que tratamos en este trabajo, se
    suele emplear la Entropía Cruzada Binaria (ECB), dada por:
    \[
    ECB(\phi) = -\frac{1}{N} \sum_{i=1}^{N}
        \left[
            y_i\ log(h(x_i, \phi)) + (1 - y_i)\ log(1 - h(x_i, \phi))
        \right]
    \]
    Sin entrar en detalles, lo que mide esta función es la diferencia entre dos
    distribuciones de probabilidad, que en este caso son la distribución real de los datos
    dada por el conjunto de entrenamiento y la distribución predicha por el modelo en su
    estado actual.
\end{itemize}

En general, se asume que un valor más bajo de \(L(\phi)\) indica un mejor desempeño del
modelo, y por lo tanto el objetivo del proceso de entrenamiento se convierte
\textbf{encontrar los parámetros \(\phi^*\) que minimicen la función de pérdida}:

\[
\phi^* = \arg\min_{\phi} L(\phi)
\]
Si luego de la minimización la pérdida es baja, quiere decir que hemos encontrado
parámetros que predicen precisamente las salidas de entrenamiento \(y_i\) a partir de los
entradas \(x_i\) (con \(i=1,...,N\)). Sin embargo, como explicamos previamente, la
evaluación final del modelo se debe hacer con el conjunto de test, sobre el cual se puede
también calcular la pérdida.

La pregunta que surge entonces es cómo hacer para lograr esta minimización. Dependiendo
del espacio de funciones y de la función de costo seleccionada, puede que exista una
fórmula cerrada para \(\phi^*\), que se calcule analíticamente. Sin embargo, si la función
de costo tiene muchas variables (parámetros) o los modelos son complejos, resulta más útil
recurrir a métodos numéricos para aproximar este mínimo.

El algoritmo por defecto que se utiliza para resolver este problema de optimización es el
llamado \textbf{Descenso por el Gradiente} (DG). Es muy potente ya que se puede aplicar a
cualquier función de pérdida \cite{ai-a-modern-approach}, sin importar el espacio de
funciones elegido.

La idea del DG es ir modificando los parámetros iterativamente hasta eventualmente llegar
a un ``valle'' de la función de pérdida. El algoritmo se basa en que la dirección dada por
el gradiente\footnotemark{} de una función en un punto es la de máximo crecimiento, y por
lo tanto su opuesta es la de máximo decrecimiento. En este caso, la función de la cual se
calcula el gradiente es la de error, con respecto a los parámetros en \(\phi\).
\footnotetext{Dada una función \(g\) de varias variables, es decir, \(g(v_1, v_2, ...,
v_M)\), el \textbf{gradiente} de \(g\) es el vector formado por las derivadas parciales de
\(g\) con respecto a cada uno de sus parámetros:
\[
\nabla g = \left( \frac{\partial g}{\partial v_1}, \frac{\partial g}{\partial v_2},
\dots, \frac{\partial g}{\partial v_M} \right)
\]
donde la notación \(\frac{\partial g}{\partial v_i}\) representa la \textbf{derivada
parcial} de \(g\) con respecto a \(v_i\), que mide cómo cambia \(g\) cuando se varía
\(v_i\) mientras se mantienen constantes las demás variables. Este vector apunta en la
dirección de mayor crecimiento de \(g\).}

Concretamente, se empieza con un vector de parámetros \(\phi\) con valores arbitrarios que
va mejorando gradualmente, tomando un paso a la vez en dirección opuesta al gradiente, con
el objetivo de reducir el valor de la función de pérdida, hasta que el algoritmo
\textit{converja} a un mínimo (local) de la función de pérdida.

Un hiperparámetro\footnotemark{} determinante en el algoritmo del DG es el tamaño de los
pasos llamado \textbf{tasa de aprendizaje}, que denotaremos con la letra \(\alpha\) y
supondremos por el momento que se mantiene constante en todo el proceso. Si el valor
\(\alpha\) es muy pequeño, entonces el algoritmo va a tener que realizar muchas
iteraciones para converger \cite{hands-on-ML-sklearn-tf}. Si en cambio el valor es muy
alto, entonces puede ser que vayamos ``saltando'' de un lado a otro de un valle de la
función, haciendo que el algoritmo diverja \cite{hands-on-ML-sklearn-tf}.
\footnotetext{Hablaremos más adelante sobre qué es un hiperparámetro, pero lo importante
es que no es un parámetro que se aprende, como lo son los contenidos en el vector \(\phi\).}

La regla del DG está dada por:
\[
\phi_{p+1} = \phi_{p} - \alpha \nabla L(\phi)
\]
donde \(p\) indica el número de iteración actual.

La parte más ``pesada'' computacionalmente de este algoritmo es que en la función de
pérdida, de la forma en la que la definimos hasta ahora, están incluidas todas las
muestras del conjunto de entrenamiento. Es decir, en cada iteración, el cálculo del
gradiente requiere evaluar la contribución de cada una de las muestras, lo que puede ser
caro cuando \(N\) es muy grande. Para mitigar este problema, existen variantes del
algoritmo que buscan aproximar el gradiente utilizando subconjuntos del conjunto de
entrenamiento, como el Descenso por el Gradiente Estocástico y el Descenso por el
Gradiente por Mini-Lotes.

% Dar un pantallazo como resumen

\bigskip
Hasta aquí hemos hablado de cómo está compuesto prácticamente cualquier algoritmo de
aprendizaje supervisado. Sin embargo, no hemos discutido la correspondencia del espacio de
funciones con el conjunto de datos con el que estamos tratando.

El éxito del aprendizaje supervisado depende en gran medida de elegir un espacio de
funciones adecuado que sea capaz de capturar la distribución de los datos. Por ejemplo, si
elegimos un modelo lineal cuando los datos tienen una relación cuadrática, el modelo no
podrá representar correctamente la estructura del problema. Por otro lado, si
seleccionamos un espacio de funciones altamente flexibles - o \textit{expresivas} -, como
polinomios de grado alto, puede ocurrir que el modelo termine describiendo peculiaridades
de los datos de entrenamiento que son atípicas y llevan a predicciones inusuales
\cite{prince2024understanding}.

Si bien existen otros modelos que permiten identificar relaciones no lineales y no
polinómicas, varios de ellos requieren tener un buen conocimiento sobre la estructura de
los datos, y muchas veces su desempeño está condicionado a ciertas transformaciones,
proceso que se conoce por su nombre en inglés \textit{feature engineering}.

En este punto es donde aparecen los modelos conocidos como \textbf{Redes Neuronales}, que
permiten describir un espacio de funciones complejas, expresivas, y no lineales sin la
necesidad de tener un conocimiento profundo sobre los datos. En cambio, son capaces de
aprender las representaciones subyacentes automáticamente. En la sección siguiente,
explicaremos el funcionamiento de estos algoritmos.

\end{document}