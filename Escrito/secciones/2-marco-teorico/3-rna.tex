\documentclass[../../main.tex]{subfiles}

\begin{document}

Las Redes Neuronales Artificiales (RNAs) son un modelo específico dentro del ML, cuya
estructura y funcionamiento estuvieron inspirados inicialmente por el intento de ser
modelos computacionales del aprendizaje biológico, es decir modelos de cómo el aprendizaje
podría ocurrir en el cerebro \cite{deep-learning}. Durante los últimos años, ha sido el
área que más desarrollo e impacto ha tenido, principalmente gracias a su versatilidad,
potencia y escalabilidad, cualidades que hacen que estos modelos sean capaces de
enfrentar problemas grandes y complejos \cite{hands-on-ML-sklearn-tf} que hasta el momento
parecían extremadamente difíciles de resolver, como son el reconocimiento de voz y la
detección de objetos.

% Incluirlo?
\subsection{Breve Contexto Histórico}
Aunque su gran éxito ha sido reciente, lo cierto es que la idea de las RNAs data desde
1943, cuando Warren McCulloch y Walter Pitts presentaron en su artículo \textit{A Logical
Calculus of Ideas Immanent of Nervous Activity} \cite{mculloch-pitts-1943} un modelo
computacional simplificado utilizando lógica proposicional acerca de cómo funcionan las
neuronas de cerebros animales en conjunto para llevar a cabo cómputos complejos
\cite{hands-on-ML-sklearn-tf}. Presentaron una versión muy simplificada de la neurona
biológica, que solamente tenía una o más entradas binarias y una salida binaria.

Posteriormente, en 1958, Frank Rosenblatt presentó una de las arquitecturas más simples de
RNAs: el ``Perceptrón'' \cite{rosenblatt1958perceptron}, el cual servía principalmente
para resolver problemas de clasificación en donde los datos son linealmente separables. Su
aporte más notorio es que definió un algoritmo para el entrenamiento del Perceptrón que le
permitía mejorar automáticamente sus parámetros internos para poder llegar a una solución.

Más tarde, se descubrió que los problemas que no podían ser resueltos por el Perceptrón,
sí podían ser resueltos ``apilando'' múltiples perceptrones, lo cual llevó a la invención
del ``Perceptrón Multicapa'' (PMC), también conocido actualmente como ``Red Neuronal de
Propagación Directa'' \footnotemark (del inglés \textit{Feedforward Neural Networks}, FFNN)
\cite{deep-learning} que conforman el punto de partida de las redes neuronales actuales.
\footnotetext{Si bien estos términos se suelen usar indistintamente, la realidad
es que las redes neuronales feedforward tienen leves diferencias con el Perceptrón
Multicapa.}

Para explicar la idea y los elementos presentes detrás de estos algoritmos, tomaremos como
referencia las redes neuronales Feedforward, y en particular las totalmente conectadas
(\textit{fully connected}), que definiremos a continuación.

% Cabe aclarar que las redes neuronales en general se enmarcan dentro del área del ML
% conocida como \textbf{Aprendizaje Profundo}.

\subsection{Red Neuronal Feedforward}
Como dijimos anteriormente, las redes neuronales son un modelo particular de Aprendizaje
Automático. Aquí, las funciones hipótesis se caracterizan por incorporar \textbf{no
linealidad} y toman la forma de circuitos algebraicos complejos con conexiones que pueden
tener diferentes ``intensidades'' \cite{ai-a-modern-approach}. La idea principal en estos
circuitos es que el ``camino'' recorrido al realizar el cómputo tenga varios pasos como
para permitir que las variables de entrada puedan interactuar de formas complejas. Esto
hace que sean lo suficientemente expresivos como para poder capturar la complejidad de los
datos del mundo real \cite{ai-a-modern-approach}.

Más concretamente, estos modelos son llamados \textit{redes} porque el espacio de
funciones que proveen está formado en realidad por la composición de varias funciones
\cite{deep-learning}. Por ejemplo, podríamos tener la composición de tres funciones
\(f^{(1)}\), \(f^{(2)}\) y \(f^{(3)}\) para formar la siguiente función:
\begin{equation}
    f(\mathbf{x}) = f^{(3)}(f^{(2)}(f^{(1)}(\mathbf{x})))
    \label{eq:fun-composition}
\end{equation}
donde \(\mathbf{x}\) es un vector de dimensión \(n\) de números reales: \(\mathbf{x}=(x_1,
x_2, ..., x_n)\), es decir \(\mathbf{x} \in \mathbb{R}^m\).

Usualmente, se dice que las redes están organizadas en \textbf{capas}. De esta forma, en
la ecuación anterior, a la función \(f^{(1)}\), que es la primera que se aplica sobre
\(\mathbf{x}\), se la llama \textbf{capa de entrada}, a \(f^{(2)}\) \textbf{capa oculta o
intermedia}, y a \(f^{(3)}\), que es la que produce el resultado final, \textbf{capa de
salida}. La longitud de esta cadena de funciones es la que va a dar la
\textbf{profundidad} de la red.

En general, las RNAs tienen una capa de entrada y una de salida, pero pueden tener una o
más ocultas. Cuando tienen una capa oculta, se las llama ``superficiales'' (o poco
profundas, del inglés \textit{shallow}), y cuando tienen más de una \textit{profundas}. Es
por esto que al hablar de redes neuronales, muchas veces se hablahace referencia al
término \textbf{Aprendizaje Profundo}.

Lo interesante de estos modelos es que si bien el conjunto de entrenamiento especifica qué
tiene que producir la capa de salida ante cada entrada particular, no determina cuál debe
ser el comportamiento de las otras capas \cite{deep-learning}. En cambio, es el algoritmo
de aprendizaje el que tiene que decidir cómo usarlas para lograr una buena aproximación de
la función desconocida.

Una forma muy común y más intuitiva de pensar estos modelos es a través de grafos
dirigidos cuyas flechas describen cómo están compuestas las funciones y cómo fluye la
información a través de ellas. Si hay una flecha que une a dos nodos, diremos que están
``conectados''. Por ejemplo, la Ecuación \ref{eq:fun-composition} se representaría de la
siguiente manera:
\begin{center}
    \begin{tikzpicture}[
        node distance=2cm,
        every node/.style={draw, circle, minimum size=1cm, align=center},
        thickborder/.style={draw, circle, minimum size=1cm, align=center, line width=0.5mm}
    ]
        % Nodes
        \node (n1) [thickborder] {\( f^{(1)} \)};
        \node (n2) [thickborder, right=of n1] {\( f^{(2)} \)};
        \node (n3) [thickborder, right=of n2] {\( f^{(3)} \)};

        \node (x) [left=of n1 ] {\(\mathbf{x}\)};
        \node (y) [right=of n3] {\( y \)};

        % Edges
        \draw [connect arrow] (x.east) -- (n1.west);
        \draw [connect arrow] (n1.east) -- (n2.west);
        \draw [connect arrow] (n2.east) -- (n3.west);
        \draw [connect arrow] (n3.east) -- (y.west);
    \end{tikzpicture}
\end{center}

En este caso, la entrada \(\mathbf{x}\) va a la función \(f^{(1)}\), la salida de
\(f^{(1)}(\mathbf{x})\) va a \(f^{(2)}\), y la salida de \(f^{(2)}(f^{(1)}(\mathbf{x}))\)
va directamente a \(f^{(3)}\) para de esa forma producir el resultado final \(y =
f(\mathbf{x}) = f^{(3)}(f^{(2)}(f^{(1)}(\mathbf{x})))\).

Es justamente el comportamiento anterior el que caracteriza a las redes neuronales de tipo
\textbf{\textit{feedforward}}: los datos y resultados fluyen en una sola dirección; cada
nodo computa su resultado y se lo pasa a su sucesor (o sucesores, como veremos más
adelante). En el grafo, esta situación se refleja en el hecho que no hay ciclos, por lo
que las redes de este tipo se representan por medio de grafos dirigidos y acíclicos.

Ahora bien, ¿qué es exactamente una capa? En la terminología de redes neuronales, una capa
es un conjunto de \textbf{unidades} o, tomando en cuenta su inspiración biológica,
\textbf{neuronas}, que actúan en paralelo. Cada unidad representa una función que toma un
vector y retorna un escalar, y se asemejan a las neuronas biológicas en el sentido que
reciben entradas (o estímulos) de otras unidades y computan su propio valor de activación
\cite{deep-learning}.

Cabe aclarar que la capa de entrada va a tener tantas neuronas como la dimensión de los
datos de entrada (\(\mathbf{x}\)). Es decir, si \(\mathbf{x}\) es de dimensión \(n\),
entonces la capa de entrada va a tener \(n\) unidades. Sin embargo, la cantidad de
neuronas de cada capa oculta depende del diseño de la red, y la de la capa de salida
depende sobre todo del problema que se esté tratando de resolver. Si se trata por ejemplo
de un problema de clasificación, entonces la capa de salida va a tener en general
tantas neuronas como categorías existan en el dominio del problema.

Teniendo el concepto de neuronas, podemos introducir el de redes \textbf{totalmente
conectadas} (\textit{fully connected}), que son aquellas en las que cada unidad de una
capa se conecta con todas las de la capa siguiente.

Con esto en mente, podemos concretizar un poco más el ejemplo con el que venimos
trabajando suponiendo que \(\mathbf{x}\) es un vector de dimensión 3, la capa oculta dada
por \(f^{(2)}\) tiene 2 neuronas y la capa de salida tiene 1. Así, suponiendo que nuestra
red es fully connected, nuestro grafo resultaría en:
\begin{center}
    \begin{tikzpicture}[
        node distance=1.5cm,
        every node/.style={draw, circle, minimum size=1cm, align=center},
    ]
        % Inputs
        \node (x1) {\(x_1\)};
        \node (x2) [below=of x1] {\(x_2\)};
        \node (x3) [below=of x2] {\(x_3\)};

        % Input layer
        \node (f11) [right=of x1] {\(f^{(1)}_1\)};
        \node (f12) [right=of x2] {\(f^{(1)}_2\)};
        \node (f13) [right=of x3] {\(f^{(1)}_3\)};

        % Hidden layer
        \node (f21) [right=of $(f11)!0.5!(f12)$] {\(f^{(2)}_1\)};
        \node (f22) [below=of f21] {\(f^{(2)}_2\)};

        % Output layer
        \node (f31) [right=of $(f21)!0.5!(f22)$] {\(f^{(3)}_1\)};

        % Output
        \node (y) [right=of f31] {\( y \)};

        % Edges
        \draw [connect arrow] (x1.east) -- (f11.west);
        \draw [connect arrow] (x2.east) -- (f12.west);
        \draw [connect arrow] (x3.east) -- (f13.west);

        \draw [connect arrow] (f11.east) -- (f21.west);
        \draw [connect arrow] (f12.east) -- (f21.west);
        \draw [connect arrow] (f13.east) -- (f21.west);
        \draw [connect arrow] (f11.east) -- (f22.west);
        \draw [connect arrow] (f12.east) -- (f22.west);
        \draw [connect arrow] (f13.east) -- (f22.west);

        \draw [connect arrow] (f21.east) -- (f31.west);
        \draw [connect arrow] (f22.east) -- (f31.west);

        \draw [connect arrow] (f31.east) -- (y.west);
    \end{tikzpicture}
\end{center}
donde el superíndice de cada nodo indica el número de capa y subíndice hace referencia al
número de neurona en esa capa.

Vemos entonces que cada neurona de la capa de entrada se encarga de recibir una ``parte'' del
vector de entrada \footnotemark, pero las neuronas de tanto la capa oculta como la de salida reciben las
salidas de las neuronas de la capa anterior. Veamos entonces qué hace precisamente una
neurona o unidad.
\footnotetext{Esto hace que en general los nodos \(x_1\), \(x_2\) y \(x_3\) del diagrama
... sean omitidos en los grafos de las redes.}

Una neurona simplemente calcula una suma pesada de sus entradas, provenientes de las
unidades de la capa anterior, y luego aplica una función \textbf{no lineal} que
denotaremos con \(a\) para producir su salida. Formalmente, si denotamos con:
\begin{itemize}[itemsep=0.1cm]
    \item \(s^{(k)}_j\) a la salida de la unidad \(j\) de la capa \(k\)
    \item \(a^{(k)}_j\) a la función no lineal de la unidad \(j\) de la capa \(k\)
    \item \(w^{(k-1)}_{i,j}\) la intensidad o \textbf{peso} de la conexión entre la
    neurona \(i\) de la capa (\(k-1\)) y la \(j\) de la capa \(k\),
\end{itemize}
tenemos que:
\begin{equation}
    s^{(k)}_j = a^{(k)}_j \left( \sum_i w^{(k-1)}_{i,j} s^{(k-1)}_i \right)
    \label{eq:neuron}
\end{equation}
donde el ínidice \(i\) de la sumatoria va a recorrer todas las neuronas de la capa
anterior.

%Gráficamente:
% Poner gráfico basado en la figura figs/neurona_orig.png

La función \(a^{(k)}_j\) se denomina \textbf{función de activación}, y el hecho que sea no
lineal es importante ya que de no ser así, cualquier composición de unidades estaría
representando una función lineal \cite{ai-a-modern-approach}. Es justamente esta no
linealidad lo que permite a estos modelos representar funciones arbitrarias
\cite{ai-a-modern-approach}. En general, se asume que todas las neuronas de una capa
tienen la misma función de activación.

Algunas funciones de activación comunes son las siguientes:
\begin{itemize}[itemsep=0.1cm]
    \item \textbf{Sigmoide}: \(\sigma(x)=\frac{1}{1+e^{-x}}\)
    \item \textbf{ReLU} (abreviatura de \textit{rectified linear unit}):
    \(\text{ReLU}(x) = \text{max}(0, x)\)
    \item \textbf{Tangente hiperbólica}: \(\text{tanh}(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}\)
\end{itemize}
Actualmente, la más utilizada es la ReLU y variantes de ella.

Si en nuestro ejemplo tomamos la neurona \(f^{(2)}_1\), tenemos que su salida estará dada
por:
\begin{align*}
    s^{(2)}_1 &= a^{(2)}_1 \left( \sum_{i=1}^{3} w^{(1)}_{i,1} s^{(1)}_i \right) \\
              &= a^{(2)}_1 \left( w^{(1)}_{1,1}s^{(1)}_1 +  w^{(1)}_{2,1}s^{(1)}_2 + w^{(1)}_{3,1}s^{(1)}_3 \right)
\end{align*}

% En el párrafo siguiente, agregar algo sobre la relación entre esta neurona dummy
% y el umbral de activación de la neurona biológica.
En las redes, se estipula que cada unidad tiene una entrada extra desde una neurona
\textit{dummy} de la capa anterior, para la cual utilizaremos el subíndice 0, cuyo valor
está fijado en 1 y su peso correspondiente será \(w^{(k)}_{0,j}\) para una neurona \(j\)
de una capa \(k\)\footnotemark. Esto permite que la entrada a dicha neurona sea distinta de 0
incluso cuando todas las salidas de la capa anterior sean 0 \cite{ai-a-modern-approach} y
agregándolo podemos escribir la Ecuación \ref{eq:neuron} de forma vectorizada:
\begin{equation}
    s^{(k)}_j = a^{(k)}_j \left( \left( \mathbf{W}^{(k)}_j \right)^T \mathbf{x}^{(k)}_j \right)
\end{equation}
donde \(\mathbf{W}^{(k)}_j\) es el vector de todos los pesos que se dirigen a la unidad \(j\) de
la capa \(k\) (incluyendo \(w_{0,j}\)) y \(\mathbf{x}^{(k)}_j\) es el vector de todas las entradas
de la unidad \(j\) de la capa \(k\) (incluyendo el 1 fijo de la neurona dummy).
\footnotetext{En la bibliografía sobre redes neuronales, también se suele presentar
a este peso como un ``sesgo'' (\textit{bias}) de la neurona, y se lo denota como
\(b^{(k)}_j\). En este caso, la ecuación de la neurona se escribiría como:
\[
    s^{(k)}_j = a^{(k)}_j \left( \sum_i w^{(k-1)}_{i,j} s^{(k-1)}_i + b^{(k)}_j \right)
\]
}


Si tomamos nuevamente a \(f^{(2)}_1\), tenemos:
\begin{quote}
    \(\mathbf{W}^{(2)}_1 = (w^{(1)}_{0,1}, w^{(1)}_{1,1}, w^{(1)}_{2,1}, w^{(1)}_{3,1})\),
    \(\mathbf{X}^{(2)}_1 = (1, s^{(1)}_1, s^{(1)}_2, s^{(1)}_3)\)
\end{quote}

Así como utilizamos vectores para describir el cómputo de una neurona, podemos emplear
matrices para describir el comportamiento de toda una capa. Para ello, tomemos la siguiente
notación:
\begin{itemize}[itemsep=0.1cm]
    \item \(\mathbf{S}^{(k)}\) es el vector columna formado por las salidas de la capa
    \(k\). Es decir: \(\mathbf{S}^{(k)} = (s_0^{(k)}, s_1^{(k)}, ..., s_m^{(k)})^T = (1,
    s_1^{(k)}, ..., s_m^{(k)})^T\), donde \(m\) es la cantidad de neuronas de la capa
    \(k\).
    \item \(a^{(k)}\) es la función de activación de la capa \(k\), con una aplicación
    elemento a elemento. Es decir: \(a^{(k)}(x_1, x_2, ..., x_m) = (a^{(k)}(x_1),
    a^{(k)}(x_2), ..., a^{(k)}(x_m))\)
    \item \(\mathbf{W}^{(k)}\) es la matriz de pesos que ``llegan'' a la capa \(k\). Cada
    fila \(j\) de esta matriz corresponde a los pesos que llegan a la neurona \(j\) de la
    capa \(k\), es decir cada fila es \(\mathbf{W}^{(k)}_j\) con \(j = 1,...,m\), con
    \(m\) la cantidad de neuronas de la capa \(k\). De esta manera, la matriz \(\mathbf{W}^{(k)}\)
    tiene dimensiones \(m \times (n + 1)\), siend \(n\) la cantidad de neuronas de la capa
    \(k-1\) sin contar la dummy.
\end{itemize}
Con esto, tenemos que la salida de una capa está dada por:
\[
    \mathbf{S}^{(k)} = a^{(k)} \left( \mathbf{W}^{(k)} \mathbf{S}^{(k-1)} \right)
\]

% Escribir la composición final de la red de ejemplo en algún lado?

\subsubsection{Entrenamiento}
% Retomar descenso por el gradiente
En el caso de las redes neuronales, los parámetros a optimizar van a ser las intensidades
de las conexiones entre las neuronas, también llamadas pesos. La gran mayoría de los
algoritmos que se utilizan actualmente se basan en la regla del Descenso por el Gradiente.

Ahora bien, esta regla lo único que indica es cómo se deben modificar los pesos para
garantizar que vamos en dirección decreciente, pero no establece cómo se calcula el
gradiente de la función en cuestión, lo cual se vuelve complejo cuando se trata de redes
neuronales. El algoritmo que soluciona este problema de manera eficiente es conocido como
\textbf{retropropagación} (del inglés \textit{backpropagation} \cite{backprop-1986}). A
continuación, describimos a grandes rasgos la idea de este algoritmo.

El backpropagation se divide en dos etapas: primero, el paso hacia adelante (\textit{forward pass})
y luego, el paso hacia atras (\textit{backward pass}).

En el forward pass,

% Retomar las dos "mejoras": estocástico y por lote
% Introducir el concepto de época
% Introducir el concepto de hiperparámetros: acá decir que se suele hacer un conjunto
% intermedio (el de validación) o técnicas como cross-validation

\subsubsection{Hiperparámetros}



\begin{comment}
Actualmente, se utilizan otros optimizadores más sofisticados y eficientes, pero que todos
parten de la idea del Descenso por el Gradiente. Los que usaremos en los experimentos son
el Descenso por el Gradiente Estocástico (\textit{Stochastic Gradient Descent}, SGD) y
Adam (\textit{Adaptive Moment Estimation}), de los cuales se puede leer más en el Capítulo
8 de \cite{deep-learning}.

Ahora bien, recordando que la función \(f\) está fija en todas las entradas y salidas del
conjunto de entrenamiento, hay algoritmos de optimización que utilizan todos estos datos
para  calcular el gradiente, otros que utilizan de a un ejemplo a la vez para calcular el
gradiente y otros que están entre medio de los dos anteriores, es decir utilizan un
subconjunto del conjunto de datos para calcular el gradiente (esto es lo que hace SGD).

Es necesario en este punto introducir el concepto de ``\textbf{época}'' y de
``\textbf{lote}''. Un lote es simplemente una subdivisión de tamaño fijo del conjunto de
entrenamiento (o de test). Dicho esto, se llama época al proceso completo en el cual el
modelo entrena utilizando \textbf{todos} los datos disponibles en el conjunto de
entrenamiento una vez, ya sea recorriéndolos de a lotes o todos de una vez. Si el conjunto
está efectivamente dividido en lotes, una época va a consistir de: \textbf{para cada
lote}, calcular las predicciones en base a los pesos actuales, obtener los errores de cada
muestra del lote, computar los gradientes en base a los ejemplos del lote y actualizar los
pesos. Si no, se hacen los mismos pasos pero para todos los datos de una vez.

Al entrenar un modelo, existen ciertos ajustes que son utilizados para controlar su
comportamiento llamados \textbf{hiperparámetros}. Los valores de los hiperparámetros no
son aprendidos por el modelo \cite{deep-learning}, sino que se fijan de antemano y no se
modifican a lo largo del entrenamiento. Algunos de estos son: la cantidad de neuronas en
cada capa oculta, la función de activación utilizada en cada capa, el optimizador, la tasa
de aprendizaje, el número de épocas, el tamaño de lote, entre otros. Todos estos pueden
contribuir a que el modelo mejore su desempeño. Para probar distintos valores de
hiperparámetros, que es lo que haremos a continuación, se utiliza un conjunto de datos
extra además del de entrenamiento y el de test, llamado de \textbf{validación} que sirve
justamente para encontrar los hiperparámetros óptimos.

% Mejoras extras: detención temprana, dropout
Otras mejoras que se han implementado para mejorar la eficacia de los modelos, y que
emplearemos en los experimentos, son las nombradas a continuación. Por un lado, tenemos la
\textbf{detención temprana}, que consiste en frenar el entrenamiento en el último mejor
``estado'' del modelo cuando se observa que a partir de dicho punto el error sobre el
conjunto de validación no mejora (notar que cuántas épocas se espera y qué se considera
una mejora son nuevos hiperparámetros). Y por otro lado, el \textbf{dropout}, que es un
algoritmo que implica suprimir un cierto número de neuronas de una capa de manera
aleatoria \cite{apuntes-redes-neuronales}.
\end{comment}

\end{document}