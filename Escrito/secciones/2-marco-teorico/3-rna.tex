\documentclass[../../main.tex]{subfiles}

\begin{document}

Las Redes Neuronales Artificiales (RNAs) son un modelo específico dentro del ML, cuya
estructura y funcionamiento estuvieron inspirados inicialmente por el intento de ser
modelos computacionales del aprendizaje biológico, es decir modelos de cómo el aprendizaje
podría ocurrir en el cerebro \cite{deep-learning}. Durante los últimos años, ha sido el
área que más desarrollo e impacto ha tenido, principalmente gracias a su versatilidad,
potencia y escalabilidad, cualidades que hacen que estos modelos sean capaces de enfrentar
problemas grandes y complejos \cite{hands-on-ML-sklearn-tf}, y que sobre todo parecían
extremadamente difíciles de resolver. Como mencionamos anteriormente, su avance se vio muy
favorecido por principalemnte por la creciente disponibilidad de datos y el aumento en la
capacidad computacional.

A continuación, damos un breve contexto histórico y luego ahondamos en su funcionamiento.

\subsection{Breve Contexto Histórico}
Aunque su gran éxito ha sido reciente, lo cierto es que la idea de las RNAs data desde
1943, cuando Warren McCulloch y Walter Pitts presentaron en su artículo \textit{A Logical
Calculus of Ideas Immanent of Nervous Activity} \cite{mculloch-pitts-1943} un modelo
computacional simplificado utilizando lógica proposicional acerca de cómo funcionan las
neuronas de cerebros animales en conjunto para llevar a cabo cómputos complejos
\cite{hands-on-ML-sklearn-tf}. Presentaron una versión muy simplificada de la neurona
biológica, que solamente tenía una o más entradas binarias y una salida binaria.

Posteriormente, en 1958, Frank Rosenblatt presentó una de las formas o
\textit{arquitecturas} más simples de RNAs: el ``Perceptrón''
\cite{rosenblatt1958perceptron}. Este consistía de solamente una neurona artificial que
recibía entradas, las combinaba en una suma pesada y si el resultado era mayor a un
determinado umbral, daba como salida un valor de 1, y en caso contrario de (-1). La gran
limitación del Perceptrón fue que servía solamente para resolver problemas de
clasificación en donde los datos son linealmente separables. Sin emabrgo, el aporte más
notorio de Rosenblatt fue la definición de un algoritmo para el entrenamiento del
Perceptrón que le permitía mejorar automáticamente sus parámetros internos (los ``pesos''
de la suma pesada) para poder llegar a la solución óptima.

Más tarde, se descubrió que los problemas que no podían ser resueltos por el Perceptrón,
sí podían ser resueltos ``apilando'' múltiples perceptrones, lo cual llevó a la invención
del ``Perceptrón Multicapa'' (PMC), también conocido actualmente como ``Red Neuronal de
Propagación Directa''\footnotemark (del inglés \textit{Feedforward Neural Networks}, FFNN)
\cite{deep-learning}, las cuales conforman el punto de partida de las redes neuronales
actuales. \footnotetext{Si bien estos términos se suelen usar indistintamente, la realidad
es que las redes neuronales Feedforward presentan algunas diferencias con respecto al
Perceptrón Multicapa.}

Para explicar la idea y los elementos presentes detrás de estos algoritmos, tomaremos como
referencia las redes neuronales Feedforward, y en particular las llamadas ``totalmente
conectadas'' (\textit{fully connected}), que definiremos a continuación.

\subsection{Red Neuronal Feedforward}
Como dijimos anteriormente, las redes neuronales son un modelo particular de Aprendizaje
Automático. Aquí, las funciones hipótesis se caracterizan por incorporar \textbf{no
linealidad} y toman la forma de circuitos algebraicos complejos con conexiones que pueden
tener diferentes ``intensidades'' \cite{ai-a-modern-approach}. La idea principal en estos
circuitos es que el ``camino'' recorrido al realizar el cómputo tenga varios pasos como
para permitir que las variables de entrada puedan interactuar de formas complejas. Esto
hace que sean lo suficientemente expresivos como para poder capturar la complejidad de los
datos del mundo real \cite{ai-a-modern-approach}.

Más concretamente, estos modelos son llamados \textit{redes} porque el espacio de
funciones que proveen está formado en realidad por la composición de varias funciones
\cite{deep-learning}. Por ejemplo, podríamos tener la composición de tres funciones
\(f^{(1)}\), \(f^{(2)}\) y \(f^{(3)}\) para formar la siguiente función:
\begin{equation}
    \hat{\bm{y}} = f(\bm{x}) = f^{(3)}(f^{(2)}(f^{(1)}(\bm{x})))
    \label{eq:fun-composition}
\end{equation}
donde \(\bm{x} \in \mathbb{R}^n\) para algún \(n \in \mathbb{N}\), \(\hat{\bm{y}} \in
\mathbb{R}^m\) para algún \(m \in \mathbb{N}\), y asumiremos que los espacios de dominio y
llegada de las diferentes funciones son ``compatibles''.

Usualmente, se dice que las redes están organizadas en \textbf{capas}. De esta forma, en
la ecuación anterior, a \(\bm{x}\) se la conoce como \textbf{capa de entrada}, a las
funciones \(f^{(1)}\) y \(f^{(2)}\) como \textbf{capas ocultas} o \textbf{intermedias}, y
a \(f^{(3)}\), que es la que produce el resultado final, como \textbf{capa de salida}. La
longitud de esta cadena de funciones es la que va a dar la \textbf{profundidad} de la red.

Las RNAs tienen una capa de entrada y una de salida, pero el número de capas ocultas
depende de quien la diseñe. Cuando tienen una capa oculta, se las llama ``superficiales''
(o poco profundas, del inglés \textit{shallow}), y cuando tienen más de una,
\textit{profundas}. Es por esto que al hablar de redes neuronales, muchas veces se
hace referencia al término \textbf{Aprendizaje Profundo}.

Recordemos que uno de los elementos presentes en el Aprendizaje Supervisado es el conjunto
de entrenamiento, compuesto por pares de entrada-etiqueta. Ahora bien, lo interesante de
estos modelos es que si bien este conjunto especifica qué tiene que producir la capa de
salida ante cada entrada particular, no determina cuál debe ser el comportamiento de las
otras capas \cite{deep-learning}. En cambio, es el algoritmo de aprendizaje el que tiene
que decidir cómo usarlas para lograr una buena aproximación de la función desconocida.

Una forma muy común y más intuitiva de pensar estos modelos es a través de grafos
dirigidos cuyas flechas describen cómo están compuestas las funciones y cómo fluye la
información a través de ellas. Si hay una flecha que une a dos nodos, diremos que están
``conectados''. Por ejemplo, la Ecuación \ref{eq:fun-composition} se representaría de la
siguiente manera:
\begin{center}
    \begin{tikzpicture}[
        node distance=2cm,
        every node/.style={draw, circle, minimum size=1cm, align=center},
        thickborder/.style={draw, circle, minimum size=1cm, align=center, line width=0.5mm}
    ]
        % Nodes
        \node [node hidden] (n1) [thickborder] {\( f^{(1)} \)};
        \node [node hidden] (n2) [thickborder, right=of n1] {\( f^{(2)} \)};
        \node [node out] (n3) [thickborder, right=of n2] {\( f^{(3)} \)};

        \node [node in] (x) [left=of n1 ] {\(\bm{x}\)};
        \node [right=of n3, draw=none] (y) {\(\bm{\hat{y}}\)};

        % Edges
        \draw [connect arrow] (x.east) -- (n1.west);
        \draw [connect arrow] (n1.east) -- (n2.west);
        \draw [connect arrow] (n2.east) -- (n3.west);
        \draw [connect arrow] (n3.east) -- (y.west);
    \end{tikzpicture}
\end{center}

En este caso, la entrada \(\bm{x}\) va a la función \(f^{(1)}\), la salida de
\(f^{(1)}(\bm{x})\) va a \(f^{(2)}\), y la salida de \(f^{(2)}(f^{(1)}(\bm{x}))\) va
directamente a \(f^{(3)}\) para de esa forma producir el resultado final\footnotemark\
\(\bm{\hat{y}} = f(\bm{x}) = f^{(3)}(f^{(2)}(f^{(1)}(\bm{x})))\). \footnotetext{Usamos
\(\bm{\hat{y}}\) para referirnos a la aproximación de \(\bm{y}\), la
etiqueta real para una entrada \(\bm{x}\), dada por el modelo.}

Es justamente el comportamiento anterior el que caracteriza a las redes neuronales de tipo
\textbf{Feedforward}: los datos y resultados fluyen en una sola dirección; cada
nodo computa su resultado y se lo pasa a su sucesor (o sucesores, como veremos más
adelante). En el grafo, esta situación se refleja en el hecho que no hay ciclos, por lo
que las redes de este tipo se representan por medio de grafos dirigidos y acíclicos.

Ahora bien, ¿qué es exactamente una capa? En la terminología de redes neuronales, una capa
es un conjunto de \textbf{unidades} o, tomando en cuenta su inspiración biológica,
\textbf{neuronas}, que actúan en paralelo. Cada unidad representa una función que toma un
vector y retorna un escalar, y se asemejan a las neuronas biológicas en el sentido que
reciben entradas (o estímulos) de otras unidades y en base a estas, computan su propio
valor de activación \cite{deep-learning}.

De esta forma, la capa de entrada va a tener tantas neuronas como la dimensión de los
datos de entrada (\(\bm{x}\)). Es decir, si \(\bm{x}\) es de dimensión \(n\), entonces la
capa de entrada va a tener \(n\) unidades. Sin embargo, la cantidad de neuronas de cada
capa oculta depende del diseño de la red, y la de la capa de salida depende sobre todo del
problema que se esté tratando de resolver. Si se trata por ejemplo de un problema de
clasificación, entonces la capa de salida va a tener en general tantas neuronas como
categorías existan en el dominio del problema.

Teniendo el concepto de neuronas, podemos introducir el de redes \textbf{totalmente
conectadas} (\textit{fully connected}), que son aquellas en las que cada unidad de una
capa se conecta con todas las de la capa siguiente, ``pasándole'' su valor computado
a todas ellas.

Con esto en mente, podemos concretizar un poco más el ejemplo con el que venimos
trabajando suponiendo que \(\bm{x}\) es un vector de dimensión 3, las capas ocultas dadas
por \(f^{(1)}\) y \(f^{(2)}\) tienen 4 y 3 neuronas respectivamente y la capa de salida
tiene 2. Así, suponiendo que nuestra red es fully connected, nuestro grafo resultaría en
el de la Figura \ref{fig:ff-neural-network}, donde el superíndice de cada nodo indica el
número de capa y el subíndice hace referencia al número de neurona en esa capa.
\begin{figure}
    \centering
    % NEURAL NETWORK with coefficients, arrows
    \begin{tikzpicture}[
        x=2.2cm,
        y=1.4cm
    ]
        \readlist\Nnod{3,4,3,2} % array of number of nodes per layer

        \foreachitem \N \in \Nnod{ % loop over layers
            \edef\lay{\Ncnt} % alias of index of current layer
            \message{\lay,}
            \pgfmathsetmacro\prev{int(\Ncnt-1)} % number of previous layer
            \foreach \i [evaluate={\y=\N/2-\i; \x=\lay; \n=\nstyle;}] in {1,...,\N}{ % loop over nodes
                % NODES
                \ifnum\lay = 1 % input layer
                    \node[node \n] (N\lay-\i) at (\x,\y) {$x_\i$};
                \else
                    \node[node \n] (N\lay-\i) at (\x,\y) {$f_\i^{(\prev)}$};
                \fi
                % CONNECTIONS
                \ifnum\lay > 1 % connect to previous layer
                    \foreach \j in {1,...,\Nnod[\prev]}{ % loop over nodes in previous layer
                        \draw[connect arrow] (N\prev-\j) -- (N\lay-\i); % connect arrows directly
                    }
                \fi % else: nothing to connect first layer
            }
        }

        % Add output nodes to the left of each final layer neuron
        \node[right=of N\Nnodlen-1, circle] (y1) {\(\hat{y}_1\)};
        \node[right=of N\Nnodlen-2, circle] (y2) {\(\hat{y}_2\)};

        % Connect final layer neurons to their corresponding output nodes
        \draw[connect arrow] (N\Nnodlen-1) -- (y1);
        \draw[connect arrow] (N\Nnodlen-2) -- (y2);
    \end{tikzpicture}
    \caption{Red Neuronal de tipo Feedforward y totalmente conectada, con la capa de
    entrada formada por 3 neuronas, dos capas ocultas, cada una formada por 4 y 3 neuronas
    respectivamente, y la capa de salida, formada por dos neuronas. En este caso, la red
    ``acepta'' entradas \(\bm{x} \in \mathbb{R}^3\) y produce salidas \(\bm{\hat{y}} \in
    \mathbb{R}^2\). Adaptado de \cite{tikz-neural-networks}.}
    \label{fig:ff-neural-network}
\end{figure}

A partir de la Figura \ref{fig:ff-neural-network}, se puede ver que cada neurona de la
capa de entrada representa un elemento del vector de entrada, pero las neuronas de tanto
la capa oculta como la de salida reciben las salidas de las neuronas de la capa anterior.
Veamos entonces qué hace concretamente una neurona o unidad.

Una neurona simplemente calcula una suma pesada de sus entradas, provenientes de las
unidades de la capa anterior, y luego aplica una función \textbf{no lineal} para producir
su salida. Esta función se denomina \textbf{función de activación}, y el hecho que sea no
lineal es importante ya que de no ser así, cualquier composición de unidades podría
representarse mediante una función lineal \cite{ai-a-modern-approach}. Como mencionamos
anteriormente, es justamente esta no linealidad lo que permite a estos modelos representar
funciones arbitrarias \cite{ai-a-modern-approach} y complejas. En general, se asume que
todas las neuronas de una capa tienen la misma función de activación, pero puede ocurrir
que diferentes capas tengan diferentes funciones de activación.

Más precisamente, una función de activación es una función no lineal que toma cualquier
valor real como entrada y produce como resultado un número en un determinado rango.
Algunas funciones de activación comunes son las siguientes:
\begin{itemize}[itemsep=0.1cm]
    \item \textbf{Sigmoide}: produce un valor entre 0 y 1. Es por esto que se suele usar
    en problemas de clasificación binaria para que una única neurona en la capa de salida
    represente la probabilidad de que la entrada pertenezca a la clase ``positiva''.
    \[\sigma(x)=\frac{1}{1+e^{-x}}\]
    \item \textbf{ReLU} (abreviatura de \textit{Rectified Linear Unit}): produce un valor
    entre 0 e \(\infty\). Esta y sus variantes son las más utilizadas actualmente en las
    neuronas de capas ocultas, siendo una de las razones la simplicidad de su cálculo.
    \[\text{ReLU}(x) = \text{max}(0, x)\]
    \item \textbf{Tangente hiperbólica}: produce un valor entre -1 y 1. Lo particular de
    esta es que mantiene el signo de la entrada.
    \[\text{tanh}(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}\]
\end{itemize}

Un aspecto a notar en este punto es que en las redes neuronales aparecen nuevos
hiperparámetros, que ya no tienen tanto que ver con el proceso de entrenamiento en sí,
sino más bien con el diseño y la capacidad de la red, como son la cantidad de capas
ocultas, la cantidad de neuronas en cada capa oculta, e incluso la función de activación
de cada capa. Para todos estos, se puede encontrar el valor óptimo utilizando las técnicas
mencionadas en la sección anterior.

Para formalizar el cómputo de una neurona, es necesario introducir cierta notación.
Denotaremos con:
\begin{itemize}[itemsep=0.1cm]
    \item \(n^{(k)}\) la cantidad de neuronas de la capa \(k\).
    \item \(s^{(k)}_j\) a la salida de la unidad \(j\) de la capa \(k\)
    \item \(a^{(k)}_j\) a la función de activación de la unidad \(j\) de la capa \(k\)
    \item \(w^{(k)}_{i,j}\) la intensidad o \textbf{peso} de la conexión entre la
    neurona \(i\) de la capa \(k\) y la \(j\) de la capa \((k+1)\),
\end{itemize}
Con esto, tenemos que la salida de una neurona está dada por:
\begin{equation}
    s^{(k)}_j = a^{(k)}_j \left( \sum_{i=1}^{n^{(k-1)}} w^{(k-1)}_{i,j} s^{(k-1)}_i \right)
    \label{eq:neuron}
\end{equation}

Volviendo a la Fórmula \ref{eq:neuron}, si en nuestro ejemplo tomamos la neurona
\(f^{(2)}_1\), tenemos que su salida estará dada por:
\begin{align*}
    s^{(2)}_1 &= a^{(2)}_1 \left( \sum_{i=1}^{3} w^{(1)}_{i,1} s^{(1)}_i \right) \\
              &= a^{(2)}_1 \left( w^{(1)}_{1,1}s^{(1)}_1 +  w^{(1)}_{2,1}s^{(1)}_2 + w^{(1)}_{3,1}s^{(1)}_3 \right)
\end{align*}

En las redes, se estipula que cada unidad tiene una entrada extra desde una neurona
\textit{dummy} de la capa anterior, para la cual utilizaremos el subíndice 0. El valor de
salida de esta neurona se fija en 1, y el peso asociado con una neurona \(j\) de una capa
\(k\) será \(w^{(k)}_{0,j}\). Este peso se suele llamar
\textit{\textbf{bias}}\footnotemark\ y permite que la entrada a dicha neurona sea distinta
de 0 incluso cuando todas las salidas de la capa anterior sean 0
\cite{ai-a-modern-approach}. Agregándolo, podemos escribir la Ecuación \ref{eq:neuron} de
forma vectorizada:
\begin{equation}
    s^{(k)}_j = a^{(k)}_j \left( \bm{w}^{(k-1)}_j \left( \bm{s}^{(k-1)}_j \right)^T \right)
\end{equation}
donde: \vspace{-0.25cm}
\begin{itemize}
    \item \(\bm{w}^{(k-1)}_j\) es el vector de todos los pesos que salen de las neuronas de la
    capa \((k-1\)) y se dirigen a la unidad \(j\) de la capa \(k\) (incluyendo \(w^{(k-1)}_{0,j}\))
    \item \(\bm{s}^{(k-1)}_j\) es el vector de todas las salidas de la capa anterior que se
dirigen a la unidad \(j\) de la capa \(k\) (incluyendo el 1 fijo de la neurona dummy).
\end{itemize}
\footnotetext{En la bibliografía sobre redes neuronales, también se suele presentar a este
peso como un elemento ``aparte'' de la neurona, no como un peso extra, y se lo denota con
\(b^{(k)}_j\).}

\vspace{-0.2cm}
Con esta notación, si tomamos nuevamente a \(f^{(2)}_1\), los vectores involucrados van a
ser \(\bm{w}^{(1)}_1\) y \(\bm{s}^{(1)}_1\), dados en este caso por:
\begin{quote}
    \(\bm{w}^{(1)}_1 = (w^{(1)}_{0,1}, w^{(1)}_{1,1}, w^{(1)}_{2,1}, w^{(1)}_{3,1}, w^{(1)}_{4,1})\),
    \(\bm{s}^{(1)}_1 = (1, s^{(1)}_1, s^{(1)}_2, s^{(1)}_3, s^{(1)}_4)\)
\end{quote}
Esto se puede ver mejor gráficamente haciendo foco en dicha neurona, como lo ilustra
la Figura \ref{fig:neuron-weights}.
\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[x=2.7cm,y=1.6cm]
        \def\NI{4} % number of nodes in input layers
        \def\NO{3} % number of nodes in output layers
        \def\yshift{0.4} % shift last node for dots

        % INPUT LAYER
        \foreach \i in {0,...,\NI} {
            \pgfmathsetmacro{\y}{\NI/2 - \i}
            \ifnum\i=0
                \node[node hidden,outer sep=0.6] (NI-\i) at (0,\y) {1};
            \else
                \node[node hidden,outer sep=0.6] (NI-\i) at (0,\y) {\(s^{(1)}_{\i}\)};
            \fi
        }

        % OUTPUT LAYER
        \foreach \i in {\NO,...,1}{ % loop over nodes
            \pgfmathsetmacro{\y}{\NO/2 - \i}
            \ifnum\i=1 % high-lighted node
                \node[node hidden] (NO-\i) at (1,\y) {\(f^{(2)}_{\i}\)};
                \foreach \j in {0,...,\NI}{ % loop over nodes in previous layer
                    \draw[connect arrow] (NI-\j) -- (NO-\i)
                        node[pos=0.50, fill=white] {\contour{white}{\footnotesize{\(w^{(1)}_{\j,\i}\)}}};
                }
            \else % other light-colored nodes
                \node[node,blue!20!black!80,draw=myblue!20,fill=myblue!5]
                (NO-\i) at (1,\y) {\(f^{(2)}_{\i}\)};
                \foreach \j in {0,...,\NI}{ % loop over nodes in previous layer
                    \draw[connect arrow,myblue!20] (NI-\j) -- (NO-\i);
                }
            \fi
        }

        % \node[below=16,right=5,mydarkblue,scale=0.95] at (NO-1)
        \def\agr#1{{s_{#1}^{(1)}}}
        \node[right=of NO-1] at (0.8, -0.45){
            $\begin{aligned}
                &= a^{(2)}_1\left( \color{black}
                        w^{(1)}_{0,1} + w_{1,1}\agr{1} + w_{2,1}\agr{2} + w_{3,1}\agr{3} + w_{4,1}\agr{4}
                    \right) \\
                &= a^{(2)}_1\left( \color{black}
                    \begin{bmatrix}
                        w^{(1)}_{0,1} & w^{(1)}_{1,1} & w^{(1)}_{2,1} & w^{(1)}_{3,1} & w^{(1)}_{4,1}
                    \end{bmatrix}
                    \begin{bmatrix}
                        1 \\ s^{(1)}_1 \\ s^{(1)}_2 \\ s^{(1)}_3 \\ s^{(1)}_4
                    \end{bmatrix}
                    \right)
            \end{aligned}$
        };
    \end{tikzpicture}
    \caption{Entradas a la neurona \(f^{(2)}_1\), junto con sus pesos asociados. Se
    incluyen tanto la neurona dummy de la capa anterior como su bias. Cabe aclarar que se
    usan indistintamente las letras \(s\) y \(f\) para denotar a las neuronas. Adaptado de
    \cite{tikz-neural-networks}.}
    \label{fig:neuron-weights}
\end{figure}

Así como utilizamos vectores para describir el cómputo de una neurona, podemos emplear
matrices para describir el comportamiento de toda una capa. De hecho, las librerías que
implementan estos modelos se valen de esto ya que suelen estar optimizadas para cálculos
con matrices.

% Para ello, tomemos la siguiente notación, para lo cual resulta conveniente fijar una capa
% \(k\), que tiene \(m\) neuronas:
% \begin{itemize}[itemsep=0.1cm]
%     \item \(\bm{s}^{(k)}\) es el vector columna formado por las salidas de la capa
%     \(k\). Es decir: \(\bm{s}^{(k)} = (s_0^{(k)}, s_1^{(k)}, ..., s_m^{(k)})^T = (1,
%     s_1^{(k)}, ..., s_m^{(k)})^T\), de dimensión \(m \times 1\).
%     \item \(\bm{a}^{(k)}\) es la función de activación de la capa \(k\), con una aplicación
%     elemento a elemento. Es decir: \(\bm{a}^{(k)}(x_1, x_2, ..., x_m) = (a^{(k)}(x_1),
%     a^{(k)}(x_2), ..., a^{(k)}(x_m))\), donde \(a^{(k)}\) es la función de activación
%     de todas las neuronas de la capa \(k\) con aplicación a un número.
%     \item \(\bm{W}^{(k)}\) es la matriz de pesos que salen de la capa \(k\). Cada fila
%     \(j\) de esta matriz corresponde a los pesos que salen de todas las neuronas de la capa
%     \(k\) (incluyendo el bias) y se dirigen a la neurona \(j\) de la capa \((k+1)\). Es
%     decir cada fila es \(\bm{w}^{(k)}_j\) con \(j = 1,...,n\), y \(n\) la cantidad de
%     neuronas de la capa \((k+1)\) (sin contar la dummy, que ``aparece después''). Así,
%     esta matriz tiene dimensiones \(n \times m\).
% \end{itemize}
% Con esto, tenemos que la salida de una capa \(k\) está dada por:
% \[
%     \bm{s}^{(k)} = \bm{a}^{(k)} \left( \bm{W}^{(k-1)} \bm{s}^{(k-1)} \right)
% \]

% Con todo esto en mente, veamos cuál es la función que describe la red neuronal presentada
% como ejemplo:
% \begin{align*}
%     \bm{\hat{y}} =\ & \bm{s}^{(3)} \\
%         =\ & \bm{a}^{(3)} \left( \bm{W}^{(2)} \bm{s}^{(2)} \right) \\
%         =\ & \bm{a}^{(3)} \left(
%             \bm{W}^{(2)} \bm{a}^{(2)} \left(
%                 \bm{W}^{(1)} \bm{s}^{(1)}
%             \right)
%         \right) \\
%         =\ & \bm{a}^{(3)} \left(
%             \bm{W}^{(2)} \bm{a}^{(2)} \left(
%                 \bm{W}^{(1)} \bm{a}^{(1)} \left( \bm{W}^{(0)} \bm{s}^{(0)} \right)
%             \right)
%         \right) \\
%         =\ & \bm{a}^{(3)} \left(
%             \bm{W}^{(2)} \bm{a}^{(2)} \left(
%                 \bm{W}^{(1)} \bm{a}^{(1)} \left( \bm{W}^{(0)} \bm{x}^T \right)
%             \right)
%         \right)
% \end{align*}

% Y si queremos profundizar aún más esta ecuación para ver dónde aparece cada peso:
% \begin{align*}
%     \bm{\hat{y}}
%     &=\ \bm{a}^{(3)} \left(
%         \bm{W}^{(2)} \bm{a}^{(2)} \left(
%             \bm{W}^{(1)} \bm{a}^{(1)} \left( \bm{W}^{(0)} \bm{x}^T \right)
%         \right)
%     \right) \\
%     &=\ \bm{a}^{(3)} \left(
%             \bm{W}^{(2)} \bm{a}^{(2)} \left(
%                 \bm{W}^{(1)} \bm{a}^{(1)} \left(
%                     \bm{W}^{(0)} \begin{bmatrix} 1 \\ x_1 \\ x_2 \\ x_3 \end{bmatrix}
%             \right)
%         \right)
%     \right) \\
%     &=\ \bm{a}^{(3)} \left(
%             \bm{W}^{(2)} \bm{a}^{(2)} \left(
%                 \bm{W}^{(1)} \bm{a}^{(1)} \left(
%                     \begin{bmatrix}
%                         w_{0,1}^{(0)} & w_{1,1}^{(0)} & w_{2,1}^{(0)} & w_{3,1}^{(0)} \\
%                         w_{0,2}^{(0)} & w_{1,2}^{(0)} & w_{2,2}^{(0)} & w_{3,2}^{(0)} \\
%                         w_{0,3}^{(0)} & w_{1,3}^{(0)} & w_{2,3}^{(0)} & w_{3,3}^{(0)} \\
%                         w_{0,4}^{(0)} & w_{1,4}^{(0)} & w_{2,4}^{(0)} & w_{3,4}^{(0)}
%                     \end{bmatrix}
%                     \begin{bmatrix} 1 \\ x_1 \\ x_2 \\ x_3 \end{bmatrix}
%             \right)
%         \right)
%     \right) \\
%     &=\ \bm{a}^{(3)} \left(
%             \bm{W}^{(2)} \bm{a}^{(2)} \left(
%                 \bm{W}^{(1)} \bm{a}^{(1)} \left(
%                     \begin{bmatrix}
%                         w_{0,1}^{(0)} + w_{1,1}^{(0)} x_1 + w_{2,1}^{(0)} x_2 + w_{3,1}^{(0)} x_3 \\
%                         w_{0,2}^{(0)} + w_{1,2}^{(0)} x_1 + w_{2,2}^{(0)} x_2 + w_{3,2}^{(0)} x_3 \\
%                         w_{0,3}^{(0)} + w_{1,3}^{(0)} x_1 + w_{2,3}^{(0)} x_2 + w_{3,3}^{(0)} x_3 \\
%                         w_{0,4}^{(0)} + w_{1,4}^{(0)} x_1 + w_{2,4}^{(0)} x_2 + w_{3,4}^{(0)} x_3
%                     \end{bmatrix}
%             \right)
%         \right)
%     \right) \\
%     &=\ \bm{a}^{(3)} \left(
%             \bm{W}^{(2)} \bm{a}^{(2)} \left(
%                 \bm{W}^{(1)}
%                 \begin{bmatrix}
%                     a^{(1)} \left( w_{0,1}^{(0)} + w_{1,1}^{(0)} x_1 + w_{2,1}^{(0)} x_2 + w_{3,1}^{(0)} x_3 \right) \\
%                     a^{(1)} \left( w_{0,2}^{(0)} + w_{1,2}^{(0)} x_1 + w_{2,2}^{(0)} x_2 + w_{3,2}^{(0)} x_3 \right) \\
%                     a^{(1)} \left( w_{0,3}^{(0)} + w_{1,3}^{(0)} x_1 + w_{2,3}^{(0)} x_2 + w_{3,3}^{(0)} x_3 \right) \\
%                     a^{(1)} \left( w_{0,4}^{(0)} + w_{1,4}^{(0)} x_1 + w_{2,4}^{(0)} x_2 + w_{3,4}^{(0)} x_3 \right)
%                 \end{bmatrix}
%         \right)
%     \right) \\
%     &=\ \left( \dots \right)
% \end{align*}

\bigskip
En resumen, las redes neuronales constituyen una forma de modelar funciones altamente
expresivas, capaces de capturar patrones complejos a través de la composición de capas de
neuronas que actúan en cojunto. Estas neuronas están conectadas entre sí con distintas
intensidades que, como veremos, son justamente los parámetros aprendibles de las redes.
Además, introducen nuevos hiperparámetros referentes a la arquitectura. A continuación,
describimos cómo se lleva a cabo su entrenamiento, siempre dentro del contexto del
Aprendizaje Supervisado.

\subsubsection{Entrenamiento}
Los parámetros a optimizar en las redes son las intensidades de las conexiones entre las
neuronas, que también venimos llamando pesos. Los algoritmos de optimización que se
emplean actualmente se basan en la regla del DG, aunque con algunas mejoras.

Lo costoso de la regla clásica del DG presentada hasta el momento es que requiere calcular
el gradiente de la función de pérdida considerando \textit{todas} las muestras del
conjunto de entrenamiento. Para reducir esta carga, en la práctica se recurre a una
aproximación: en lugar de usar todas las muestras, se selecciona aleatoriamente un
subconjunto de ellas, llamado \textbf{lote} (\textit{batch}), y se calcula el gradiente
usando únicamente ese lote. Luego, se actualizan los pesos en base a esta estimación. Cabe
aclarar que el tamaño de lote, es decir la cantidad de ejemplos que se eligen cada vez, se
mantiene fijo en todo el entrenamiento y constituye un hiperparámetro. Esta técnica suele
llamarse optimización por \textbf{mini-lotes} o \textbf{estocástica}, ya que introduce
cierto grado de aletoriedad en el cálculo del gradiente.

Otra mejora aplicada sobre el método del DG estándar, diseñada para acelerar el
aprendizaje, es la técnica conocida como \textbf{momentum}. A grandes rasgos, consiste en
actualizar los pesos mirando no solo el gradiente de la iteración actual, sino también
prestando atención a la acumulación de gradientes de las iteraciones anteriores. Esto
permite sobre todo acelerar las actualizaciones cuando se encuentran sucesivos gradientes
que apuntan en la misma dirección \cite{deep-learning}. Un optimizador ampliamente
utilizado actualmente, y que es el que empleamos en este trabajo, es \textbf{Adam}
\cite{adampaper}. Este combina momentum con una tasa de aprendizaje adaptativa para cada
parámetro.

Para entender cómo progresa el entrenamiento, es útil definir el concepto el concepto de
\textbf{época}. Una época se refiere al proceso completo en el cual el modelo se entrena
utilizando \textbf{todos} los datos disponibles en el conjunto de entrenamiento una vez. A
grandes rasgos, los pasos involucrados en una época son los siguientes:
\begin{enumerate}[itemsep=0.05cm,label=\textbf{\arabic*.}]
    \item Mezclar el conjunto de entrenamiento. Este paso en realidad es opcional
    pero evita que el modelo aprenda patrones no deseados debido al orden de los datos.
    \item Seleccionar un lote del tamaño predefinido del conjunto de datos de entrenamiento.
    \item Para cada ejemplo del lote:
    \vspace{-0.2cm}
    \begin{enumerate}[noitemsep]
        \item Computar la predicción del modelo.
        \item Calcular la pérdida.
    \end{enumerate}
    \item Promediar el error a lo largo de todos los ejemplos del lote. Este valor escalar
    no se utiliza directamente en el entrenamiento, pero se emplea comúnmente para
    monitorear el progreso del aprendizaje.
    \item Calcular el gradiente utilizando solamente las muestras del lote.
    \item Actualizar los pesos.
    \item Volver a 2.
    \item Una vez que se han recorrido todos los lotes, finaliza la época.
\end{enumerate}

Ahora bien, un paso fundamental en el entrenamiento de las redes neuronales y del que vale
la pena profundizar es el del cálculo del gradiente. De hecho, no encontrar una solución
eficiente para lograrlo detuvo el avance de estos modelos durante varios años. El algoritmo
que vino a dar respuesta y que es el utilizado hasta hoy es conocido como
\textbf{retropropagación} (del inglés \textit{backpropagation}) y fue presentado en el año
1986 \cite{backprop-1986}.

El backpropagation se basa fundamentalmente en la regla de la cadena para derivadas de
funciones compuestas y se divide en dos etapas: primero, el paso hacia adelante
(\textit{forward pass}) y luego, el paso hacia atras (\textit{backward pass}). Para
entender estas etapas, supondremos que solamente una entrada es provista a la red.

En el forward pass, la red simplemente lleva a cabo una predicción para la entrada,
realizando todo el cómputo intermedio necesario para llegar a producir una salida, y
guardando la salida de cada neurona.

El backward pass comienza por calcular el error cometido por la red para la entrada dada,
y consiste en propagar este error desde la capa de salida hasta la de entrada, midiendo la
contribución al error de cada conexión \cite{hands-on-ML-sklearn-tf}. Este paso se basa
fuertemente en la idea que un pequeño cambio en uno de los pesos causa un efecto cadena
sobre el cómputo restante de la red \cite{prince2024understanding}. Para verlo, supongamos
que tenemos una red neuronal con tres capas ocultas, que denotaremos con \(\bm{h}^{(1)}\),
\(\bm{h}^{(2)}\) y \(\bm{h}^{(3)}\) (la cantidad de neuronas en cada capa es irrelevante),
y veamos cómo computaríamos el efecto de un cambio en un peso de manera intuitiva
\cite{prince2024understanding}:
\begin{itemize}
    \item Para calcular cómo un cambio en un peso que se dirige a \(\bm{h}^{(3)}\)
    modifica el valor de la pérdida, necesitamos saber (i) cómo un cambio en
    \(\bm{h}^{(3)}\) modifica la salida del modelo y (ii) cómo un cambio en la salida
    modifica la pérdida.
    \item Para calcular cómo un cambio en un peso que se dirige a \(\bm{h}^{(2)}\)
    modifica el valor de la pérdida, necesitamos saber (i) cómo un cambio en
    \(\bm{h}^{(2)}\) afecta a \(\bm{h}^{(3)}\), (ii) cómo un cambio en \(\bm{h}^{(3)}\)
    modifica la salida del modelo y (iii) cómo un cambio en la salida modifica la pérdida.
    \item Para calcular cómo un cambio en un peso que se dirige a \(\bm{h}^{(1)}\)
    modifica el valor de la pérdida, necesitamos saber (i) cómo un cambio en
    \(\bm{h}^{(1)}\) afecta a \(\bm{h}^{(2)}\), (ii) cómo un cambio en \(\bm{h}^{(2)}\)
    afecta a \(\bm{h}^{(3)}\), (iii) cómo un cambio en \(\bm{h}^{(3)}\) modifica la salida
    del modelo y (iv) cómo un cambio en la salida modifica la pérdida.
\end{itemize}
Mientras nos movemos hacia las primeras capas de la red, vemos que la mayoría de los
términos que se necesitan ya han sido calculados en pasos anteriores, por lo que no es
necesario recomputarlos. Justamente calcular los efectos de los cambios - que son en otras
palabras las derivadas parciales - de esta manera es conocido como el backward pass.

El paso final del backpropagation es actualizar los pesos con los gradientes calculados
en el backward pass utilizando la regla del DG (con las optimizaciones que se hayan
incluido).

\bigskip
Para finalizar, hablaremos de un problema bastante conocido al entrenar redes neuronales,
conocido como \textbf{sobreajuste} (en inglés \textit{overfitting}).

A grandes rasgos, los factores que determinan qué tan bueno es un modelo son sus capacidades
para \cite{deep-learning}:
\begin{itemize}[itemsep=0.1cm]
    \item Reducir el error en el conjunto de entrenamiento.
    \item Reducir la brecha entre el error en el conjunto de entrenamiento y en el de
    test.
\end{itemize}

Las redes neuronales son bastante capaces de lograr lo primero, principalmente gracias a
su habilidad de modelar una gran variedad de funciones, pero muchas veces puede ocurrir
que no logren alcanzar lo segundo, y esto es lo que se conoce como sobreajuste. Es decir,
el overfitting ocurre cuando la brecha entre el error en el conjunto de entrenamiento y en
el de test es significativa. Esto signficia que el modelo ha aprendido los patrones vistos
durante su entrenamiento ``de memoria'' y no está siendo capaz de generalizar correctamente.

Por suerte, para solucionar este problema, existen técnicas llamadas \textbf{de
regularización}. Una regularización es cualquier modificación hecha sobre un algoritmo de
aprendizaje que tiene como objetivo reducir el error de generalización (i.e. en el
conjunto de test) pero no el de entrenamiento \cite{deep-learning}.

Existen varias estrategia de regularización, pero una puntual que utilizaremos en este
trabajo y que ha probado ser efectiva es llamada \textbf{\textit{dropout}}. El dropout se
puede aplicar sobre la capa de entrada o las capas ocultas, pero no sobre la de salida.
Una ventaja es que su implementación es relativamente sencilla: en cada paso de
entrenamiento\footnotemark, cada neurona de la capa sobre la que se esté aplicando el
dropout tiene una probabilidad \(p\) de ser temporalmente descartada, lo cual significa
que su salida va a ser ignorada en este paso \cite{hands-on-ML-sklearn-tf}, normalmente
multiplicándola por 0. Aquí se introduce un nuevo hiperparámetro, \(p\), llamado ``tasa de
dropout''.
\footnotetext{Cuando se utiliza DG Estocástico, un paso de entrenamiento equivale a procesar un lote.}

Este método fuerza a las neuronas a aprender no solo a ser útiles por sí solas,
pero sino también a ser compatibles con muchos conjuntos posibles de neuronas que pueden
estar o no incluidas en la red \cite{ai-a-modern-approach}. En resumen, contribuye
a que la red no dependa de unidades específicas y la fuerza a aprender diversas
explicaciones para cada entrada \cite{ai-a-modern-approach}.

Luego del entrenamiento, no se aplica más el dropout y todas las neuronas de la red
contribuyen a la inferencia. Sin embargo, como en este momento la red tiene más neuronas
ocultas que cuando fue entrenada, lo que se hace para compensar este hecho es multiplicar
cada peso por (\(1-p\)) \cite{prince2024understanding}.

\bigskip
En las siguientes secciones, hablaremos sobre dos tipos particulares de redes neuronales
de las que hacemos uso en este trabajo: las redes neuronales Convolucionales y las redes
neuronales Recurrentes. Cada una fue diseñada originalmente para trabajar con un tipo
específico de datos. Las convolucionales son ideales para procesar datos estructurados en
forma de grilla, mientras que las recurrentes son adecuadas para secuencias temporales.
Presentaremos la intuición detrás de ellas y nos concentraremos en su aplicación sobre
series de tiempo, relevante para nuestro trabajo.

\end{document}