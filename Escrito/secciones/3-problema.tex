\documentclass[../main.tex]{subfiles}

\begin{document}
El objetivo principal de toda evaluación de impacto es calcular el efecto de un programa o
intervención sobre la población receptora. Para ello, es necesario obtener una estimación
apropiada del contrafactual: ¿qué habría pasado con la variable de resultado de los
beneficiarios del programa si el mismo no hubiera existido? Como esta es una situación
hipotética, no observable en la realidad, se recurre a la conformación de un grupo de
control, que debería estar formado, idelamente, por individuos que eran estadísticamentes
similares a los tratados antes de la implementación del programa — es decir, en la línea
de base — pero que no fueron expuestos a la intervención en cuestión.

En esta tarea, aparece el problema del sesgo de autoselección, que ocurre cuando no se
toman en cuenta las diferencias preexistentes entre tratados y no tratados. Estas
diferencias pueden haber influido tanto en la decisión de participar en el programa como
en los resultados potenciales posteriores, por lo que no considerarlas podría afectar la
validez de las comparaciones entre ambos grupos.

En evaluaciones sobre programas con asignación aleatoria, el grupo de control se obtiene
directamente tomando todos los individuos que no fueron tratados y el problema de
autoselección se soluciona naturalmente. Sin embargo, en las evaluaciones
cuasi-experimentales, hechas sobre intervenciones en donde la asignación al tratamiento no
fue aleatoria y se desconocen los motivos que han llevado a los individuos a inscribirse o
recibir el tratamiento, seleccionar un grupo de control adecuado constituye un gran
desafío. Este es uno de los temas centrales de este trabajo.

Una técnica para abordar este problema es el PSM, discutida anteriormente y que es la que
tomamos como punto de partida aquí. Este método empareja individuos tratados con no
tratados basándose en su probabilidad estimada de participación, calculada a partir de un
conjunto de variables que se consideran influyentes en el programa bajo cuestión.

Estas variables son seleccionadas por los evaluadores y pueden representar tanto
características observadas en un instante determinado como también compartamientos a lo
largo del tiempo. Por ejemplo, si consideramos un programa de financiamento a empresas, se
puede tomar como variable el número de empleados y los ingresos mensuales de solamente el
mes anterior al inicio del programa, o se podría tomar esta cantidad observada durante
diez meses previos al comienzo, siempre y cuando el investigador considere que es
relevante hacerlo. De esta forma, es posible incluir series de tiempo en el cálculo del
puntaje de propensión, tomando como variables explicativas varios períodos de la misma
característica. Esto permite capturar no solo un estado puntual de las unidades sino
también cómo ha sido su evolución antes del inicio del programa, lo cual puede contribuir
a un mejor emparejamiento y consecuentemente, a una estimación más precisa del
contrafactual.

Otra aspecto a tener en cuenta a la hora de identificar los individuos de control es la
forma de implementación del programa a lo largo del tiempo. En algunos casos, el ingreso
al tratamiento por parte de los individuos se realiza en un único instante de tiempo, pero
en otros la entrada al programa ocurre de manera secuencial. En este último caso, se habla
de una \textbf{cohorte} o una \textbf{camada} para referirse al conjunto de individuos que
ingresaron al programa en el mismo momento. Por ejemplo, si los ingresos al programa se
dieron en dos meses distintos de un determinado año, entonces los individuos que
ingresaron en el primer mes conforman una cohorte, y los que ingresaron en el segundo forman
otra cohorte distinta.

Habiendo presentado estas cuestiones, nuestro trabajo se enfoca en programas con entrada
secuencial y en los que se supone que los individuos son tratados (o deciden inscribirse
al programa) debido a la dinámica temporal observada en la variable
objetivo\footnote{Recordemos que la variable objetivo es aquella sobre la que se espera
que el programa tenga un efecto.} de cada uno durante períodos previos a la asignación.
Bajo estas circunstancias, el PSM presenta ciertas limitaciones:
\begin{itemize}
    \item Por un lado, cuando existen múltiples cohortes, la forma en la que se aplica la
    técnica es de a una cohorte a la vez. Es decir, se estima un modelo para calcular la
    probabilidad de participación por camada, y se buscan controles por separado para cada
    una de ellas. Dicho de otra manera, el proceso completo de emparejamiento se realiza
    tantas veces como cohortes haya.
    \item Por otro lado, cuando las variables tenidas en cuenta en realidad representan
    una misma característica observada en distintos períodos de tiempo, la regresión
    logística — que es es una de las formas más comunes en la que se calcula el puntaje de
    propensión (y la que usamos en este trabajo) — no es capaz de capturar la relación
    temporal entre ellas, sino que las trata como si fueran independientes.
\end{itemize}

Con estos problemas en mente, el objetivo de este trabajo es explorar una alternativa
basada en la utilización de redes neuronales para la identificación de grupos de control
bajo los supuestos mencionados previamente. La estrategia propuesta se apoya en distintos
tipos de arquitecturas, concretamente: redes convolucionales, redes LSTM, y la combinación
de ellas. Como explicamos en el capítulo anterior, estas incorporan naturalmente la
relación temporal de los datos, permitiendo capturar patrones a lo largo del tiempo. En
los escenarios bajo estudio, donde suponemos que la dinámica previa a la intervención es
un factor clave para entender la participación en el programa, consideramos que estas
redes pueden resultar especialmente útiles.

Para evaluar la metodología propuesta, desarrollamos diferentes conjuntos de datos
sintéticos de tipo panel\footnote{Los datos de tipo panel son aquellos en los que a cada
unidad considerada le corresponde una serie de tiempo.}, ya que en los casos reales
algunos comportamientos no pueden observarse directamente. En estos escenarios, variamos
la cantidad de \textbf{períodos observados} (previos al inicio del programa), la cantidad
de \textbf{períodos de dependencia temporal} — que son aquellos dentro de los períodos
observados en los que modelamos una tendencia específica —, y la \textbf{dinámica
temporal} observada en la variable. Teniendo esto en cuenta, los objetivos de nuestro
trabajo se pueden resumir en los siguientes puntos:
\begin{itemize}
    \item Obtener resultados que permitan comparar el desempeño de las diferentes
    arquitecturas de redes neuronales propuestas con el del PSM en los escenarios
    simulados.
    \item Evaluar la capacidad de las redes neuronales para identificar individuos de
    control ante variaciones en la cantidad de períodos observados, los períodos de
    dependencia y la dinámica temporal de la variable observada.
    \item Superar las limitaciones observadas del PSM utilizando las redes neuronales.
    Esto es: incorporar de manera más efectiva la dependencia temporal de las covariables
    y agilizar la identificación de los grupos de control de cada cohorte.
\end{itemize}

Nuestras hipótesis son las siguientes:
\begin{itemize}
    \item Dada una cantidad fija de períodos observados pre-tratamiento, cuanto mayor sea
    la cantidad de períodos de dependencia, mayor será la diferencia de desempeño entre
    las redes neuronales y el PSM, siempre a favor de las redes. Sin embargo, a medida que
    se reduzca la cantidad de períodos de dependencia, consideramos que su rendimeinto se
    degradará y tenderá a acercarse al del PSM.
    \item A medida que haya más períodos pre-tratamiento — en otras palabras, mayor
    disponibilidad de datos —, ambos métodos mejorarán sus resultados, aunque el de las
    redes será consistentemente superior.
    \item Las redes neuronales permitirán entrenar un único modelo que pueda utilizarse en
    diferentes cohortes, a diferencia del PSM, que requiere una estimación por cohorte.
    \item Las redes LSTM superarán el desempeño de las convolucionales, y la combinación de
    ambas dará un mejor rendimiento que el de cada una por separado.
\end{itemize}

A continuación, presentamos el marco sobre el cual llevamos a cabo los experimentos.
Detallamos el alcance de nuestro trabajo, el diseño de las diferentes simulaciones, las
arquitecturas de redes propuestas, las métricas de interés para evaluar los modelos, la
estrategia de comparación entre los dos enfoques, y las herramientas empleadas en todo
este proceso.

\end{document}